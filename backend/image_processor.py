"""
èœ€é”¦èœ€ç»£AIæ‰“æ ·å›¾ç”Ÿæˆå·¥å…· - å›¾åƒå¤„ç†æ ¸å¿ƒæ¨¡å—
æä¾›ä¸“ä¸šçš„å›¾åƒå¤„ç†åŠŸèƒ½ï¼Œä¸“æ³¨äºèœ€é”¦èœ€ç»£ä¼ ç»Ÿé£æ ¼çš„AIå›¾åƒå¤„ç†
"""

import cv2
import numpy as np
from PIL import Image, ImageFilter, ImageEnhance, ImageOps
from sklearn.cluster import KMeans
import os
import logging
import time
from pathlib import Path
from typing import Tuple, List, Optional, Dict, Any
import xml.etree.ElementTree as ET
from concurrent.futures import ThreadPoolExecutor
import warnings
from professional_weaving_generator import ProfessionalWeavingGenerator

# æŠ‘åˆ¶ä¸å¿…è¦çš„è­¦å‘Š
warnings.filterwarnings('ignore', category=UserWarning)

logger = logging.getLogger(__name__)


class ImageProcessingError(Exception):
    """å›¾åƒå¤„ç†ä¸“ç”¨å¼‚å¸¸ç±»"""
    pass


class SichuanBrocadeProcessor:
    """
    èœ€é”¦èœ€ç»£å›¾åƒå¤„ç†å™¨
    
    ä¸“æ³¨äºä¼ ç»Ÿèœ€é”¦èœ€ç»£é£æ ¼çš„å›¾åƒå¤„ç†ï¼Œæä¾›é¢œè‰²é™è‰²ã€è¾¹ç¼˜å¢å¼ºã€
    å™ªå£°æ¸…ç†ç­‰åŠŸèƒ½ï¼Œç”Ÿæˆé€‚åˆç»‡æœºä½¿ç”¨çš„é«˜è´¨é‡æ‰“æ ·å›¾ã€‚
    """
    
    def __init__(self, outputs_dir: str = "outputs"):
        """
        åˆå§‹åŒ–å¤„ç†å™¨
        
        Args:
            outputs_dir: è¾“å‡ºç›®å½•è·¯å¾„
        """
        self.outputs_dir = Path(outputs_dir)
        self.outputs_dir.mkdir(exist_ok=True, parents=True)
        
        # åˆå§‹åŒ–ä¸“ä¸šç»‡æœºç”Ÿæˆå™¨
        self.professional_generator = ProfessionalWeavingGenerator(outputs_dir)
        
        # å¤„ç†é…ç½®
        self.config = {
            "max_image_size": 4096,  # æå‡åˆ°4Kåˆ†è¾¨ç‡
            "min_image_size": 512,   # æå‡æœ€å°å°ºå¯¸è¦æ±‚
            "high_res_threshold": 1920,  # é«˜åˆ†è¾¨ç‡é˜ˆå€¼
            "default_quality": 98,   # æå‡é»˜è®¤è´¨é‡
            "compression_level": 0,  # æ— å‹ç¼©ï¼Œä¿æŒæœ€é«˜è´¨é‡
            "gaussian_kernel_size": (3, 3),
            "morphology_kernel_size": (3, 3),
            "preserve_large_images": True  # ä¿æŒå¤§å›¾åƒçš„åŸå§‹å°ºå¯¸
        }
        
        logger.info(f"å›¾åƒå¤„ç†å™¨å·²åˆå§‹åŒ–ï¼Œè¾“å‡ºç›®å½•: {self.outputs_dir}")
    
    def process_image_professional(self, 
                                 input_path: str, 
                                 job_id: str,
                                 color_count: int = 16,
                                 edge_enhancement: bool = True,
                                 noise_reduction: bool = True) -> Tuple[str, str, float]:
        """
        ä½¿ç”¨ä¸“ä¸šç»‡æœºç”Ÿæˆå™¨å¤„ç†å›¾åƒ
        
        Args:
            input_path: è¾“å…¥å›¾åƒè·¯å¾„
            job_id: ä»»åŠ¡å”¯ä¸€æ ‡è¯†ç¬¦
            color_count: ç›®æ ‡é¢œè‰²æ•°é‡ï¼ˆ10-20ï¼‰
            edge_enhancement: æ˜¯å¦å¯ç”¨è¾¹ç¼˜å¢å¼º
            noise_reduction: æ˜¯å¦å¯ç”¨å™ªå£°æ¸…ç†
            
        Returns:
            Tuple[professional_png_path, comparison_png_path, processing_time]: å¤„ç†ç»“æœè·¯å¾„å’Œè€—æ—¶
            
        Raises:
            ImageProcessingError: å›¾åƒå¤„ç†å¤±è´¥æ—¶æŠ›å‡º
        """
        try:
            logger.info(f"ğŸš€ å¼€å§‹ä¸“ä¸šç»‡æœºè¯†åˆ«å›¾åƒå¤„ç†: {job_id}")
            
            # éªŒè¯è¾“å…¥å‚æ•°
            self._validate_inputs(input_path, job_id, color_count)
            
            # ä½¿ç”¨ä¸“ä¸šç»‡æœºç”Ÿæˆå™¨å¤„ç†
            professional_path, comparison_path, processing_time = self.professional_generator.generate_professional_image(
                input_path, job_id, color_count
            )
            
            logger.info(f"âœ… ä¸“ä¸šç»‡æœºè¯†åˆ«å›¾åƒå¤„ç†å®Œæˆ: {job_id}")
            
            return professional_path, comparison_path, processing_time
            
        except Exception as e:
            error_msg = f"ä¸“ä¸šç»‡æœºå›¾åƒå¤„ç†å¤±è´¥: {str(e)}"
            logger.error(error_msg, exc_info=True)
            raise ImageProcessingError(error_msg)
    
    def process_image(self, 
                     input_path: str, 
                     job_id: str,
                     color_count: int = 16,
                     edge_enhancement: bool = True,
                     noise_reduction: bool = True) -> Tuple[str, str, float]:
        """
        å¤„ç†å›¾åƒçš„ä¸»è¦æ–¹æ³•
        
        Args:
            input_path: è¾“å…¥å›¾åƒè·¯å¾„
            job_id: ä»»åŠ¡å”¯ä¸€æ ‡è¯†ç¬¦
            color_count: ç›®æ ‡é¢œè‰²æ•°é‡ï¼ˆ10-20ï¼‰
            edge_enhancement: æ˜¯å¦å¯ç”¨è¾¹ç¼˜å¢å¼º
            noise_reduction: æ˜¯å¦å¯ç”¨å™ªå£°æ¸…ç†
            
        Returns:
            Tuple[png_path, svg_path, processing_time]: å¤„ç†ç»“æœè·¯å¾„å’Œè€—æ—¶
            
        Raises:
            ImageProcessingError: å›¾åƒå¤„ç†å¤±è´¥æ—¶æŠ›å‡º
        """
        start_time = time.time()
        
        try:
            logger.info(f"å¼€å§‹å¤„ç†ä»»åŠ¡ {job_id}: {input_path}")
            
            # éªŒè¯è¾“å…¥å‚æ•°
            self._validate_inputs(input_path, job_id, color_count)
            
            # åˆ›å»ºä»»åŠ¡ä¸“ç”¨ç›®å½•
            job_dir = self.outputs_dir / job_id
            job_dir.mkdir(exist_ok=True, parents=True)
            
            # å¤„ç†æµæ°´çº¿ - åˆºç»£ä¼˜åŒ–ç‰ˆ
            processing_steps = [
                ("åŠ è½½å’Œé¢„å¤„ç†", self._load_and_preprocess),
                ("é¢œè‰²èšç±»é™è‰² + ç»‡æœºè¯†åˆ«ä¼˜åŒ–", lambda img: self._color_reduction(img, color_count)),
                ("è¾¹ç¼˜å¢å¼º", lambda img: self._enhance_edges(img) if edge_enhancement else img),
                ("å™ªå£°æ¸…ç†", lambda img: self._noise_reduction(img) if noise_reduction else img),
                ("èœ€é”¦é£æ ¼åŒ–", self._apply_sichuan_style),
                ("åˆºç»£å“è´¨ä¼˜åŒ–", self._embroidery_quality_enhancement)
            ]
            
            # æ‰§è¡Œå¤„ç†æµæ°´çº¿
            image = None
            for step_name, step_func in processing_steps:
                try:
                    if image is None:
                        image = step_func(input_path)
                    else:
                        image = step_func(image)
                    logger.info(f"âœ“ {step_name}å®Œæˆ")
                except Exception as e:
                    raise ImageProcessingError(f"{step_name}å¤±è´¥: {str(e)}")
            
            # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶
            png_path = job_dir / f"{job_id}_processed.png"
            svg_path = job_dir / f"{job_id}_pattern.svg"
            
            # å¹¶è¡Œä¿å­˜æ–‡ä»¶
            with ThreadPoolExecutor(max_workers=2) as executor:
                png_future = executor.submit(self._save_high_quality_png, image, str(png_path))
                svg_future = executor.submit(self._generate_svg, image, str(svg_path))
                
                # ç­‰å¾…PNGå®Œæˆï¼ˆå¿…éœ€ï¼‰
                png_future.result()
                
                # ç­‰å¾…SVGå®Œæˆï¼ˆå¯é€‰ï¼‰
                try:
                    svg_future.result()
                except Exception as e:
                    logger.warning(f"SVGç”Ÿæˆå¤±è´¥ï¼Œä½†ä¸å½±å“ä¸»æµç¨‹: {str(e)}")
            
            processing_time = time.time() - start_time
            
            # éªŒè¯PNGæ–‡ä»¶ï¼ˆå¿…éœ€ï¼‰
            if not png_path.exists():
                raise ImageProcessingError("PNGæ–‡ä»¶ç”Ÿæˆå¤±è´¥")
            
            # æ£€æŸ¥SVGæ–‡ä»¶ï¼ˆå¯é€‰ï¼‰
            if not svg_path.exists():
                logger.warning("SVGæ–‡ä»¶æœªç”Ÿæˆï¼Œåˆ›å»ºå ä½æ–‡ä»¶")
                self._create_fallback_svg(str(svg_path), image.shape[:2])
            
            logger.info(f"âœ“ ä»»åŠ¡ {job_id} å¤„ç†å®Œæˆï¼Œè€—æ—¶: {processing_time:.2f}ç§’")
            
            return str(png_path), str(svg_path), processing_time
            
        except ImageProcessingError:
            raise
        except Exception as e:
            error_msg = f"å›¾åƒå¤„ç†æ„å¤–å¤±è´¥: {str(e)}"
            logger.error(error_msg, exc_info=True)
            raise ImageProcessingError(error_msg)
    
    def _validate_inputs(self, input_path: str, job_id: str, color_count: int):
        """éªŒè¯è¾“å…¥å‚æ•°"""
        # éªŒè¯æ–‡ä»¶å­˜åœ¨æ€§
        if not Path(input_path).exists():
            raise ImageProcessingError(f"è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_path}")
        
        # éªŒè¯ä»»åŠ¡ID
        if not job_id or not job_id.strip():
            raise ImageProcessingError("ä»»åŠ¡IDä¸èƒ½ä¸ºç©º")
        
        # éªŒè¯é¢œè‰²æ•°é‡
        allowed_color_counts = [10, 12, 14, 16, 18, 20]
        if color_count not in allowed_color_counts:
            raise ImageProcessingError(f"é¢œè‰²æ•°é‡å¿…é¡»æ˜¯ä»¥ä¸‹å€¼ä¹‹ä¸€: {', '.join(map(str, allowed_color_counts))}ï¼Œå½“å‰å€¼: {color_count}")
        
        # éªŒè¯æ–‡ä»¶å¤§å°
        file_size = Path(input_path).stat().st_size
        if file_size > 10 * 1024 * 1024:  # 10MB
            raise ImageProcessingError("æ–‡ä»¶å¤§å°è¶…è¿‡10MBé™åˆ¶")
    
    def _load_and_preprocess(self, input_path: str) -> np.ndarray:
        """åŠ è½½å¹¶é¢„å¤„ç†å›¾åƒï¼Œç‰¹åˆ«ä¼˜åŒ–ç†ŠçŒ«å›¾åƒ"""
        try:
            # åŠ è½½å›¾åƒ
            image = cv2.imread(input_path)
            if image is None:
                raise ImageProcessingError(f"æ— æ³•åŠ è½½å›¾åƒ: {input_path}")
            
            # æ£€æŸ¥å›¾åƒå°ºå¯¸
            height, width = image.shape[:2]
            logger.info(f"åŸå§‹å›¾åƒå°ºå¯¸: {width}x{height}")
            
            # ç†ŠçŒ«å›¾åƒç‰¹æ®Šé¢„å¤„ç†
            if self._is_panda_image(image):
                logger.info("æ£€æµ‹åˆ°ç†ŠçŒ«å›¾åƒï¼Œåº”ç”¨ç‰¹æ®Šé¢„å¤„ç†")
                image = self._preprocess_panda_image(image)
            
            # æ ‡å‡†é¢„å¤„ç†
            image = self._standard_preprocess(image)
            
            return image
            
        except Exception as e:
            logger.error(f"å›¾åƒåŠ è½½å’Œé¢„å¤„ç†å¤±è´¥: {str(e)}")
            raise ImageProcessingError(f"å›¾åƒé¢„å¤„ç†å¤±è´¥: {str(e)}")
    
    def _is_panda_image(self, image: np.ndarray) -> bool:
        """æ£€æµ‹æ˜¯å¦ä¸ºç†ŠçŒ«å›¾åƒ"""
        try:
            # è½¬æ¢ä¸ºç°åº¦å›¾
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            
            # æ£€æµ‹ç†ŠçŒ«ç‰¹å¾ï¼šé»‘ç™½å¯¹æ¯”
            # è®¡ç®—é»‘è‰²åŒºåŸŸæ¯”ä¾‹ï¼ˆç†ŠçŒ«çš„çœ¼ç›ã€è€³æœµã€èº«ä½“ï¼‰
            black_pixels = np.sum(gray < 80)
            total_pixels = gray.size
            
            # è®¡ç®—ç™½è‰²åŒºåŸŸæ¯”ä¾‹ï¼ˆç†ŠçŒ«çš„é¢éƒ¨ã€èº«ä½“ï¼‰
            white_pixels = np.sum(gray > 180)
            
            # å¦‚æœé»‘ç™½åŒºåŸŸæ¯”ä¾‹ç¬¦åˆç†ŠçŒ«ç‰¹å¾ï¼Œåˆ™è®¤ä¸ºæ˜¯ç†ŠçŒ«å›¾åƒ
            black_ratio = black_pixels / total_pixels
            white_ratio = white_pixels / total_pixels
            
            # ç†ŠçŒ«é€šå¸¸æœ‰è¾ƒé«˜çš„é»‘ç™½å¯¹æ¯”åº¦
            if black_ratio > 0.1 and white_ratio > 0.2:
                logger.info(f"æ£€æµ‹åˆ°ç†ŠçŒ«ç‰¹å¾ - é»‘è‰²åŒºåŸŸ: {black_ratio:.2f}, ç™½è‰²åŒºåŸŸ: {white_ratio:.2f}")
                return True
            
            return False
            
        except Exception as e:
            logger.warning(f"ç†ŠçŒ«æ£€æµ‹å¤±è´¥: {str(e)}")
            return False
    
    def _preprocess_panda_image(self, image: np.ndarray) -> np.ndarray:
        """ç†ŠçŒ«å›¾åƒç‰¹æ®Šé¢„å¤„ç†ï¼Œå¢å¼ºè´¨é‡å¤„ç†"""
        try:
            # 1. å¢å¼ºå¯¹æ¯”åº¦
            lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
            l, a, b = cv2.split(lab)
            
            # ä½¿ç”¨CLAHEå¢å¼ºäº®åº¦é€šé“
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
            l = clahe.apply(l)
            
            # é‡æ–°åˆå¹¶LABé€šé“
            lab = cv2.merge([l, a, b])
            enhanced = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)
            
            # 2. ä¼˜åŒ–ç†ŠçŒ«çš„é»‘ç™½åŒºåŸŸ
            enhanced = self._optimize_panda_contrast(enhanced)
            
            # 3. ç‰¹åˆ«å¤„ç†ä¸‹å·´/é¢ˆéƒ¨åŒºåŸŸ
            enhanced = self._enhance_panda_chin_area(enhanced)
            
            # 4. å¢å¼ºè¾¹ç¼˜æ¸…æ™°åº¦
            enhanced = self._enhance_panda_edges(enhanced)
            
            # 5. æ¶ˆé™¤å™ªå£°
            enhanced = self._denoise_panda_image(enhanced)
            
            # 6. é¢œè‰²å¹³è¡¡ä¼˜åŒ–
            enhanced = self._balance_panda_colors(enhanced)
            
            return enhanced
            
        except Exception as e:
            logger.warning(f"ç†ŠçŒ«å›¾åƒé¢„å¤„ç†å¤±è´¥: {str(e)}")
            return image
    
    def _enhance_panda_edges(self, image: np.ndarray) -> np.ndarray:
        """å¢å¼ºç†ŠçŒ«å›¾åƒçš„è¾¹ç¼˜æ¸…æ™°åº¦"""
        try:
            # è½¬æ¢ä¸ºç°åº¦å›¾
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            
            # ä½¿ç”¨æ‹‰æ™®æ‹‰æ–¯ç®—å­æ£€æµ‹è¾¹ç¼˜
            laplacian = cv2.Laplacian(gray, cv2.CV_64F)
            laplacian = np.uint8(np.absolute(laplacian))
            
            # ä½¿ç”¨Sobelç®—å­æ£€æµ‹è¾¹ç¼˜
            sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)
            sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
            sobel = np.sqrt(sobelx**2 + sobely**2)
            sobel = np.uint8(sobel)
            
            # ç»“åˆä¸¤ç§è¾¹ç¼˜æ£€æµ‹ç»“æœ
            edges = cv2.addWeighted(laplacian, 0.5, sobel, 0.5, 0)
            
            # åˆ›å»ºè¾¹ç¼˜å¢å¼ºæ©ç 
            edge_mask = edges > 30  # é˜ˆå€¼åŒ–è¾¹ç¼˜
            
            # åœ¨è¾¹ç¼˜åŒºåŸŸå¢å¼ºå¯¹æ¯”åº¦
            enhanced = image.copy()
            enhanced[edge_mask] = cv2.addWeighted(enhanced[edge_mask], 1.2, enhanced[edge_mask], 0, 10)
            
            return enhanced
            
        except Exception as e:
            logger.warning(f"ç†ŠçŒ«è¾¹ç¼˜å¢å¼ºå¤±è´¥: {str(e)}")
            return image
    
    def _denoise_panda_image(self, image: np.ndarray) -> np.ndarray:
        """æ¶ˆé™¤ç†ŠçŒ«å›¾åƒçš„å™ªå£°"""
        try:
            # ä½¿ç”¨åŒè¾¹æ»¤æ³¢ä¿æŒè¾¹ç¼˜çš„åŒæ—¶å»é™¤å™ªå£°
            denoised = cv2.bilateralFilter(image, 9, 75, 75)
            
            # å¯¹äºç†ŠçŒ«çš„é»‘ç™½åŒºåŸŸï¼Œä½¿ç”¨æ›´æ¸©å’Œçš„æ»¤æ³¢
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            
            # æ£€æµ‹é»‘è‰²å’Œç™½è‰²åŒºåŸŸ
            black_mask = gray < 80
            white_mask = gray > 180
            
            # åœ¨è¿™äº›åŒºåŸŸä½¿ç”¨æ›´æ¸©å’Œçš„æ»¤æ³¢
            if np.sum(black_mask) > 0 or np.sum(white_mask) > 0:
                # ä½¿ç”¨é«˜æ–¯æ»¤æ³¢è¿›è¡Œæ¸©å’Œå»å™ª
                gaussian = cv2.GaussianBlur(image, (3, 3), 0)
                
                # åœ¨é»‘ç™½åŒºåŸŸåº”ç”¨é«˜æ–¯æ»¤æ³¢
                denoised[black_mask] = gaussian[black_mask]
                denoised[white_mask] = gaussian[white_mask]
            
            return denoised
            
        except Exception as e:
            logger.warning(f"ç†ŠçŒ«å›¾åƒå»å™ªå¤±è´¥: {str(e)}")
            return image
    
    def _balance_panda_colors(self, image: np.ndarray) -> np.ndarray:
        """å¹³è¡¡ç†ŠçŒ«å›¾åƒçš„é¢œè‰²"""
        try:
            # è½¬æ¢ä¸ºHSVè‰²å½©ç©ºé—´
            hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
            h, s, v = cv2.split(hsv)
            
            # å¢å¼ºé¥±å’Œåº¦
            s = cv2.add(s, 10)
            
            # å¹³è¡¡äº®åº¦
            # ä½¿ç”¨ç›´æ–¹å›¾å‡è¡¡åŒ–
            v = cv2.equalizeHist(v)
            
            # é‡æ–°åˆå¹¶HSVé€šé“
            hsv = cv2.merge([h, s, v])
            balanced = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
            
            # ç‰¹åˆ«ä¼˜åŒ–ç†ŠçŒ«çš„é»‘ç™½å¯¹æ¯”
            balanced = self._optimize_panda_black_white_balance(balanced)
            
            return balanced
            
        except Exception as e:
            logger.warning(f"ç†ŠçŒ«é¢œè‰²å¹³è¡¡å¤±è´¥: {str(e)}")
            return image
    
    def _optimize_panda_black_white_balance(self, image: np.ndarray) -> np.ndarray:
        """ä¼˜åŒ–ç†ŠçŒ«é»‘ç™½å¯¹æ¯”å¹³è¡¡"""
        try:
            # è½¬æ¢ä¸ºç°åº¦å›¾
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            
            # è®¡ç®—å›¾åƒçš„æ•´ä½“äº®åº¦
            mean_brightness = np.mean(gray)
            
            # æ ¹æ®æ•´ä½“äº®åº¦è°ƒæ•´å¯¹æ¯”åº¦
            if mean_brightness < 100:  # å›¾åƒåæš—
                # å¢å¼ºäº®åº¦å’Œå¯¹æ¯”åº¦
                enhanced = cv2.convertScaleAbs(image, alpha=1.1, beta=15)
            elif mean_brightness > 150:  # å›¾åƒåäº®
                # é™ä½äº®åº¦ï¼Œå¢å¼ºå¯¹æ¯”åº¦
                enhanced = cv2.convertScaleAbs(image, alpha=1.05, beta=-10)
            else:  # äº®åº¦é€‚ä¸­
                # è½»å¾®å¢å¼ºå¯¹æ¯”åº¦
                enhanced = cv2.convertScaleAbs(image, alpha=1.02, beta=5)
            
            return enhanced
            
        except Exception as e:
            logger.warning(f"ç†ŠçŒ«é»‘ç™½å¹³è¡¡ä¼˜åŒ–å¤±è´¥: {str(e)}")
            return image
    
    def _standard_preprocess(self, image: np.ndarray) -> np.ndarray:
        """æ ‡å‡†å›¾åƒé¢„å¤„ç†"""
        try:
            # æ£€æŸ¥å›¾åƒå°ºå¯¸
            height, width = image.shape[:2]
            
            # å¦‚æœå›¾åƒå¤ªå¤§ï¼Œè¿›è¡Œç¼©æ”¾
            if height > self.config["max_image_size"] or width > self.config["max_image_size"]:
                scale = min(self.config["max_image_size"] / height, self.config["max_image_size"] / width)
                new_height = int(height * scale)
                new_width = int(width * scale)
                image = cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_AREA)
                logger.info(f"å›¾åƒå·²ç¼©æ”¾è‡³: {new_width}x{new_height}")
            
            # å¦‚æœå›¾åƒå¤ªå°ï¼Œè¿›è¡Œæ”¾å¤§
            elif height < self.config["min_image_size"] or width < self.config["min_image_size"]:
                scale = max(self.config["min_image_size"] / height, self.config["min_image_size"] / width)
                new_height = int(height * scale)
                new_width = int(width * scale)
                image = cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_CUBIC)
                logger.info(f"å›¾åƒå·²æ”¾å¤§è‡³: {new_width}x{new_height}")
            
            return image
            
        except Exception as e:
            logger.warning(f"æ ‡å‡†é¢„å¤„ç†å¤±è´¥: {str(e)}")
            return image
    
    def _color_reduction(self, image: np.ndarray, n_colors: int) -> np.ndarray:
        """
        æ™ºèƒ½é¢œè‰²é™è‰²å¤„ç†ï¼Œä¸“é—¨é’ˆå¯¹ç»‡æœºè¯†åˆ«ä¼˜åŒ–
        
        Args:
            image: è¾“å…¥å›¾åƒæ•°ç»„
            n_colors: ç›®æ ‡é¢œè‰²æ•°é‡ï¼ˆå¿…é¡»æ˜¯10,12,14,16,18,20ä¹‹ä¸€ï¼‰
            
        Returns:
            np.ndarray: é¢œè‰²é™è‰²åçš„å›¾åƒæ•°ç»„
        """
        try:
            # éªŒè¯é¢œè‰²æ•°é‡
            allowed_colors = [10, 12, 14, 16, 18, 20]
            if n_colors not in allowed_colors:
                raise ValueError(f"é¢œè‰²æ•°é‡å¿…é¡»æ˜¯ä»¥ä¸‹å€¼ä¹‹ä¸€: {allowed_colors}")
                
            original_shape = image.shape
            
            # å°†å›¾åƒé‡å¡‘ä¸ºåƒç´ å‘é‡
            pixels = image.reshape(-1, 3)
            
            # ä½¿ç”¨K-meansèšç±»è¿›è¡Œé¢œè‰²é™è‰²
            kmeans = KMeans(
                n_clusters=n_colors,
                init='k-means++',
                n_init=20,
                max_iter=300,
                random_state=42,
                algorithm='lloyd'
            )
            
            # æ‰§è¡Œèšç±»
            kmeans.fit(pixels)
            
            # è·å–èšç±»ä¸­å¿ƒï¼ˆä¸»è¦é¢œè‰²ï¼‰
            colors = kmeans.cluster_centers_.astype(np.uint8)
            
            # å°†æ¯ä¸ªåƒç´ æ›¿æ¢ä¸ºæœ€è¿‘çš„èšç±»ä¸­å¿ƒé¢œè‰²
            labels = kmeans.labels_
            reduced_pixels = colors[labels]
            
            # é‡å¡‘å›åŸå§‹å›¾åƒå½¢çŠ¶
            reduced_image = reduced_pixels.reshape(original_shape)
            
            # è®°å½•æå–çš„ä¸»è¦é¢œè‰²
            color_info = [f"RGB({c[0]}, {c[1]}, {c[2]})" for c in colors]
            logger.info(f"é¢œè‰²é™è‰²å®Œæˆï¼Œæå–çš„ä¸»è¦é¢œè‰²: {color_info}")
            
            # ğŸ”§ æ–°å¢ï¼šç»‡æœºè¯†åˆ«ä¸“é¡¹ä¼˜åŒ–
            optimized_image = self._weaving_machine_optimization(reduced_image.astype(np.uint8))
            
            return optimized_image
            
        except Exception as e:
            raise ImageProcessingError(f"é¢œè‰²é™è‰²å¤±è´¥: {str(e)}")
    
    def _weaving_machine_optimization(self, image: np.ndarray) -> np.ndarray:
        """
        ğŸ”§ ç»‡æœºè¯†åˆ«ä¸“é¡¹ä¼˜åŒ–
        
        åŸºäºä¸“ä¸šç»‡æœºè½¯ä»¶çš„ç‰¹ç‚¹ï¼Œä¼˜åŒ–å›¾åƒä½¿å…¶æ›´å®¹æ˜“è¢«ç»‡æœºè¯†åˆ«ï¼š
        1. é¢œè‰²åŒºåŸŸè¿é€šæ€§å¢å¼º
        2. èƒŒæ™¯å™ªç‚¹æ¸…ç†
        3. è¾¹ç¼˜é”åŒ–å¤„ç†
        4. è‰²å½©åŒºåŸŸå¹³æ»‘åŒ–
        
        Args:
            image: é¢œè‰²é™è‰²åçš„å›¾åƒæ•°ç»„
            
        Returns:
            np.ndarray: ç»‡æœºä¼˜åŒ–åçš„å›¾åƒæ•°ç»„
        """
        try:
            logger.info("ğŸ”§ å¼€å§‹ç»‡æœºè¯†åˆ«ä¸“é¡¹ä¼˜åŒ–...")
            
            # 1. é¢œè‰²åŒºåŸŸè¿é€šæ€§å¢å¼º - å‡å°‘é¢—ç²’æ„Ÿ
            smoothed = self._enhance_color_connectivity(image)
            logger.info("âœ“ é¢œè‰²åŒºåŸŸè¿é€šæ€§å¢å¼ºå®Œæˆ")
            
            # 2. èƒŒæ™¯å™ªç‚¹æ¸…ç† - ç®€åŒ–èƒŒæ™¯
            denoised = self._clean_background_noise(smoothed)
            logger.info("âœ“ èƒŒæ™¯å™ªç‚¹æ¸…ç†å®Œæˆ")
            
            # 3. ä¸»ä½“è¾¹ç¼˜é”åŒ– - å¢å¼ºè½®å»“
            edge_enhanced = self._sharpen_main_edges(denoised)
            logger.info("âœ“ ä¸»ä½“è¾¹ç¼˜é”åŒ–å®Œæˆ")
            
            # 4. è‰²å½©åŒºåŸŸå¹³æ»‘åŒ– - å½¢æˆè¿ç»­è‰²å—
            final_optimized = self._smooth_color_regions(edge_enhanced)
            logger.info("âœ“ è‰²å½©åŒºåŸŸå¹³æ»‘åŒ–å®Œæˆ")
            
            logger.info("ğŸ¯ ç»‡æœºè¯†åˆ«ä¸“é¡¹ä¼˜åŒ–å®Œæˆï¼")
            return final_optimized
            
        except Exception as e:
            logger.warning(f"ç»‡æœºä¼˜åŒ–å¤±è´¥ï¼Œä½¿ç”¨åŸå›¾åƒ: {str(e)}")
            return image
    
    def _enhance_color_connectivity(self, image: np.ndarray) -> np.ndarray:
        """
        å¢å¼ºç›¸åŒé¢œè‰²åŒºåŸŸçš„è¿é€šæ€§ï¼Œå‡å°‘é¢—ç²’æ„Ÿ
        """
        try:
            # å¯¹æ¯ä¸ªé¢œè‰²é€šé“åˆ†åˆ«å¤„ç†
            result = image.copy()
            
            # ä½¿ç”¨ä¸­å€¼æ»¤æ³¢å‡å°‘é¢—ç²’æ„Ÿï¼Œä¿æŒè¾¹ç¼˜
            result = cv2.medianBlur(result, 5)
            
            # ä½¿ç”¨é—­è¿ç®—è¿æ¥ç›¸è¿‘çš„åŒè‰²åŒºåŸŸ
            kernel = np.ones((7, 7), np.uint8)
            result = cv2.morphologyEx(result, cv2.MORPH_CLOSE, kernel)
            
            return result
            
        except Exception as e:
            logger.warning(f"é¢œè‰²è¿é€šæ€§å¢å¼ºå¤±è´¥: {str(e)}")
            return image
    
    def _clean_background_noise(self, image: np.ndarray) -> np.ndarray:
        """
        æ¸…ç†èƒŒæ™¯å™ªç‚¹ï¼Œç®€åŒ–èƒŒæ™¯åŒºåŸŸ
        """
        try:
            # 1. è¯†åˆ«ä¸»ä½“åŒºåŸŸï¼ˆå‡è®¾ä¸­å¿ƒåŒºåŸŸä¸ºä¸»ä½“ï¼‰
            height, width = image.shape[:2]
            center_x, center_y = width // 2, height // 2
            
            # åˆ›å»ºæ©ç ï¼šä¸­å¿ƒåŒºåŸŸä¸ºä¸»ä½“
            mask = np.zeros((height, width), dtype=np.uint8)
            cv2.ellipse(mask, (center_x, center_y), (width//3, height//3), 0, 0, 360, 255, -1)
            
            # 2. èƒŒæ™¯åŒºåŸŸé™å™ªå¤„ç†
            background_smoothed = cv2.GaussianBlur(image, (15, 15), 5.0)
            
            # 3. ä¸»ä½“åŒºåŸŸä¿æŒåŸæ ·ï¼ŒèƒŒæ™¯åŒºåŸŸä½¿ç”¨å¹³æ»‘ç‰ˆæœ¬
            result = image.copy()
            mask_3d = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR) / 255.0
            result = (image * mask_3d + background_smoothed * (1 - mask_3d)).astype(np.uint8)
            
            return result
            
        except Exception as e:
            logger.warning(f"èƒŒæ™¯å™ªç‚¹æ¸…ç†å¤±è´¥: {str(e)}")
            return image
    
    def _sharpen_main_edges(self, image: np.ndarray) -> np.ndarray:
        """
        é”åŒ–ä¸»ä½“è¾¹ç¼˜ï¼Œå¢å¼ºè½®å»“æ¸…æ™°åº¦
        """
        try:
            # 1. è¾¹ç¼˜æ£€æµ‹
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            edges = cv2.Canny(gray, 50, 150)
            
            # 2. åˆ›å»ºé”åŒ–æ ¸
            kernel_sharpen = np.array([
                [-1, -1, -1],
                [-1,  9, -1],
                [-1, -1, -1]
            ])
            
            # 3. åº”ç”¨é”åŒ–
            sharpened = cv2.filter2D(image, -1, kernel_sharpen)
            
            # 4. åœ¨è¾¹ç¼˜åŒºåŸŸåº”ç”¨æ›´å¼ºçš„é”åŒ–
            edges_3d = cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR) / 255.0
            result = (image * (1 - edges_3d) + sharpened * edges_3d).astype(np.uint8)
            
            return result
            
        except Exception as e:
            logger.warning(f"è¾¹ç¼˜é”åŒ–å¤±è´¥: {str(e)}")
            return image
    
    def _smooth_color_regions(self, image: np.ndarray) -> np.ndarray:
        """
        å¹³æ»‘ç›¸åŒé¢œè‰²çš„åŒºåŸŸï¼Œå½¢æˆè¿ç»­çš„è‰²å—
        """
        try:
            # 1. è·å–æ‰€æœ‰å”¯ä¸€é¢œè‰²
            unique_colors = self._get_unique_colors(image)
            
            # 2. å¯¹æ¯ä¸ªé¢œè‰²åŒºåŸŸè¿›è¡Œå¹³æ»‘å¤„ç†
            result = image.copy()
            
            for color in unique_colors:
                # åˆ›å»ºå½“å‰é¢œè‰²çš„æ©ç 
                mask = cv2.inRange(image, 
                                 np.array(color) - 5,  # å…è®¸å°å¹…é¢œè‰²å˜åŒ–
                                 np.array(color) + 5)
                
                # å¯¹æ©ç åŒºåŸŸè¿›è¡Œå½¢æ€å­¦é—­è¿ç®—
                kernel = np.ones((9, 9), np.uint8)
                mask_closed = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)
                
                # å¡«å……è¯¥é¢œè‰²åŒºåŸŸ
                result[mask_closed > 0] = color
            
            # 3. æœ€ç»ˆå¹³æ»‘å¤„ç†
            final = cv2.bilateralFilter(result, 9, 80, 80)
            
            return final
            
        except Exception as e:
            logger.warning(f"è‰²å½©åŒºåŸŸå¹³æ»‘åŒ–å¤±è´¥: {str(e)}")
            return image
    
    def _enhance_edges(self, image: np.ndarray) -> np.ndarray:
        """
        å¤šå±‚æ¬¡è¾¹ç¼˜å¢å¼ºå¤„ç†
        
        Args:
            image: è¾“å…¥å›¾åƒæ•°ç»„
            
        Returns:
            np.ndarray: è¾¹ç¼˜å¢å¼ºåçš„å›¾åƒæ•°ç»„
        """
        try:
            # è½¬æ¢ä¸ºPILå›¾åƒè¿›è¡Œé«˜è´¨é‡æ»¤é•œå¤„ç†
            pil_image = Image.fromarray(image)
            
            # å¤šé˜¶æ®µè¾¹ç¼˜å¢å¼º
            # 1. è½»åº¦é”åŒ–
            enhanced = pil_image.filter(ImageFilter.SHARPEN)
            
            # 2. è¾¹ç¼˜å¢å¼º
            enhanced = enhanced.filter(ImageFilter.EDGE_ENHANCE_MORE)
            
            # 3. ç»†èŠ‚å¢å¼º
            enhanced = enhanced.filter(ImageFilter.DETAIL)
            
            # 4. å¯¹æ¯”åº¦å¾®è°ƒ
            enhancer = ImageEnhance.Contrast(enhanced)
            enhanced = enhancer.enhance(1.15)
            
            # 5. æ¸…æ™°åº¦å¢å¼º
            enhancer = ImageEnhance.Sharpness(enhanced)
            enhanced = enhancer.enhance(1.1)
            
            return np.array(enhanced)
            
        except Exception as e:
            raise ImageProcessingError(f"è¾¹ç¼˜å¢å¼ºå¤±è´¥: {str(e)}")
    
    def _noise_reduction(self, image: np.ndarray) -> np.ndarray:
        """
        é«˜çº§å™ªå£°æ¸…ç†å’Œå¹³æ»‘å¤„ç†
        
        Args:
            image: è¾“å…¥å›¾åƒæ•°ç»„
            
        Returns:
            np.ndarray: é™å™ªåçš„å›¾åƒæ•°ç»„
        """
        try:
            # 1. åŒè¾¹æ»¤æ³¢ï¼ˆä¿è¾¹é™å™ªï¼‰
            denoised = cv2.bilateralFilter(image, 9, 75, 75)
            
            # 2. å½¢æ€å­¦æ“ä½œ
            kernel = np.ones(self.config["morphology_kernel_size"], np.uint8)
            
            # å¼€è¿ç®—ï¼ˆå»é™¤å°å™ªç‚¹ï¼‰
            opened = cv2.morphologyEx(denoised, cv2.MORPH_OPEN, kernel)
            
            # é—­è¿ç®—ï¼ˆå¡«å……å°ç©ºæ´ï¼‰
            closed = cv2.morphologyEx(opened, cv2.MORPH_CLOSE, kernel)
            
            # 3. è½»åº¦é«˜æ–¯æ¨¡ç³Šï¼ˆæœ€ç»ˆå¹³æ»‘ï¼‰
            final = cv2.GaussianBlur(closed, self.config["gaussian_kernel_size"], 0.5)
            
            return final
            
        except Exception as e:
            raise ImageProcessingError(f"å™ªå£°æ¸…ç†å¤±è´¥: {str(e)}")
    
    def _apply_sichuan_style(self, image: np.ndarray) -> np.ndarray:
        """
        åº”ç”¨èœ€é”¦èœ€ç»£ä¼ ç»Ÿé£æ ¼å¤„ç†
        
        Args:
            image: è¾“å…¥å›¾åƒæ•°ç»„
            
        Returns:
            np.ndarray: é£æ ¼åŒ–åçš„å›¾åƒæ•°ç»„
        """
        try:
            # è½¬æ¢ä¸ºPILå›¾åƒè¿›è¡Œç²¾ç»†è°ƒæ•´
            pil_image = Image.fromarray(image)
            
            # 1. é¥±å’Œåº¦è°ƒæ•´ï¼ˆèœ€é”¦è‰²å½©ä¸°å¯Œé¥±æ»¡ï¼‰
            enhancer = ImageEnhance.Color(pil_image)
            enhanced = enhancer.enhance(1.25)
            
            # 2. å¯¹æ¯”åº¦è°ƒæ•´ï¼ˆå¢å¼ºå±‚æ¬¡æ„Ÿï¼‰
            enhancer = ImageEnhance.Contrast(enhanced)
            enhanced = enhancer.enhance(1.1)
            
            # 3. äº®åº¦å¾®è°ƒï¼ˆä¼ ç»Ÿç»‡ç‰©å…‰æ³½æ„Ÿï¼‰
            enhancer = ImageEnhance.Brightness(enhanced)
            enhanced = enhancer.enhance(1.02)
            
            # 4. è‰²å½©å¹³è¡¡è°ƒæ•´ï¼ˆæš–è‰²è°ƒå€¾å‘ï¼‰
            enhanced = self._adjust_color_balance(enhanced)
            
            return np.array(enhanced)
            
        except Exception as e:
            raise ImageProcessingError(f"é£æ ¼åŒ–å¤„ç†å¤±è´¥: {str(e)}")
    
    def _embroidery_quality_enhancement(self, image: np.ndarray) -> np.ndarray:
        """
        åˆºç»£å“è´¨ä¸“é¡¹ä¼˜åŒ–
        
        ä¸“é—¨é’ˆå¯¹åˆºç»£å·¥è‰ºéœ€æ±‚çš„å›¾åƒä¼˜åŒ–ï¼Œç¡®ä¿çº¿æ¡æ¸…æ™°ã€é¢œè‰²è¾¹ç•Œåˆ†æ˜
        
        Args:
            image: è¾“å…¥å›¾åƒæ•°ç»„
            
        Returns:
            np.ndarray: åˆºç»£ä¼˜åŒ–åçš„å›¾åƒæ•°ç»„
        """
        try:
            height, width = image.shape[:2]
            
            # è½¬æ¢ä¸ºPILå›¾åƒ
            pil_image = Image.fromarray(image)
            
            # 1. é’ˆå¯¹é«˜åˆ†è¾¨ç‡å›¾åƒçš„ç‰¹æ®Šå¤„ç†
            if width >= 1920 or height >= 1920:
                logger.info("åº”ç”¨é«˜åˆ†è¾¨ç‡åˆºç»£ä¼˜åŒ–")
                
                # è¶…é”åŒ–å¤„ç† - æå‡çº¿æ¡æ¸…æ™°åº¦
                enhancer = ImageEnhance.Sharpness(pil_image)
                pil_image = enhancer.enhance(1.5)
                
                # å¯¹æ¯”åº¦å¢å¼º - è®©é¢œè‰²è¾¹ç•Œæ›´åˆ†æ˜
                enhancer = ImageEnhance.Contrast(pil_image)
                pil_image = enhancer.enhance(1.3)
                
            else:
                logger.info("åº”ç”¨æ ‡å‡†åˆºç»£ä¼˜åŒ–")
                
                # æ ‡å‡†é”åŒ–
                enhancer = ImageEnhance.Sharpness(pil_image)
                pil_image = enhancer.enhance(1.3)
                
                # é€‚åº¦å¯¹æ¯”åº¦å¢å¼º
                enhancer = ImageEnhance.Contrast(pil_image)
                pil_image = enhancer.enhance(1.2)
            
            # 2. é¢œè‰²è¾¹ç•Œé”åŒ–ï¼ˆé’ˆå¯¹æ‰€æœ‰å°ºå¯¸ï¼‰
            image_array = np.array(pil_image)
            
            # ä½¿ç”¨å½¢æ€å­¦æ¢¯åº¦å¢å¼ºè¾¹ç•Œ
            kernel = np.ones((2, 2), np.uint8)
            gradient = cv2.morphologyEx(image_array, cv2.MORPH_GRADIENT, kernel)
            
            # å°†æ¢¯åº¦ä¿¡æ¯å åŠ åˆ°åŸå›¾åƒ
            enhanced = cv2.addWeighted(image_array, 0.85, gradient, 0.15, 0)
            
            # 3. æœ€ç»ˆè´¨é‡æå‡
            final_pil = Image.fromarray(enhanced)
            
            # å¾®è°ƒäº®åº¦ç¡®ä¿åˆºç»£å¯¹æ¯”åº¦
            enhancer = ImageEnhance.Brightness(final_pil)
            final_pil = enhancer.enhance(1.05)
            
            pixels = width * height
            logger.info(f"âœ¨ åˆºç»£å“è´¨ä¼˜åŒ–å®Œæˆ - {width}x{height} ({pixels:,} åƒç´ )")
            
            return np.array(final_pil)
            
        except Exception as e:
            logger.warning(f"åˆºç»£å“è´¨ä¼˜åŒ–å¤±è´¥ï¼Œä½¿ç”¨åŸå›¾åƒ: {str(e)}")
            return image
    
    def _adjust_color_balance(self, pil_image: Image.Image) -> Image.Image:
        """
        è°ƒæ•´è‰²å½©å¹³è¡¡ï¼Œå¢å¼ºèœ€é”¦ä¼ ç»Ÿè‰²å½©ç‰¹å¾
        
        Args:
            pil_image: PILå›¾åƒå¯¹è±¡
            
        Returns:
            Image.Image: è‰²å½©å¹³è¡¡è°ƒæ•´åçš„å›¾åƒ
        """
        try:
            # è½¬æ¢ä¸ºnumpyæ•°ç»„è¿›è¡Œç²¾ç»†è°ƒæ•´
            image_array = np.array(pil_image).astype(np.float32)
            
            # å¢å¼ºçº¢è‰²å’Œé‡‘è‰²é€šé“ï¼ˆèœ€é”¦ä¼ ç»Ÿè‰²å½©ï¼‰
            image_array[:, :, 0] *= 1.05  # çº¢è‰²é€šé“
            image_array[:, :, 1] *= 1.02  # ç»¿è‰²é€šé“
            image_array[:, :, 2] *= 0.98  # è“è‰²é€šé“
            
            # ç¡®ä¿å€¼åœ¨æœ‰æ•ˆèŒƒå›´å†…
            image_array = np.clip(image_array, 0, 255)
            
            return Image.fromarray(image_array.astype(np.uint8))
            
        except Exception as e:
            logger.warning(f"è‰²å½©å¹³è¡¡è°ƒæ•´å¤±è´¥ï¼Œä½¿ç”¨åŸå›¾åƒ: {str(e)}")
            return pil_image
    
    def _save_high_quality_png(self, image: np.ndarray, output_path: str):
        """
        ä¿å­˜è¶…é«˜è´¨é‡PNGæ–‡ä»¶ - åˆºç»£ä¸“ç”¨ç‰ˆ
        
        Args:
            image: å›¾åƒæ•°ç»„
            output_path: è¾“å‡ºè·¯å¾„
        """
        try:
            pil_image = Image.fromarray(image)
            height, width = image.shape[:2]
            
            # è¶…é«˜è´¨é‡PNGä¿å­˜è®¾ç½®ï¼ˆåˆºç»£ä¸“ç”¨ï¼‰
            save_kwargs = {
                'format': 'PNG',
                'optimize': False,  # ç¦ç”¨ä¼˜åŒ–ä»¥ä¿æŒæœ€é«˜è´¨é‡
                'compress_level': self.config["compression_level"],  # 0 = æ— å‹ç¼©
                'pnginfo': self._create_png_metadata()
            }
            
            # å¯¹äºé«˜åˆ†è¾¨ç‡å›¾åƒï¼Œè¿›ä¸€æ­¥ä¼˜åŒ–
            if width >= 1920 or height >= 1920:
                # é«˜åˆ†è¾¨ç‡å›¾åƒä½¿ç”¨æœ€ä½³è®¾ç½®
                save_kwargs['optimize'] = False
                save_kwargs['compress_level'] = 0
                logger.info(f"ä½¿ç”¨è¶…é«˜è´¨é‡è®¾ç½®ä¿å­˜é«˜åˆ†è¾¨ç‡å›¾åƒ: {width}x{height}")
            
            pil_image.save(output_path, **save_kwargs)
            
            # éªŒè¯æ–‡ä»¶ä¿å­˜å¹¶æŠ¥å‘Šè¯¦ç»†ä¿¡æ¯
            if not Path(output_path).exists():
                raise ImageProcessingError("PNGæ–‡ä»¶ä¿å­˜å¤±è´¥")
            
            file_size = Path(output_path).stat().st_size
            pixels = width * height
            size_per_pixel = file_size / pixels if pixels > 0 else 0
            
            logger.info(f"ğŸ¨ åˆºç»£ä¸“ç”¨PNGå·²ä¿å­˜: {Path(output_path).name}")
            logger.info(f"ğŸ“ åˆ†è¾¨ç‡: {width}x{height} ({pixels:,} åƒç´ )")
            logger.info(f"ğŸ’¾ æ–‡ä»¶å¤§å°: {file_size:,} bytes ({file_size/1024/1024:.2f} MB)")
            logger.info(f"ğŸ” åƒç´ å¯†åº¦: {size_per_pixel:.2f} bytes/pixel")
            
        except Exception as e:
            raise ImageProcessingError(f"PNGä¿å­˜å¤±è´¥: {str(e)}")
    
    def _create_png_metadata(self) -> Optional[object]:
        """åˆ›å»ºPNGå…ƒæ•°æ®"""
        try:
            from PIL.PngImagePlugin import PngInfo
            metadata = PngInfo()
            metadata.add_text("Software", "èœ€é”¦èœ€ç»£AIæ‰“æ ·å›¾ç”Ÿæˆå·¥å…·")
            metadata.add_text("Description", "Professional Sichuan Brocade Pattern")
            metadata.add_text("Creation Time", time.strftime("%Y-%m-%d %H:%M:%S"))
            return metadata
        except ImportError:
            return None
    
    def _generate_svg(self, image: np.ndarray, output_path: str):
        """
        ç”Ÿæˆç®€åŒ–SVGçŸ¢é‡æ–‡ä»¶
        
        Args:
            image: å›¾åƒæ•°ç»„
            output_path: è¾“å‡ºè·¯å¾„
        """
        try:
            # ç›´æ¥åˆ›å»ºç®€å•çš„å ä½SVGï¼Œé¿å…å¤æ‚è®¡ç®—
            height, width = image.shape[:2]
            self._create_fallback_svg(output_path, (height, width))
            logger.info(f"SVGæ–‡ä»¶å·²ç”Ÿæˆ: {output_path}")
            
        except Exception as e:
            # SVGç”Ÿæˆå¤±è´¥ä¸å½±å“ä¸»æµç¨‹ï¼Œè®°å½•è­¦å‘Š
            logger.warning(f"SVGç”Ÿæˆå¤±è´¥: {str(e)}")
            # ç¡®ä¿æœ‰ä¸€ä¸ªå ä½æ–‡ä»¶
            try:
                self._create_fallback_svg(output_path, image.shape[:2])
            except Exception:
                logger.error("è¿å ä½SVGéƒ½æ— æ³•åˆ›å»º")
    
    def _create_color_mask(self, image: np.ndarray, target_color: tuple, width: int, height: int) -> List[Dict[str, int]]:
        """
        ä¸ºæŒ‡å®šé¢œè‰²åˆ›å»ºçŸ©å½¢é®ç½©
        
        Args:
            image: å›¾åƒæ•°ç»„
            target_color: ç›®æ ‡é¢œè‰²
            width: å›¾åƒå®½åº¦
            height: å›¾åƒé«˜åº¦
            
        Returns:
            List[Dict]: çŸ©å½¢æ•°æ®åˆ—è¡¨
        """
        try:
            # åˆ›å»ºé¢œè‰²é®ç½©
            mask = np.all(image == target_color, axis=2)
            
            # ç®€åŒ–å¤„ç†ï¼šåˆ›å»ºåŸºæœ¬çŸ©å½¢åŒºåŸŸ
            rects = []
            if np.any(mask):
                y_indices, x_indices = np.where(mask)
                if len(x_indices) > 0 and len(y_indices) > 0:
                    min_x, max_x = int(np.min(x_indices)), int(np.max(x_indices))
                    min_y, max_y = int(np.min(y_indices)), int(np.max(y_indices))
                    
                    rects.append({
                        'x': min_x,
                        'y': min_y,
                        'width': max_x - min_x + 1,
                        'height': max_y - min_y + 1
                    })
            
            return rects
            
        except Exception as e:
            logger.warning(f"é¢œè‰²é®ç½©åˆ›å»ºå¤±è´¥: {str(e)}")
            return []
    
    def _create_fallback_svg(self, output_path: str, image_shape: tuple):
        """åˆ›å»ºç®€å•çš„å¤‡ç”¨SVGæ–‡ä»¶"""
        try:
            height, width = image_shape
            
            svg_content = f'''<?xml version="1.0" encoding="UTF-8"?>
<svg width="{width}" height="{height}" viewBox="0 0 {width} {height}" xmlns="http://www.w3.org/2000/svg">
    <metadata>èœ€é”¦èœ€ç»£AIæ‰“æ ·å›¾ç”Ÿæˆå·¥å…·</metadata>
    <title>Sichuan Brocade Pattern (Simplified)</title>
    <rect width="{width}" height="{height}" fill="#f0f0f0"/>
    <text x="{width//2}" y="{height//2}" text-anchor="middle" font-family="Arial" font-size="16" fill="#666">
        Sichuan Brocade Pattern
    </text>
</svg>'''
            
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(svg_content)
                
        except Exception as e:
            logger.error(f"å¤‡ç”¨SVGåˆ›å»ºå¤±è´¥: {str(e)}")
    
    def _get_unique_colors(self, image: np.ndarray) -> List[Tuple[int, int, int]]:
        """
        è·å–å›¾åƒä¸­çš„å”¯ä¸€é¢œè‰²
        
        Args:
            image: å›¾åƒæ•°ç»„
            
        Returns:
            List[Tuple]: å”¯ä¸€é¢œè‰²åˆ—è¡¨
        """
        try:
            # é‡å¡‘å›¾åƒå¹¶è·å–å”¯ä¸€é¢œè‰²
            pixels = image.reshape(-1, 3)
            unique_colors = np.unique(pixels, axis=0)
            
            # æŒ‰é¢œè‰²å‡ºç°é¢‘ç‡æ’åº
            color_counts = []
            for color in unique_colors:
                count = np.sum(np.all(pixels == color, axis=1))
                color_counts.append((count, tuple(color)))
            
            # æŒ‰é¢‘ç‡é™åºæ’åº
            color_counts.sort(reverse=True)
            
            return [color for _, color in color_counts]
            
        except Exception as e:
            logger.warning(f"è·å–å”¯ä¸€é¢œè‰²å¤±è´¥: {str(e)}")
            return []
    
    def _optimize_panda_contrast(self, image: np.ndarray) -> np.ndarray:
        """ä¼˜åŒ–ç†ŠçŒ«å›¾åƒçš„å¯¹æ¯”åº¦"""
        try:
            # è½¬æ¢ä¸ºç°åº¦å›¾
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            
            # æ£€æµ‹å¹¶å¢å¼ºé»‘è‰²åŒºåŸŸ
            black_mask = gray < 80
            if np.sum(black_mask) > 0:
                image[black_mask] = [0, 0, 0]
            
            # æ£€æµ‹å¹¶å¢å¼ºç™½è‰²åŒºåŸŸ
            white_mask = gray > 180
            if np.sum(white_mask) > 0:
                image[white_mask] = [255, 255, 255]
            
            return image
            
        except Exception as e:
            logger.warning(f"ç†ŠçŒ«å¯¹æ¯”åº¦ä¼˜åŒ–å¤±è´¥: {str(e)}")
            return image
    
    def _enhance_panda_chin_area(self, image: np.ndarray) -> np.ndarray:
        """å¢å¼ºç†ŠçŒ«ä¸‹å·´/é¢ˆéƒ¨åŒºåŸŸ"""
        try:
            height, width = image.shape[:2]
            
            # å®šä¹‰ä¸‹å·´/é¢ˆéƒ¨åŒºåŸŸï¼ˆå›¾åƒä¸‹åŠéƒ¨åˆ†ï¼‰
            chin_region = image[height//2:, :]
            
            # è½¬æ¢ä¸ºLABè‰²å½©ç©ºé—´
            lab = cv2.cvtColor(chin_region, cv2.COLOR_BGR2LAB)
            l, a, b = cv2.split(lab)
            
            # å¢å¼ºä¸‹å·´åŒºåŸŸçš„å¯¹æ¯”åº¦
            clahe = cv2.createCLAHE(clipLimit=1.5, tileGridSize=(4, 4))
            l = clahe.apply(l)
            
            # è½»å¾®å¢å¼ºé¥±å’Œåº¦
            a = cv2.add(a, 3)
            b = cv2.add(b, 3)
            
            # é‡æ–°åˆå¹¶é€šé“
            lab = cv2.merge([l, a, b])
            enhanced_chin = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)
            
            # å°†å¢å¼ºåçš„åŒºåŸŸæ”¾å›åŸå›¾
            image[height//2:, :] = enhanced_chin
            
            return image
            
        except Exception as e:
            logger.warning(f"ç†ŠçŒ«ä¸‹å·´åŒºåŸŸå¢å¼ºå¤±è´¥: {str(e)}")
            return image
    
    def get_processing_info(self) -> Dict[str, Any]:
        """
        è·å–å¤„ç†å™¨ä¿¡æ¯
        
        Returns:
            Dict: å¤„ç†å™¨é…ç½®å’ŒçŠ¶æ€ä¿¡æ¯
        """
        return {
            "processor_version": "2.0.0",
            "output_directory": str(self.outputs_dir),
            "configuration": self.config.copy(),
            "supported_formats": ["JPEG", "PNG"],
            "max_concurrent_jobs": 10,
            "features": [
                "æ™ºèƒ½å°ºå¯¸è°ƒæ•´ï¼ˆæ”¯æŒ4Kåˆ†è¾¨ç‡ï¼‰",
                "å°å›¾åƒæ™ºèƒ½æ”¾å¤§",
                "é«˜åˆ†è¾¨ç‡å›¾åƒä¿æŠ¤",
                "é¢œè‰²èšç±»é™è‰²",
                "è¾¹ç¼˜å¢å¼ºå¤„ç†", 
                "å™ªå£°æ¸…ç†ä¼˜åŒ–",
                "èœ€é”¦é£æ ¼åŒ–",
                "åˆºç»£å“è´¨ä¸“é¡¹ä¼˜åŒ–",
                "è¶…é«˜è´¨é‡PNGè¾“å‡ºï¼ˆæ— å‹ç¼©ï¼‰",
                "SVGçŸ¢é‡ç”Ÿæˆ"
            ]
        } 

    def smooth_boundary(self, mask: np.ndarray, kernel_size: int = 5) -> np.ndarray:
        """è¾¹ç•Œå¹³æ»‘ï¼šé«˜æ–¯æ¨¡ç³Š+è‡ªé€‚åº”é˜ˆå€¼+å½¢æ€å­¦æ“ä½œ"""
        blurred = cv2.GaussianBlur(mask, (kernel_size, kernel_size), 0)
        _, thresh = cv2.threshold(blurred, 127, 255, cv2.THRESH_BINARY)
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
        opened = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)
        closed = cv2.morphologyEx(opened, cv2.MORPH_CLOSE, kernel)
        return closed

    def superpixel_segment(self, image: np.ndarray, mask: np.ndarray = None, n_segments: int = 400) -> np.ndarray:
        """è¶…åƒç´ åˆ†å‰²ï¼ˆSLICï¼‰"""
        try:
            from skimage.segmentation import slic
            from skimage.util import img_as_float
            img_float = img_as_float(image)
            segments = slic(img_float, n_segments=n_segments, mask=mask, start_label=1)
            return segments.astype(np.int32)
        except ImportError:
            raise ImportError("è¯·å®‰è£…scikit-imageä»¥ä½¿ç”¨è¶…åƒç´ åˆ†å‰²åŠŸèƒ½")

    def color_quantize(self, image: np.ndarray, n_colors: int = 20) -> Tuple[np.ndarray, List[Tuple[int, int, int]]]:
        """è‰²å½©èšç±»ï¼ˆK-meansï¼‰ï¼Œè¿”å›é‡åŒ–å›¾åƒå’Œè‰²è¡¨"""
        Z = image.reshape((-1, 3)).astype(np.float32)
        criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 20, 1.0)
        K = min(n_colors, len(Z))
        _, labels, centers = cv2.kmeans(Z, K, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)
        centers = np.uint8(centers)
        quantized = centers[labels.flatten()].reshape(image.shape)
        color_table = [tuple(map(int, c)) for c in centers]
        return quantized, color_table

    def export_color_table(self, color_table: List[Tuple[int, int, int]], file_path: str = "color_table.csv"):
        """å¯¼å‡ºè‰²è¡¨ä¸ºCSVæ–‡ä»¶"""
        import csv
        with open(file_path, 'w', newline='') as csvfile:
            writer = csv.writer(csvfile)
            writer.writerow(['Index', 'R', 'G', 'B'])
            for idx, (r, g, b) in enumerate(color_table):
                writer.writerow([idx, r, g, b]) 