#!/usr/bin/env python3
"""
ä¼˜åŒ–ä¸“ä¸šç»‡æœºè¯†åˆ«å›¾åƒç”Ÿæˆå™¨
åŸºäºæç®€ç‰ˆæœ¬ï¼Œè¿›ä¸€æ­¥æå‡ç»“æ„ç›¸ä¼¼æ€§å’Œä¸“ä¸šæ•ˆæœ
"""

import os
import cv2
import numpy as np
from PIL import Image, ImageEnhance
from sklearn.cluster import KMeans
import logging
from typing import Tuple
import time

logger = logging.getLogger(__name__)

class OptimizedProfessionalGenerator:
    """ä¼˜åŒ–ä¸“ä¸šç»‡æœºè¯†åˆ«å›¾åƒç”Ÿæˆå™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–"""
        self.config = {
            # ä¼˜åŒ–é…ç½®ï¼Œç¡®ä¿ç»“æ„ä¿æŒçš„åŒæ—¶è¾¾åˆ°ä¸“ä¸šæ•ˆæœ
            "color_count": 12,          # å¢åŠ åˆ°12ç§é¢œè‰²ï¼Œä¿æŒæ›´å¤šç»†èŠ‚
            "saturation_boost": 2.0,    # 2.0å€é¥±å’Œåº¦
            "contrast_boost": 1.6,      # 1.6å€å¯¹æ¯”åº¦
            "edge_enhancement": 1.5,    # é€‚åº¦è¾¹ç¼˜å¢å¼º
            "structure_preservation": 0.7,  # ç»“æ„ä¿æŒæƒé‡
        }
        logger.info("ä¼˜åŒ–ä¸“ä¸šç»‡æœºç”Ÿæˆå™¨å·²åˆå§‹åŒ–")
    
    def generate_professional_image(self, input_path: str, job_id: str) -> Tuple[str, str, float]:
        """ç”Ÿæˆä¸“ä¸šç»‡æœºè¯†åˆ«å›¾åƒ - ä¼˜åŒ–ç‰ˆæœ¬"""
        start_time = time.time()
        
        try:
            # 1. åŠ è½½åŸå›¾
            image = self._load_image(input_path)
            logger.info(f"åŸå›¾å°ºå¯¸: {image.shape}")
            
            # 2. ä¼˜åŒ–ä¸“ä¸šå¤„ç†æµæ°´çº¿
            professional_image = self._optimized_professional_pipeline(image)
            
            # 3. ä¿å­˜ç»“æœ
            output_dir = f"outputs/{job_id}"
            os.makedirs(output_dir, exist_ok=True)
            
            professional_path = os.path.join(output_dir, f"{job_id}_optimized_professional.png")
            comparison_path = os.path.join(output_dir, f"{job_id}_optimized_comparison.png")
            
            # ä¿å­˜ä¸“ä¸šå›¾åƒ
            self._save_image(professional_image, professional_path)
            
            # åˆ›å»ºå¯¹æ¯”å›¾
            comparison = self._create_comparison(image, professional_image)
            self._save_image(comparison, comparison_path)
            
            processing_time = time.time() - start_time
            logger.info(f"ä¼˜åŒ–ä¸“ä¸šå›¾åƒç”Ÿæˆå®Œæˆï¼Œè€—æ—¶: {processing_time:.2f}ç§’")
            
            return professional_path, comparison_path, processing_time
            
        except Exception as e:
            raise Exception(f"ä¼˜åŒ–ä¸“ä¸šå›¾åƒç”Ÿæˆå¤±è´¥: {str(e)}")
    
    def _load_image(self, input_path: str) -> np.ndarray:
        """åŠ è½½å›¾åƒ"""
        image = cv2.imread(input_path)
        if image is None:
            raise ValueError(f"æ— æ³•åŠ è½½å›¾åƒ: {input_path}")
        return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    def _optimized_professional_pipeline(self, image: np.ndarray) -> np.ndarray:
        """ä¼˜åŒ–ä¸“ä¸šå¤„ç†æµæ°´çº¿"""
        try:
            logger.info("å¼€å§‹ä¼˜åŒ–ä¸“ä¸šå¤„ç†...")
            
            # ä¿å­˜åŸå›¾ç”¨äºç»“æ„ä¿æŒ
            original = image.copy()
            
            # ç¬¬1æ­¥ï¼šæ™ºèƒ½é¢œè‰²é‡åŒ–ï¼ˆä¿æŒç»“æ„ï¼‰
            quantized = self._structure_preserving_quantization(image)
            logger.info("  âœ“ ç»“æ„ä¿æŒé¢œè‰²é‡åŒ–å®Œæˆ")
            
            # ç¬¬2æ­¥ï¼šä¸“ä¸šè‰²å½©å¢å¼º
            enhanced = self._professional_color_enhancement(quantized)
            logger.info("  âœ“ ä¸“ä¸šè‰²å½©å¢å¼ºå®Œæˆ")
            
            # ç¬¬3æ­¥ï¼šæ™ºèƒ½è¾¹ç¼˜å¢å¼ºï¼ˆä¸ç ´åç»“æ„ï¼‰
            sharpened = self._intelligent_edge_enhancement(enhanced, original)
            logger.info("  âœ“ æ™ºèƒ½è¾¹ç¼˜å¢å¼ºå®Œæˆ")
            
            # ç¬¬4æ­¥ï¼šç»“æ„ä¿æŒèåˆ
            final_result = self._structure_preserving_blend(original, sharpened)
            logger.info("  âœ“ ç»“æ„ä¿æŒèåˆå®Œæˆ")
            
            return final_result
            
        except Exception as e:
            raise Exception(f"ä¼˜åŒ–ä¸“ä¸šå¤„ç†å¤±è´¥: {str(e)}")
    
    def _structure_preserving_quantization(self, image: np.ndarray) -> np.ndarray:
        """ç»“æ„ä¿æŒé¢œè‰²é‡åŒ–"""
        try:
            # æ£€æµ‹è¾¹ç¼˜åŒºåŸŸ
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
            edges = cv2.Canny(gray, 30, 100)
            
            # åˆ›å»ºè¾¹ç¼˜æ©ç 
            edge_mask = cv2.dilate(edges, np.ones((3, 3), np.uint8), iterations=1)
            
            # åˆ†åˆ«å¤„ç†è¾¹ç¼˜åŒºåŸŸå’Œéè¾¹ç¼˜åŒºåŸŸ
            edge_pixels = image[edge_mask > 0]
            non_edge_pixels = image[edge_mask == 0]
            
            # å¯¹éè¾¹ç¼˜åŒºåŸŸè¿›è¡Œé¢œè‰²é‡åŒ–
            if len(non_edge_pixels) > 0:
                pixels = non_edge_pixels.reshape(-1, 3)
                
                kmeans = KMeans(
                    n_clusters=min(self.config["color_count"], len(pixels)),
                    init='k-means++',
                    n_init=20,
                    max_iter=300,
                    random_state=42
                )
                
                kmeans.fit(pixels)
                colors = kmeans.cluster_centers_.astype(np.uint8)
                labels = kmeans.labels_
                quantized_pixels = colors[labels]
                
                # é‡å»ºå›¾åƒ
                result = image.copy()
                result[edge_mask == 0] = quantized_pixels.reshape(-1, 3)
                
                # è¾¹ç¼˜åŒºåŸŸä¿æŒåŸå§‹é¢œè‰²ä½†åšè½»å¾®è°ƒæ•´
                if len(edge_pixels) > 0:
                    # å¯¹è¾¹ç¼˜åŒºåŸŸåšè½»å¾®çš„é¢œè‰²è°ƒæ•´ï¼Œä½¿å…¶ä¸é‡åŒ–åçš„é¢œè‰²åè°ƒ
                    edge_enhanced = self._adjust_edge_colors(edge_pixels, colors)
                    result[edge_mask > 0] = edge_enhanced
                
                return result
            else:
                return image
            
        except Exception as e:
            logger.warning(f"ç»“æ„ä¿æŒé¢œè‰²é‡åŒ–å¤±è´¥: {str(e)}")
            return image
    
    def _adjust_edge_colors(self, edge_pixels: np.ndarray, palette_colors: np.ndarray) -> np.ndarray:
        """è°ƒæ•´è¾¹ç¼˜é¢œè‰²ä½¿å…¶ä¸è°ƒè‰²æ¿åè°ƒ"""
        try:
            adjusted_pixels = []
            
            for pixel in edge_pixels:
                # æ‰¾åˆ°æœ€æ¥è¿‘çš„è°ƒè‰²æ¿é¢œè‰²
                distances = np.sum((palette_colors - pixel) ** 2, axis=1)
                closest_color = palette_colors[np.argmin(distances)]
                
                # æ··åˆåŸå§‹é¢œè‰²å’Œæœ€æ¥è¿‘çš„è°ƒè‰²æ¿é¢œè‰²
                adjusted_pixel = (pixel * 0.7 + closest_color * 0.3).astype(np.uint8)
                adjusted_pixels.append(adjusted_pixel)
            
            return np.array(adjusted_pixels)
            
        except Exception as e:
            logger.warning(f"è¾¹ç¼˜é¢œè‰²è°ƒæ•´å¤±è´¥: {str(e)}")
            return edge_pixels
    
    def _professional_color_enhancement(self, image: np.ndarray) -> np.ndarray:
        """ä¸“ä¸šè‰²å½©å¢å¼º"""
        try:
            # è½¬æ¢ä¸ºPILå›¾åƒ
            pil_image = Image.fromarray(image)
            
            # å¢å¼ºé¥±å’Œåº¦
            enhancer = ImageEnhance.Color(pil_image)
            enhanced = enhancer.enhance(self.config["saturation_boost"])
            
            # å¢å¼ºå¯¹æ¯”åº¦
            enhancer = ImageEnhance.Contrast(enhanced)
            enhanced = enhancer.enhance(self.config["contrast_boost"])
            
            # è½»å¾®å¢å¼ºé”åº¦
            enhancer = ImageEnhance.Sharpness(enhanced)
            enhanced = enhancer.enhance(1.2)
            
            return np.array(enhanced)
            
        except Exception as e:
            logger.warning(f"ä¸“ä¸šè‰²å½©å¢å¼ºå¤±è´¥: {str(e)}")
            return image
    
    def _intelligent_edge_enhancement(self, image: np.ndarray, original: np.ndarray) -> np.ndarray:
        """æ™ºèƒ½è¾¹ç¼˜å¢å¼º"""
        try:
            # æ£€æµ‹åŸå›¾çš„è¾¹ç¼˜
            gray_orig = cv2.cvtColor(original, cv2.COLOR_RGB2GRAY)
            edges_orig = cv2.Canny(gray_orig, 50, 150)
            
            # åˆ›å»ºé”åŒ–æ ¸
            kernel = np.array([
                [-0.3, -0.7, -0.3],
                [-0.7, 4.0, -0.7],
                [-0.3, -0.7, -0.3]
            ], dtype=np.float32)
            
            # åº”ç”¨é”åŒ–
            sharpened = cv2.filter2D(image, -1, kernel)
            
            # åªåœ¨åŸå›¾è¾¹ç¼˜åŒºåŸŸåº”ç”¨é”åŒ–
            edges_3d = cv2.cvtColor(edges_orig, cv2.COLOR_GRAY2RGB) / 255.0
            edges_3d = cv2.dilate(edges_3d, np.ones((3, 3), np.uint8), iterations=1)
            
            # æ··åˆé”åŒ–å’ŒåŸå›¾
            enhancement_strength = self.config["edge_enhancement"] - 1.0
            result = image * (1 - edges_3d * enhancement_strength) + sharpened * (edges_3d * enhancement_strength)
            
            return np.clip(result, 0, 255).astype(np.uint8)
            
        except Exception as e:
            logger.warning(f"æ™ºèƒ½è¾¹ç¼˜å¢å¼ºå¤±è´¥: {str(e)}")
            return image
    
    def _structure_preserving_blend(self, original: np.ndarray, processed: np.ndarray) -> np.ndarray:
        """ç»“æ„ä¿æŒèåˆ"""
        try:
            # è®¡ç®—ç»“æ„ä¿æŒæƒé‡
            preservation_weight = self.config["structure_preservation"]
            
            # æ£€æµ‹é‡è¦ç»“æ„åŒºåŸŸï¼ˆé«˜æ¢¯åº¦åŒºåŸŸï¼‰
            gray_orig = cv2.cvtColor(original, cv2.COLOR_RGB2GRAY)
            
            # è®¡ç®—æ¢¯åº¦
            grad_x = cv2.Sobel(gray_orig, cv2.CV_64F, 1, 0, ksize=3)
            grad_y = cv2.Sobel(gray_orig, cv2.CV_64F, 0, 1, ksize=3)
            gradient_magnitude = np.sqrt(grad_x**2 + grad_y**2)
            
            # å½’ä¸€åŒ–æ¢¯åº¦
            gradient_normalized = gradient_magnitude / np.max(gradient_magnitude)
            gradient_3d = np.stack([gradient_normalized] * 3, axis=2)
            
            # åœ¨é«˜æ¢¯åº¦åŒºåŸŸæ›´å¤šåœ°ä¿æŒåŸå›¾ç»“æ„
            structure_mask = gradient_3d * preservation_weight
            
            # èåˆ
            result = processed * (1 - structure_mask) + original * structure_mask
            
            return np.clip(result, 0, 255).astype(np.uint8)
            
        except Exception as e:
            logger.warning(f"ç»“æ„ä¿æŒèåˆå¤±è´¥: {str(e)}")
            return processed
    
    def _create_comparison(self, original: np.ndarray, processed: np.ndarray) -> np.ndarray:
        """åˆ›å»ºå¯¹æ¯”å›¾"""
        try:
            # ç¡®ä¿ä¸¤ä¸ªå›¾åƒå°ºå¯¸ç›¸åŒ
            if original.shape != processed.shape:
                processed = cv2.resize(processed, (original.shape[1], original.shape[0]))
            
            # æ°´å¹³æ‹¼æ¥
            comparison = np.hstack([original, processed])
            
            return comparison
            
        except Exception as e:
            logger.warning(f"åˆ›å»ºå¯¹æ¯”å›¾å¤±è´¥: {str(e)}")
            return processed
    
    def _save_image(self, image: np.ndarray, output_path: str):
        """ä¿å­˜å›¾åƒ"""
        try:
            # è½¬æ¢ä¸ºPILå›¾åƒå¹¶ä¿å­˜
            pil_image = Image.fromarray(image)
            pil_image.save(output_path, 'PNG', optimize=True)
            
            # è·å–æ–‡ä»¶å¤§å°
            file_size = os.path.getsize(output_path) / (1024 * 1024)
            logger.info(f"å›¾åƒå·²ä¿å­˜: {output_path} ({file_size:.2f} MB)")
            
        except Exception as e:
            raise Exception(f"ä¿å­˜å›¾åƒå¤±è´¥: {str(e)}")

def main():
    """æµ‹è¯•å‡½æ•°"""
    logging.basicConfig(level=logging.INFO)
    
    generator = OptimizedProfessionalGenerator()
    
    # æµ‹è¯•å›¾åƒ
    test_image = "uploads/250625_205648.jpg"
    if not os.path.exists(test_image):
        print(f"æµ‹è¯•å›¾åƒä¸å­˜åœ¨: {test_image}")
        return
    
    # ç”Ÿæˆä¸“ä¸šå›¾åƒ
    job_id = f"optimized_test_{int(time.time())}"
    
    try:
        professional_path, comparison_path, processing_time = generator.generate_professional_image(
            test_image, job_id
        )
        
        print(f"âœ… ä¼˜åŒ–ä¸“ä¸šå›¾åƒç”ŸæˆæˆåŠŸï¼")
        print(f"ğŸ“ ä¸“ä¸šå›¾åƒ: {professional_path}")
        print(f"ğŸ“Š å¯¹æ¯”å›¾åƒ: {comparison_path}")
        print(f"â±ï¸  å¤„ç†æ—¶é—´: {processing_time:.2f}ç§’")
        
    except Exception as e:
        print(f"âŒ ç”Ÿæˆå¤±è´¥: {str(e)}")

if __name__ == "__main__":
    main() 