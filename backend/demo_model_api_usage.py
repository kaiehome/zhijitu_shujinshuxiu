"""
æ¨¡å‹APIä½¿ç”¨æ¼”ç¤º
å±•ç¤ºå¦‚ä½•ä½¿ç”¨å¯ç”¨çš„æ¨¡å‹APIç»„ä»¶
"""

import asyncio
import cv2
import numpy as np
import time
from pathlib import Path

# å¯¼å…¥å¯ç”¨çš„æ¨¡å‹APIç»„ä»¶
from simple_model_api import SimpleModelAPIManager, SimpleModelAPIConfig, SimpleGenerationRequest
from ai_enhanced_processor import AIEnhancedProcessor
from ai_image_generator import AIImageGenerator
from ai_segmentation import AISegmenter


def create_demo_image() -> np.ndarray:
    """åˆ›å»ºæ¼”ç¤ºå›¾åƒ"""
    # åˆ›å»ºä¸€ä¸ªç®€å•çš„ç†ŠçŒ«å›¾æ¡ˆ
    image = np.ones((512, 512, 3), dtype=np.uint8) * 240
    
    # ç†ŠçŒ«å¤´éƒ¨
    cv2.ellipse(image, (256, 256), (120, 100), 0, 0, 360, (240, 240, 240), -1)
    
    # çœ¼ç›
    cv2.circle(image, (220, 230), 15, (50, 50, 50), -1)
    cv2.circle(image, (292, 230), 15, (50, 50, 50), -1)
    
    # é¼»å­
    cv2.circle(image, (256, 270), 8, (50, 50, 50), -1)
    
    # æ·»åŠ ä¸€äº›ç»†èŠ‚
    cv2.putText(image, "Demo", (220, 400), cv2.FONT_HERSHEY_SIMPLEX, 1, (100, 100, 100), 2)
    
    return image


async def demo_simple_model_api():
    """æ¼”ç¤ºç®€åŒ–æ¨¡å‹API"""
    print("ğŸ¨ æ¼”ç¤ºç®€åŒ–æ¨¡å‹API...")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path("demo_outputs")
    output_dir.mkdir(exist_ok=True)
    
    # åˆ›å»ºæ¼”ç¤ºå›¾åƒ
    demo_image = create_demo_image()
    input_path = output_dir / "demo_input.png"
    cv2.imwrite(str(input_path), demo_image)
    
    # åˆå§‹åŒ–APIç®¡ç†å™¨
    config = SimpleModelAPIConfig(
        enable_optimization=True,
        enable_quality_analysis=True,
        default_style="embroidery"
    )
    api_manager = SimpleModelAPIManager(config)
    
    # æ¼”ç¤ºä¸åŒé£æ ¼
    styles = ["basic", "embroidery", "traditional", "modern"]
    
    for style in styles:
        print(f"\nğŸ”„ å¤„ç† {style} é£æ ¼...")
        
        request = SimpleGenerationRequest(
            image_path=str(input_path),
            style=style,
            color_count=16,
            edge_enhancement=True,
            noise_reduction=True,
            optimization_level="balanced"
        )
        
        # æäº¤ä»»åŠ¡
        job_id = await api_manager.generate_embroidery(request)
        print(f"ä»»åŠ¡ID: {job_id}")
        
        # ç­‰å¾…å®Œæˆ
        max_wait = 30
        while max_wait > 0:
            status = api_manager.get_job_status(job_id)
            if status and status['status'] in ['completed', 'failed']:
                break
            await asyncio.sleep(1)
            max_wait -= 1
        
        if status and status['status'] == 'completed':
            print(f"âœ… {style} é£æ ¼å¤„ç†å®Œæˆ")
            print(f"   å¤„ç†æ—¶é—´: {status['processing_time']:.2f}ç§’")
            print(f"   è¾“å‡ºæ–‡ä»¶: {status['output_files']}")
        else:
            print(f"âŒ {style} é£æ ¼å¤„ç†å¤±è´¥")
    
    # æ˜¾ç¤ºç³»ç»Ÿç»Ÿè®¡
    stats = api_manager.get_system_stats()
    print(f"\nğŸ“Š ç³»ç»Ÿç»Ÿè®¡: {stats}")


def demo_ai_enhanced_processor():
    """æ¼”ç¤ºAIå¢å¼ºå¤„ç†å™¨"""
    print("\nğŸ¤– æ¼”ç¤ºAIå¢å¼ºå¤„ç†å™¨...")
    
    # åˆ›å»ºæ¼”ç¤ºå›¾åƒ
    demo_image = create_demo_image()
    
    # åˆå§‹åŒ–å¤„ç†å™¨
    processor = AIEnhancedProcessor()
    
    # åˆ†æå›¾åƒå†…å®¹
    print("ğŸ” åˆ†æå›¾åƒå†…å®¹...")
    analysis = processor.analyze_image_content(demo_image)
    print(f"åˆ†æç»“æœ: {analysis}")
    
    # å›é€€åˆ†æ
    print("ğŸ”„ æ‰§è¡Œå›é€€åˆ†æ...")
    fallback_analysis = processor._fallback_analysis(demo_image)
    print(f"å›é€€åˆ†æç»“æœ: {fallback_analysis}")


def demo_ai_image_generator():
    """æ¼”ç¤ºAIå›¾åƒç”Ÿæˆå™¨"""
    print("\nğŸ¨ æ¼”ç¤ºAIå›¾åƒç”Ÿæˆå™¨...")
    
    # åˆå§‹åŒ–ç”Ÿæˆå™¨
    generator = AIImageGenerator()
    
    # ç”Ÿæˆä¸“ä¸šèƒŒæ™¯
    print("ğŸ–¼ï¸ ç”Ÿæˆä¸“ä¸šèƒŒæ™¯...")
    background = generator.generate_professional_background(512, 512, "ç†ŠçŒ«åˆºç»£")
    
    # ä¿å­˜èƒŒæ™¯
    output_dir = Path("demo_outputs")
    output_dir.mkdir(exist_ok=True)
    cv2.imwrite(str(output_dir / "generated_background.png"), background)
    print(f"âœ… èƒŒæ™¯å·²ä¿å­˜: {output_dir}/generated_background.png")
    
    # ç”ŸæˆåŸºç¡€èƒŒæ™¯
    print("ğŸ–¼ï¸ ç”ŸæˆåŸºç¡€èƒŒæ™¯...")
    basic_bg = generator._generate_basic_background(256, 256)
    cv2.imwrite(str(output_dir / "basic_background.png"), basic_bg)
    print(f"âœ… åŸºç¡€èƒŒæ™¯å·²ä¿å­˜: {output_dir}/basic_background.png")


def demo_ai_segmentation():
    """æ¼”ç¤ºAIåˆ†å‰²å™¨"""
    print("\nâœ‚ï¸ æ¼”ç¤ºAIåˆ†å‰²å™¨...")
    
    # åˆ›å»ºæ¼”ç¤ºå›¾åƒ
    demo_image = create_demo_image()
    
    # æµ‹è¯•ä¸åŒåˆ†å‰²æ–¹æ³•
    methods = ['grabcut', 'watershed', 'slic', 'contour']
    
    output_dir = Path("demo_outputs")
    output_dir.mkdir(exist_ok=True)
    
    for method in methods:
        print(f"ğŸ” ä½¿ç”¨ {method} æ–¹æ³•åˆ†å‰²...")
        
        try:
            # åˆå§‹åŒ–åˆ†å‰²å™¨
            segmenter = AISegmenter(model_name=method)
            
            # æ‰§è¡Œåˆ†å‰²
            result = segmenter.segment(demo_image)
            
            # ä¿å­˜ç»“æœ
            output_path = output_dir / f"segmentation_{method}.png"
            cv2.imwrite(str(output_path), result)
            print(f"âœ… {method} åˆ†å‰²å®Œæˆï¼Œå·²ä¿å­˜: {output_path}")
            
        except Exception as e:
            print(f"âŒ {method} åˆ†å‰²å¤±è´¥: {e}")


def demo_integration():
    """æ¼”ç¤ºç»„ä»¶é›†æˆ"""
    print("\nğŸ”— æ¼”ç¤ºç»„ä»¶é›†æˆ...")
    
    # åˆ›å»ºæ¼”ç¤ºå›¾åƒ
    demo_image = create_demo_image()
    
    # 1. ä½¿ç”¨AIå¢å¼ºå¤„ç†å™¨åˆ†æ
    processor = AIEnhancedProcessor()
    analysis = processor.analyze_image_content(demo_image)
    print(f"ğŸ“Š å›¾åƒåˆ†æ: {analysis}")
    
    # 2. ä½¿ç”¨AIåˆ†å‰²å™¨åˆ†å‰²
    segmenter = AISegmenter(model_name='grabcut')
    segmentation = segmenter.segment(demo_image)
    print(f"âœ‚ï¸ å›¾åƒåˆ†å‰²å®Œæˆï¼Œå½¢çŠ¶: {segmentation.shape}")
    
    # 3. ä½¿ç”¨AIå›¾åƒç”Ÿæˆå™¨ç”ŸæˆèƒŒæ™¯
    generator = AIImageGenerator()
    background = generator.generate_professional_background(512, 512, "ç†ŠçŒ«")
    print(f"ğŸ¨ èƒŒæ™¯ç”Ÿæˆå®Œæˆï¼Œå½¢çŠ¶: {background.shape}")
    
    # 4. ä¿å­˜é›†æˆç»“æœ
    output_dir = Path("demo_outputs")
    output_dir.mkdir(exist_ok=True)
    
    cv2.imwrite(str(output_dir / "integration_segmentation.png"), segmentation)
    cv2.imwrite(str(output_dir / "integration_background.png"), background)
    
    print("âœ… é›†æˆæ¼”ç¤ºå®Œæˆï¼Œç»“æœå·²ä¿å­˜")


async def main():
    """ä¸»æ¼”ç¤ºå‡½æ•°"""
    print("ğŸš€ æ¨¡å‹APIä½¿ç”¨æ¼”ç¤º")
    print("=" * 50)
    
    # åˆ›å»ºæ¼”ç¤ºè¾“å‡ºç›®å½•
    output_dir = Path("demo_outputs")
    output_dir.mkdir(exist_ok=True)
    
    # è¿è¡Œå„ä¸ªæ¼”ç¤º
    await demo_simple_model_api()
    demo_ai_enhanced_processor()
    demo_ai_image_generator()
    demo_ai_segmentation()
    demo_integration()
    
    print("\nğŸ‰ æ¼”ç¤ºå®Œæˆï¼")
    print(f"ğŸ“ æ‰€æœ‰è¾“å‡ºæ–‡ä»¶ä¿å­˜åœ¨: {output_dir.absolute()}")
    print("\nğŸ’¡ ä½¿ç”¨å»ºè®®:")
    print("1. ç®€åŒ–æ¨¡å‹API: ç”¨äºå›¾åƒå¤„ç†å’Œé£æ ¼è½¬æ¢")
    print("2. AIå¢å¼ºå¤„ç†å™¨: ç”¨äºå›¾åƒå†…å®¹åˆ†æ")
    print("3. AIå›¾åƒç”Ÿæˆå™¨: ç”¨äºèƒŒæ™¯ç”Ÿæˆ")
    print("4. AIåˆ†å‰²å™¨: ç”¨äºå›¾åƒåˆ†å‰²")
    print("5. ç»„ä»¶é›†æˆ: ç»„åˆä½¿ç”¨ä»¥è·å¾—æœ€ä½³æ•ˆæœ")


if __name__ == "__main__":
    asyncio.run(main()) 