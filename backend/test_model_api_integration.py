"""
æ¨¡å‹APIé›†æˆæµ‹è¯•
éªŒè¯æ‰€æœ‰æ¨¡å‹APIç»„ä»¶çš„é›†æˆå’ŒåŠŸèƒ½
"""

import asyncio
import cv2
import numpy as np
import time
import json
import logging
from pathlib import Path
from typing import Dict, Any, List, Tuple

# å¯¼å…¥æ‰€æœ‰æ¨¡å‹APIç»„ä»¶
from simple_model_api import SimpleModelAPIManager, SimpleModelAPIConfig, SimpleGenerationRequest
from model_api_manager import ModelAPIManager, ModelAPIConfig, GenerationRequest
from deep_learning_models import DeepLearningModelManager, ModelConfig
from ai_enhanced_processor import AIEnhancedProcessor
from ai_image_generator import AIImageGenerator
from ai_segmentation import AISegmenter
from local_ai_generator import LocalAIGenerator

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class ModelAPIIntegrationTest:
    """æ¨¡å‹APIé›†æˆæµ‹è¯•ç±»"""

    def __init__(self):
        self.test_results = {
            "simple_api": {},
            "unified_api": {},
            "deep_learning": {},
            "ai_enhanced": {},
            "ai_generation": {},
            "ai_segmentation": {},
            "local_ai": {},
            "integration": {}
        }
        self.test_images = {}
        self.output_dir = Path("test_outputs")
        self.output_dir.mkdir(exist_ok=True)

    def create_test_images(self) -> Dict[str, np.ndarray]:
        """åˆ›å»ºæµ‹è¯•å›¾åƒ"""
        logger.info("åˆ›å»ºæµ‹è¯•å›¾åƒ...")
        
        images = {}
        
        # 1. ç®€å•æµ‹è¯•å›¾åƒ
        simple_image = np.ones((512, 512, 3), dtype=np.uint8) * 240
        cv2.rectangle(simple_image, (100, 100), (412, 412), (100, 100, 100), 2)
        cv2.circle(simple_image, (256, 256), 80, (150, 150, 150), -1)
        images["simple"] = simple_image
        
        # 2. å¤æ‚æµ‹è¯•å›¾åƒï¼ˆæ¨¡æ‹Ÿåˆºç»£å›¾æ¡ˆï¼‰
        complex_image = np.ones((512, 512, 3), dtype=np.uint8) * 200
        # æ·»åŠ å¤æ‚å›¾æ¡ˆ
        for i in range(0, 512, 64):
            for j in range(0, 512, 64):
                color = np.random.randint(50, 200, 3)
                cv2.rectangle(complex_image, (i, j), (i+32, j+32), color.tolist(), -1)
        images["complex"] = complex_image
        
        # 3. ç†ŠçŒ«å›¾æ¡ˆï¼ˆæ¨¡æ‹ŸçœŸå®åˆºç»£ï¼‰
        panda_image = np.ones((512, 512, 3), dtype=np.uint8) * 240
        # ç†ŠçŒ«å¤´éƒ¨
        cv2.ellipse(panda_image, (256, 256), (120, 100), 0, 0, 360, (240, 240, 240), -1)
        # çœ¼ç›
        cv2.circle(panda_image, (220, 230), 15, (50, 50, 50), -1)
        cv2.circle(panda_image, (292, 230), 15, (50, 50, 50), -1)
        # é¼»å­
        cv2.circle(panda_image, (256, 270), 8, (50, 50, 50), -1)
        images["panda"] = panda_image
        
        # ä¿å­˜æµ‹è¯•å›¾åƒ
        for name, image in images.items():
            cv2.imwrite(str(self.output_dir / f"test_{name}.png"), image)
        
        self.test_images = images
        logger.info(f"åˆ›å»ºäº† {len(images)} ä¸ªæµ‹è¯•å›¾åƒ")
        return images

    async def test_simple_model_api(self) -> Dict[str, Any]:
        """æµ‹è¯•ç®€åŒ–æ¨¡å‹API"""
        logger.info("ğŸ§ª æµ‹è¯•ç®€åŒ–æ¨¡å‹API...")
        
        results = {
            "status": "passed",
            "tests": {},
            "performance": {},
            "errors": []
        }
        
        try:
            # åˆå§‹åŒ–APIç®¡ç†å™¨
            config = SimpleModelAPIConfig(
                enable_optimization=True,
                enable_quality_analysis=True,
                default_style="basic"
            )
            api_manager = SimpleModelAPIManager(config)
            
            # æµ‹è¯•1: æ£€æŸ¥å¯ç”¨æ¨¡å‹
            available_models = api_manager.get_available_models()
            results["tests"]["available_models"] = {
                "status": "passed",
                "data": available_models
            }
            
            # æµ‹è¯•2: åŸºç¡€å›¾åƒå¤„ç†
            test_image_path = str(self.output_dir / "test_simple.png")
            request = SimpleGenerationRequest(
                image_path=test_image_path,
                style="basic",
                color_count=12,
                optimization_level="balanced"
            )
            
            start_time = time.time()
            job_id = await api_manager.generate_embroidery(request)
            
            # ç­‰å¾…ä»»åŠ¡å®Œæˆ
            max_wait = 30
            while max_wait > 0:
                status = api_manager.get_job_status(job_id)
                if status and status['status'] in ['completed', 'failed']:
                    break
                await asyncio.sleep(1)
                max_wait -= 1
            
            if status and status['status'] == 'completed':
                results["tests"]["basic_processing"] = {
                    "status": "passed",
                    "processing_time": status['processing_time'],
                    "output_files": status['output_files']
                }
            else:
                results["tests"]["basic_processing"] = {
                    "status": "failed",
                    "error": status.get('error_message', 'Unknown error')
                }
                results["status"] = "failed"
            
            # æµ‹è¯•3: ä¸åŒé£æ ¼å¤„ç†
            styles = ["basic", "embroidery", "traditional", "modern"]
            style_results = {}
            
            for style in styles:
                request.style = style
                job_id = await api_manager.generate_embroidery(request)
                
                # ç­‰å¾…å®Œæˆ
                max_wait = 20
                while max_wait > 0:
                    status = api_manager.get_job_status(job_id)
                    if status and status['status'] in ['completed', 'failed']:
                        break
                    await asyncio.sleep(1)
                    max_wait -= 1
                
                style_results[style] = {
                    "status": status['status'] if status else "timeout",
                    "processing_time": status.get('processing_time', 0) if status else 0
                }
            
            results["tests"]["style_processing"] = {
                "status": "passed" if all(r["status"] == "completed" for r in style_results.values()) else "failed",
                "data": style_results
            }
            
            # æµ‹è¯•4: ç³»ç»Ÿç»Ÿè®¡
            stats = api_manager.get_system_stats()
            results["tests"]["system_stats"] = {
                "status": "passed",
                "data": stats
            }
            
            # æ€§èƒ½ç»Ÿè®¡
            results["performance"] = {
                "total_tests": len(results["tests"]),
                "passed_tests": sum(1 for t in results["tests"].values() if t["status"] == "passed"),
                "failed_tests": sum(1 for t in results["tests"].values() if t["status"] == "failed")
            }
            
        except Exception as e:
            logger.error(f"ç®€åŒ–æ¨¡å‹APIæµ‹è¯•å¤±è´¥: {e}")
            results["status"] = "failed"
            results["errors"].append(str(e))
        
        self.test_results["simple_api"] = results
        return results

    async def test_unified_model_api(self) -> Dict[str, Any]:
        """æµ‹è¯•ç»Ÿä¸€æ¨¡å‹API"""
        logger.info("ğŸ§ª æµ‹è¯•ç»Ÿä¸€æ¨¡å‹API...")
        
        results = {
            "status": "passed",
            "tests": {},
            "performance": {},
            "errors": []
        }
        
        try:
            # åˆå§‹åŒ–APIç®¡ç†å™¨
            config = ModelAPIConfig(
                enable_optimization=True,
                enable_quality_analysis=True,
                default_style="sichuan_brocade"
            )
            api_manager = ModelAPIManager(config)
            
            # æµ‹è¯•1: æ£€æŸ¥å¯ç”¨æ¨¡å‹
            available_models = api_manager.get_available_models()
            results["tests"]["available_models"] = {
                "status": "passed",
                "data": available_models
            }
            
            # æµ‹è¯•2: èœ€é”¦é£æ ¼å¤„ç†
            test_image_path = str(self.output_dir / "test_panda.png")
            request = GenerationRequest(
                image_path=test_image_path,
                style="sichuan_brocade",
                color_count=16,
                optimization_level="balanced"
            )
            
            job_id = await api_manager.generate_embroidery(request)
            
            # ç­‰å¾…ä»»åŠ¡å®Œæˆ
            max_wait = 30
            while max_wait > 0:
                status = api_manager.get_job_status(job_id)
                if status and status['status'] in ['completed', 'failed']:
                    break
                await asyncio.sleep(1)
                max_wait -= 1
            
            if status and status['status'] == 'completed':
                results["tests"]["sichuan_brocade"] = {
                    "status": "passed",
                    "processing_time": status['processing_time'],
                    "output_files": status['output_files']
                }
            else:
                results["tests"]["sichuan_brocade"] = {
                    "status": "failed",
                    "error": status.get('error_message', 'Unknown error') if status else 'Timeout'
                }
                results["status"] = "failed"
            
            # æµ‹è¯•3: ç»“æ„åŒ–ç”Ÿæˆ
            request.style = "structural"
            job_id = await api_manager.generate_embroidery(request)
            
            max_wait = 30
            while max_wait > 0:
                status = api_manager.get_job_status(job_id)
                if status and status['status'] in ['completed', 'failed']:
                    break
                await asyncio.sleep(1)
                max_wait -= 1
            
            if status and status['status'] == 'completed':
                results["tests"]["structural_generation"] = {
                    "status": "passed",
                    "processing_time": status['processing_time']
                }
            else:
                results["tests"]["structural_generation"] = {
                    "status": "failed",
                    "error": status.get('error_message', 'Unknown error') if status else 'Timeout'
                }
            
            # æ€§èƒ½ç»Ÿè®¡
            results["performance"] = {
                "total_tests": len(results["tests"]),
                "passed_tests": sum(1 for t in results["tests"].values() if t["status"] == "passed"),
                "failed_tests": sum(1 for t in results["tests"].values() if t["status"] == "failed")
            }
            
        except Exception as e:
            logger.error(f"ç»Ÿä¸€æ¨¡å‹APIæµ‹è¯•å¤±è´¥: {e}")
            results["status"] = "failed"
            results["errors"].append(str(e))
        
        self.test_results["unified_api"] = results
        return results

    def test_deep_learning_models(self) -> Dict[str, Any]:
        """æµ‹è¯•æ·±åº¦å­¦ä¹ æ¨¡å‹"""
        logger.info("ğŸ§ª æµ‹è¯•æ·±åº¦å­¦ä¹ æ¨¡å‹...")
        
        results = {
            "status": "passed",
            "tests": {},
            "performance": {},
            "errors": []
        }
        
        try:
            # åˆå§‹åŒ–æ¨¡å‹ç®¡ç†å™¨
            model_manager = DeepLearningModelManager(models_dir=str(self.output_dir / "models"))
            
            # æµ‹è¯•1: æ¨¡å‹é…ç½®
            config = ModelConfig(
                model_type="unet",
                input_size=(256, 256),
                num_classes=2,
                device="cpu"  # ä½¿ç”¨CPUè¿›è¡Œæµ‹è¯•
            )
            
            results["tests"]["model_config"] = {
                "status": "passed",
                "config": config.to_dict()
            }
            
            # æµ‹è¯•2: æ¨¡å‹åŠ è½½ï¼ˆå¦‚æœä¾èµ–åº“å¯ç”¨ï¼‰
            try:
                if model_manager.load_segmentation_model("unet", config):
                    results["tests"]["model_loading"] = {
                        "status": "passed",
                        "message": "æ¨¡å‹åŠ è½½æˆåŠŸ"
                    }
                else:
                    results["tests"]["model_loading"] = {
                        "status": "skipped",
                        "message": "æ¨¡å‹åŠ è½½è·³è¿‡ï¼ˆä¾èµ–åº“æœªå®‰è£…ï¼‰"
                    }
                    results["status"] = "skipped"
            except ImportError:
                results["tests"]["model_loading"] = {
                    "status": "skipped",
                    "message": "PyTorchæœªå®‰è£…"
                }
                results["status"] = "skipped"
            
            # æµ‹è¯•3: ç‰¹å¾æå–å™¨
            try:
                if model_manager.load_feature_extractor("resnet50"):
                    results["tests"]["feature_extractor"] = {
                        "status": "passed",
                        "message": "ç‰¹å¾æå–å™¨åŠ è½½æˆåŠŸ"
                    }
                else:
                    results["tests"]["feature_extractor"] = {
                        "status": "skipped",
                        "message": "ç‰¹å¾æå–å™¨åŠ è½½è·³è¿‡"
                    }
            except ImportError:
                results["tests"]["feature_extractor"] = {
                    "status": "skipped",
                    "message": "PyTorchæœªå®‰è£…"
                }
            
            # æµ‹è¯•4: å¯ç”¨æ¨¡å‹åˆ—è¡¨
            available_models = model_manager.get_available_models()
            results["tests"]["available_models"] = {
                "status": "passed",
                "data": available_models
            }
            
            # æµ‹è¯•5: ç»Ÿè®¡ä¿¡æ¯
            stats = model_manager.get_stats()
            results["tests"]["stats"] = {
                "status": "passed",
                "data": stats
            }
            
            # æ€§èƒ½ç»Ÿè®¡
            results["performance"] = {
                "total_tests": len(results["tests"]),
                "passed_tests": sum(1 for t in results["tests"].values() if t["status"] == "passed"),
                "skipped_tests": sum(1 for t in results["tests"].values() if t["status"] == "skipped")
            }
            
        except Exception as e:
            logger.error(f"æ·±åº¦å­¦ä¹ æ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
            results["status"] = "failed"
            results["errors"].append(str(e))
        
        self.test_results["deep_learning"] = results
        return results

    def test_ai_enhanced_processor(self) -> Dict[str, Any]:
        """æµ‹è¯•AIå¢å¼ºå¤„ç†å™¨"""
        logger.info("ğŸ§ª æµ‹è¯•AIå¢å¼ºå¤„ç†å™¨...")
        
        results = {
            "status": "passed",
            "tests": {},
            "performance": {},
            "errors": []
        }
        
        try:
            # åˆå§‹åŒ–AIå¢å¼ºå¤„ç†å™¨
            processor = AIEnhancedProcessor()
            
            # æµ‹è¯•1: å¤„ç†å™¨åˆå§‹åŒ–
            results["tests"]["initialization"] = {
                "status": "passed",
                "ai_enabled": processor.ai_enabled
            }
            
            # æµ‹è¯•2: å›¾åƒå†…å®¹åˆ†æ
            test_image = self.test_images["panda"]
            analysis = processor.analyze_image_content(test_image)
            
            results["tests"]["image_analysis"] = {
                "status": "passed",
                "analysis": analysis
            }
            
            # æµ‹è¯•3: å›é€€åˆ†æ
            fallback_analysis = processor._fallback_analysis(test_image)
            results["tests"]["fallback_analysis"] = {
                "status": "passed",
                "analysis": fallback_analysis
            }
            
            # æ€§èƒ½ç»Ÿè®¡
            results["performance"] = {
                "total_tests": len(results["tests"]),
                "passed_tests": len(results["tests"])
            }
            
        except Exception as e:
            logger.error(f"AIå¢å¼ºå¤„ç†å™¨æµ‹è¯•å¤±è´¥: {e}")
            results["status"] = "failed"
            results["errors"].append(str(e))
        
        self.test_results["ai_enhanced"] = results
        return results

    def test_ai_image_generator(self) -> Dict[str, Any]:
        """æµ‹è¯•AIå›¾åƒç”Ÿæˆå™¨"""
        logger.info("ğŸ§ª æµ‹è¯•AIå›¾åƒç”Ÿæˆå™¨...")
        
        results = {
            "status": "passed",
            "tests": {},
            "performance": {},
            "errors": []
        }
        
        try:
            # åˆå§‹åŒ–AIå›¾åƒç”Ÿæˆå™¨
            generator = AIImageGenerator()
            
            # æµ‹è¯•1: ç”Ÿæˆå™¨åˆå§‹åŒ–
            results["tests"]["initialization"] = {
                "status": "passed",
                "ai_enabled": generator.ai_enabled
            }
            
            # æµ‹è¯•2: ä¸“ä¸šèƒŒæ™¯ç”Ÿæˆ
            background = generator.generate_professional_background(512, 512, "ç†ŠçŒ«")
            
            results["tests"]["background_generation"] = {
                "status": "passed",
                "background_shape": background.shape
            }
            
            # ä¿å­˜ç”Ÿæˆçš„èƒŒæ™¯
            cv2.imwrite(str(self.output_dir / "generated_background.png"), background)
            
            # æµ‹è¯•3: åŸºç¡€èƒŒæ™¯ç”Ÿæˆ
            basic_background = generator._generate_basic_background(256, 256)
            results["tests"]["basic_background"] = {
                "status": "passed",
                "background_shape": basic_background.shape
            }
            
            # æ€§èƒ½ç»Ÿè®¡
            results["performance"] = {
                "total_tests": len(results["tests"]),
                "passed_tests": len(results["tests"])
            }
            
        except Exception as e:
            logger.error(f"AIå›¾åƒç”Ÿæˆå™¨æµ‹è¯•å¤±è´¥: {e}")
            results["status"] = "failed"
            results["errors"].append(str(e))
        
        self.test_results["ai_generation"] = results
        return results

    def test_ai_segmentation(self) -> Dict[str, Any]:
        """æµ‹è¯•AIåˆ†å‰²å™¨"""
        logger.info("ğŸ§ª æµ‹è¯•AIåˆ†å‰²å™¨...")
        
        results = {
            "status": "passed",
            "tests": {},
            "performance": {},
            "errors": []
        }
        
        try:
            # æµ‹è¯•ä¸åŒçš„åˆ†å‰²æ–¹æ³•
            segmentation_methods = ['grabcut', 'watershed', 'slic', 'contour']
            
            for method in segmentation_methods:
                try:
                    # åˆå§‹åŒ–åˆ†å‰²å™¨
                    segmenter = AISegmenter(model_name=method)
                    
                    # æ‰§è¡Œåˆ†å‰²
                    test_image = self.test_images["complex"]
                    segmentation_result = segmenter.segment(test_image)
                    
                    results["tests"][f"{method}_segmentation"] = {
                        "status": "passed",
                        "result_shape": segmentation_result.shape,
                        "unique_values": len(np.unique(segmentation_result))
                    }
                    
                    # ä¿å­˜åˆ†å‰²ç»“æœ
                    cv2.imwrite(str(self.output_dir / f"segmentation_{method}.png"), segmentation_result)
                    
                except Exception as e:
                    results["tests"][f"{method}_segmentation"] = {
                        "status": "failed",
                        "error": str(e)
                    }
            
            # æ€§èƒ½ç»Ÿè®¡
            passed_tests = sum(1 for t in results["tests"].values() if t["status"] == "passed")
            results["performance"] = {
                "total_tests": len(results["tests"]),
                "passed_tests": passed_tests,
                "failed_tests": len(results["tests"]) - passed_tests
            }
            
            if passed_tests < len(results["tests"]):
                results["status"] = "partial"
            
        except Exception as e:
            logger.error(f"AIåˆ†å‰²å™¨æµ‹è¯•å¤±è´¥: {e}")
            results["status"] = "failed"
            results["errors"].append(str(e))
        
        self.test_results["ai_segmentation"] = results
        return results

    def test_local_ai_generator(self) -> Dict[str, Any]:
        """æµ‹è¯•æœ¬åœ°AIç”Ÿæˆå™¨"""
        logger.info("ğŸ§ª æµ‹è¯•æœ¬åœ°AIç”Ÿæˆå™¨...")
        
        results = {
            "status": "passed",
            "tests": {},
            "performance": {},
            "errors": []
        }
        
        try:
            # åˆå§‹åŒ–æœ¬åœ°AIç”Ÿæˆå™¨
            generator = LocalAIGenerator()
            
            # æµ‹è¯•1: ç”Ÿæˆå™¨åˆå§‹åŒ–
            results["tests"]["initialization"] = {
                "status": "passed",
                "models_loaded": generator.models_loaded,
                "device": generator.device
            }
            
            # æµ‹è¯•2: å›¾åƒç†è§£
            test_image = self.test_images["panda"]
            understanding = generator.understand_image(test_image)
            
            results["tests"]["image_understanding"] = {
                "status": "passed",
                "understanding": understanding
            }
            
            # æµ‹è¯•3: é£æ ¼è½¬æ¢
            style_result = generator.apply_style(test_image, "embroidery")
            
            results["tests"]["style_transfer"] = {
                "status": "passed",
                "result_shape": style_result.shape
            }
            
            # ä¿å­˜ç»“æœ
            cv2.imwrite(str(self.output_dir / "local_ai_style.png"), style_result)
            
            # æ€§èƒ½ç»Ÿè®¡
            results["performance"] = {
                "total_tests": len(results["tests"]),
                "passed_tests": len(results["tests"])
            }
            
        except Exception as e:
            logger.error(f"æœ¬åœ°AIç”Ÿæˆå™¨æµ‹è¯•å¤±è´¥: {e}")
            results["status"] = "failed"
            results["errors"].append(str(e))
        
        self.test_results["local_ai"] = results
        return results

    async def test_integration(self) -> Dict[str, Any]:
        """æµ‹è¯•ç»„ä»¶é›†æˆ"""
        logger.info("ğŸ§ª æµ‹è¯•ç»„ä»¶é›†æˆ...")
        
        results = {
            "status": "passed",
            "tests": {},
            "performance": {},
            "errors": []
        }
        
        try:
            # æµ‹è¯•1: ç»„ä»¶é—´æ•°æ®æµ
            test_image = self.test_images["panda"]
            
            # ä½¿ç”¨AIå¢å¼ºå¤„ç†å™¨åˆ†æ
            processor = AIEnhancedProcessor()
            analysis = processor.analyze_image_content(test_image)
            
            # ä½¿ç”¨AIåˆ†å‰²å™¨åˆ†å‰²
            segmenter = AISegmenter(model_name='grabcut')
            segmentation = segmenter.segment(test_image)
            
            # ä½¿ç”¨ç®€åŒ–APIå¤„ç†
            config = SimpleModelAPIConfig()
            api_manager = SimpleModelAPIManager(config)
            
            # ä¿å­˜ä¸´æ—¶å›¾åƒç”¨äºAPIæµ‹è¯•
            temp_path = str(self.output_dir / "temp_integration.png")
            cv2.imwrite(temp_path, test_image)
            
            request = SimpleGenerationRequest(
                image_path=temp_path,
                style="embroidery",
                optimization_level="balanced"
            )
            
            job_id = await api_manager.generate_embroidery(request)
            
            # ç­‰å¾…å®Œæˆ
            max_wait = 30
            while max_wait > 0:
                status = api_manager.get_job_status(job_id)
                if status and status['status'] in ['completed', 'failed']:
                    break
                await asyncio.sleep(1)
                max_wait -= 1
            
            results["tests"]["data_flow"] = {
                "status": "passed" if status and status['status'] == 'completed' else "failed",
                "analysis": analysis,
                "segmentation_shape": segmentation.shape,
                "api_result": status
            }
            
            # æµ‹è¯•2: é”™è¯¯å¤„ç†é›†æˆ
            # æµ‹è¯•æ— æ•ˆå›¾åƒè·¯å¾„
            invalid_request = SimpleGenerationRequest(
                image_path="nonexistent.png",
                style="basic"
            )
            
            try:
                job_id = await api_manager.generate_embroidery(invalid_request)
                # ç­‰å¾…å¤±è´¥
                max_wait = 10
                while max_wait > 0:
                    status = api_manager.get_job_status(job_id)
                    if status and status['status'] == 'failed':
                        break
                    await asyncio.sleep(1)
                    max_wait -= 1
                
                results["tests"]["error_handling"] = {
                    "status": "passed" if status and status['status'] == 'failed' else "failed",
                    "error_message": status.get('error_message', '') if status else ''
                }
            except Exception as e:
                results["tests"]["error_handling"] = {
                    "status": "passed",
                    "error_message": str(e)
                }
            
            # æ€§èƒ½ç»Ÿè®¡
            results["performance"] = {
                "total_tests": len(results["tests"]),
                "passed_tests": sum(1 for t in results["tests"].values() if t["status"] == "passed"),
                "failed_tests": sum(1 for t in results["tests"].values() if t["status"] == "failed")
            }
            
        except Exception as e:
            logger.error(f"é›†æˆæµ‹è¯•å¤±è´¥: {e}")
            results["status"] = "failed"
            results["errors"].append(str(e))
        
        self.test_results["integration"] = results
        return results

    def generate_test_report(self) -> str:
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        logger.info("ğŸ“Š ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š...")
        
        report = []
        report.append("# ğŸ¤– æ¨¡å‹APIé›†æˆæµ‹è¯•æŠ¥å‘Š")
        report.append("")
        report.append(f"**æµ‹è¯•æ—¶é—´**: {time.strftime('%Y-%m-%d %H:%M:%S')}")
        report.append("")
        
        # æ€»ä½“ç»Ÿè®¡
        total_tests = 0
        total_passed = 0
        total_failed = 0
        total_skipped = 0
        
        for component, results in self.test_results.items():
            if not results:
                continue
                
            total_tests += 1
            if results["status"] == "passed":
                total_passed += 1
            elif results["status"] == "failed":
                total_failed += 1
            elif results["status"] == "skipped":
                total_skipped += 1
        
        report.append("## ğŸ“ˆ æ€»ä½“æµ‹è¯•ç»“æœ")
        report.append("")
        report.append(f"- **æ€»ç»„ä»¶æ•°**: {total_tests}")
        report.append(f"- **é€šè¿‡**: {total_passed} âœ…")
        report.append(f"- **å¤±è´¥**: {total_failed} âŒ")
        report.append(f"- **è·³è¿‡**: {total_skipped} â­ï¸")
        report.append("")
        
        # è¯¦ç»†ç»“æœ
        report.append("## ğŸ” è¯¦ç»†æµ‹è¯•ç»“æœ")
        report.append("")
        
        for component, results in self.test_results.items():
            if not results:
                continue
                
            status_emoji = "âœ…" if results["status"] == "passed" else "âŒ" if results["status"] == "failed" else "â­ï¸"
            report.append(f"### {status_emoji} {component.replace('_', ' ').title()}")
            report.append("")
            
            if "tests" in results:
                for test_name, test_result in results["tests"].items():
                    test_status = "âœ…" if test_result["status"] == "passed" else "âŒ" if test_result["status"] == "failed" else "â­ï¸"
                    report.append(f"- {test_status} **{test_name}**: {test_result['status']}")
                    
                    if "error" in test_result:
                        report.append(f"  - é”™è¯¯: {test_result['error']}")
            
            if "performance" in results:
                perf = results["performance"]
                report.append(f"- ğŸ“Š **æ€§èƒ½**: {perf.get('passed_tests', 0)}/{perf.get('total_tests', 0)} é€šè¿‡")
            
            if "errors" in results and results["errors"]:
                report.append("**é”™è¯¯åˆ—è¡¨**:")
                for error in results["errors"]:
                    report.append(f"- {error}")
            
            report.append("")
        
        # å»ºè®®
        report.append("## ğŸ’¡ å»ºè®®")
        report.append("")
        
        if total_failed > 0:
            report.append("### ğŸ”§ éœ€è¦ä¿®å¤çš„é—®é¢˜")
            report.append("")
            for component, results in self.test_results.items():
                if results and results["status"] == "failed":
                    report.append(f"- **{component}**: æ£€æŸ¥é”™è¯¯æ—¥å¿—å¹¶ä¿®å¤ç›¸å…³é—®é¢˜")
            report.append("")
        
        if total_passed > 0:
            report.append("### âœ… è¿è¡Œè‰¯å¥½çš„ç»„ä»¶")
            report.append("")
            for component, results in self.test_results.items():
                if results and results["status"] == "passed":
                    report.append(f"- **{component}**: åŠŸèƒ½æ­£å¸¸ï¼Œå¯ä»¥æŠ•å…¥ä½¿ç”¨")
            report.append("")
        
        report.append("### ğŸš€ ä¸‹ä¸€æ­¥è¡ŒåŠ¨")
        report.append("")
        report.append("1. **ä¿®å¤å¤±è´¥ç»„ä»¶**: æ ¹æ®é”™è¯¯ä¿¡æ¯ä¿®å¤ç›¸å…³é—®é¢˜")
        report.append("2. **æ€§èƒ½ä¼˜åŒ–**: å¯¹é€šè¿‡æµ‹è¯•çš„ç»„ä»¶è¿›è¡Œæ€§èƒ½ä¼˜åŒ–")
        report.append("3. **æ–‡æ¡£å®Œå–„**: æ›´æ–°APIæ–‡æ¡£å’Œä½¿ç”¨ç¤ºä¾‹")
        report.append("4. **ç”Ÿäº§éƒ¨ç½²**: å°†æµ‹è¯•é€šè¿‡çš„ç»„ä»¶éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ")
        
        report_content = "\n".join(report)
        
        # ä¿å­˜æŠ¥å‘Š
        report_path = self.output_dir / "model_api_integration_test_report.md"
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        logger.info(f"æµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
        return report_content

    async def run_all_tests(self) -> Dict[str, Any]:
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        logger.info("ğŸš€ å¼€å§‹è¿è¡Œæ¨¡å‹APIé›†æˆæµ‹è¯•...")
        
        # åˆ›å»ºæµ‹è¯•å›¾åƒ
        self.create_test_images()
        
        # è¿è¡Œå„ä¸ªç»„ä»¶æµ‹è¯•
        await self.test_simple_model_api()
        await self.test_unified_model_api()
        self.test_deep_learning_models()
        self.test_ai_enhanced_processor()
        self.test_ai_image_generator()
        self.test_ai_segmentation()
        self.test_local_ai_generator()
        await self.test_integration()
        
        # ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
        report = self.generate_test_report()
        
        logger.info("ğŸ‰ æ¨¡å‹APIé›†æˆæµ‹è¯•å®Œæˆï¼")
        return self.test_results


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¤– æ¨¡å‹APIé›†æˆæµ‹è¯•")
    print("=" * 50)
    
    # åˆ›å»ºæµ‹è¯•å®ä¾‹
    tester = ModelAPIIntegrationTest()
    
    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    results = await tester.run_all_tests()
    
    # æ‰“å°ç®€è¦ç»“æœ
    print("\nğŸ“Š æµ‹è¯•ç»“æœæ‘˜è¦:")
    for component, result in results.items():
        if result:
            status = result["status"]
            emoji = "âœ…" if status == "passed" else "âŒ" if status == "failed" else "â­ï¸"
            print(f"{emoji} {component}: {status}")
    
    print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {tester.output_dir}/model_api_integration_test_report.md")


if __name__ == "__main__":
    asyncio.run(main()) 