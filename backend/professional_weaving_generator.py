"""
ä¸“ä¸šç»‡æœºè¯†åˆ«å›¾åƒç”Ÿæˆå™¨
åŸºäºä¸“ä¸šç»‡æœºè½¯ä»¶æ•ˆæœåˆ†æï¼Œæä¾›é«˜è´¨é‡çš„å›¾åƒå¤„ç†åŠŸèƒ½
"""

import cv2
import numpy as np
from PIL import Image, ImageFilter, ImageEnhance, ImageOps, ImageDraw, ImageFont
from sklearn.cluster import KMeans
import logging
import time
from pathlib import Path
from ai_enhanced_processor import AIEnhancedProcessor
from ai_image_generator import AIImageGenerator
from typing import Tuple, List, Optional, Dict, Any
import warnings

warnings.filterwarnings('ignore', category=UserWarning)
logger = logging.getLogger(__name__)


class ProfessionalWeavingGenerator:
    """ä¸“ä¸šç»‡æœºè¯†åˆ«å›¾åƒç”Ÿæˆå™¨"""
    
    def __init__(self, outputs_dir: str = "outputs"):
        """åˆå§‹åŒ–ç”Ÿæˆå™¨"""
        self.outputs_dir = Path(outputs_dir)
        self.outputs_dir.mkdir(exist_ok=True, parents=True)
        
        # åˆå§‹åŒ–AIå¢å¼ºå¤„ç†å™¨
        try:
            self.ai_processor = AIEnhancedProcessor()
            logger.info("AIå¢å¼ºå¤„ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.warning(f"AIå¢å¼ºå¤„ç†å™¨åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            self.ai_processor = None
        
        # åˆå§‹åŒ–AIå›¾åƒç”Ÿæˆå™¨
        try:
            self.ai_generator = AIImageGenerator()
            logger.info("AIå›¾åƒç”Ÿæˆå™¨åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.warning(f"AIå›¾åƒç”Ÿæˆå™¨åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            self.ai_generator = None
        
        # AIå¢å¼ºç»‡æœºè¯†åˆ«é…ç½® - å‘ä¸“ä¸šè½¯ä»¶é è¿‘
        self.config = {
            "color_connectivity_strength": 25,      # å¢å¼ºè¿è´¯æ€§
            "edge_sharpening_intensity": 3.5,       # æåº¦å¢å¼ºè¾¹ç¼˜é”åŒ–
            "region_consolidation": True,
            "decorative_border": False,             # å…³é—­è£…é¥°è¾¹æ¡† - æ•°å­—åŒ–è¯†åˆ«å›¾æ¨¡å¼
            "color_saturation_boost": 2.5,          # æåº¦å¢å¼ºé¥±å’Œåº¦ - çœŸæ­£è¯†åˆ«å›¾é£æ ¼
            "contrast_boost": 2.2,                  # æåº¦å¢å¼ºå¯¹æ¯”åº¦ - çœŸæ­£è¯†åˆ«å›¾é£æ ¼
            "anti_aliasing": False,                 # å…³é—­æŠ—é”¯é½¿ - ä¿æŒåƒç´ åŒ–æ•ˆæœ
            "artistic_background": False,           # å…³é—­è‰ºæœ¯åŒ–èƒŒæ™¯ - æ•°å­—åŒ–è¯†åˆ«å›¾æ¨¡å¼
            "complex_decoration": False,            # å…³é—­å¤æ‚è£…é¥° - æ•°å­—åŒ–è¯†åˆ«å›¾æ¨¡å¼
            "professional_enhancement": False,      # å…³é—­ä¸“ä¸šè‰ºæœ¯åŒ–å¤„ç† - æ•°å­—åŒ–è¯†åˆ«å›¾æ¨¡å¼
            "pure_weaving_mode": True,              # å¯ç”¨çº¯ç»‡æœºæ¨¡å¼ - æ•°å­—åŒ–è¯†åˆ«å›¾
        }
        
        logger.info("ä¸“ä¸šç»‡æœºè¯†åˆ«å›¾åƒç”Ÿæˆå™¨å·²åˆå§‹åŒ–")
    
    def generate_professional_image(self, 
                                  input_path: str, 
                                  job_id: str,
                                  color_count: int = 16) -> Tuple[str, str, float]:
        """ç”Ÿæˆä¸“ä¸šç»‡æœºè¯†åˆ«å›¾åƒ"""
        start_time = time.time()
        
        try:
            logger.info(f"ğŸ¨ å¼€å§‹ç”Ÿæˆä¸“ä¸šç»‡æœºè¯†åˆ«å›¾åƒ: {job_id}")
            
            # åˆ›å»ºè¾“å‡ºç›®å½•
            job_dir = self.outputs_dir / job_id
            job_dir.mkdir(exist_ok=True, parents=True)
            
            # åŠ è½½åŸå§‹å›¾åƒ
            original_image = self._load_image(input_path)
            
            # ä¸“ä¸šç»‡æœºå¤„ç†æµæ°´çº¿
            processed_image = self._professional_pipeline(original_image, color_count)
            
            # æ•°å­—åŒ–è¯†åˆ«å›¾æ¨¡å¼ - å¢å¼ºé¢œè‰²é¥±å’Œåº¦å’Œå¯¹æ¯”åº¦
            if self.config["pure_weaving_mode"]:
                processed_image = self._apply_digital_recognition_style(processed_image)
                logger.info("  âœ“ æ•°å­—åŒ–è¯†åˆ«å›¾é£æ ¼å·²åº”ç”¨")
            
            # ä¸“ä¸šæ¨¡å¼ - æ·»åŠ è£…é¥°æ•ˆæœ
            if self.config["decorative_border"] or self.config["complex_decoration"]:
                final_image = self._add_decorations(processed_image)
                logger.info("  âœ“ ä¸“ä¸šè£…é¥°æ•ˆæœå·²åº”ç”¨")
            else:
                final_image = processed_image
            
            # åˆ›å»ºå¯¹æ¯”å›¾åƒ
            comparison_image = self._create_comparison(original_image, final_image)
            
            # ä¿å­˜ç»“æœ
            professional_path = job_dir / f"{job_id}_professional.png"
            comparison_path = job_dir / f"{job_id}_comparison.png"
            
            self._save_image(final_image, str(professional_path))
            self._save_image(comparison_image, str(comparison_path))
            
            processing_time = time.time() - start_time
            logger.info(f"ğŸ¯ ä¸“ä¸šç»‡æœºå›¾åƒç”Ÿæˆå®Œæˆï¼Œè€—æ—¶: {processing_time:.2f}ç§’")
            
            return str(professional_path), str(comparison_path), processing_time
            
        except Exception as e:
            error_msg = f"ä¸“ä¸šç»‡æœºå›¾åƒç”Ÿæˆå¤±è´¥: {str(e)}"
            logger.error(error_msg, exc_info=True)
            raise Exception(error_msg)
    
    def _load_image(self, input_path: str) -> np.ndarray:
        """åŠ è½½å›¾åƒ"""
        try:
            with Image.open(input_path) as pil_image:
                if pil_image.mode != 'RGB':
                    pil_image = pil_image.convert('RGB')
                return np.array(pil_image)
        except Exception as e:
            raise Exception(f"å›¾åƒåŠ è½½å¤±è´¥: {str(e)}")
    
    def _professional_pipeline(self, image: np.ndarray, color_count: int) -> np.ndarray:
        """ä¸“ä¸šç»‡æœºå¤„ç†æµæ°´çº¿ - é‡æ–°è®¾è®¡ï¼šå…ˆé”åŒ–åç®€åŒ–"""
        try:
            # 1. é¢„é”åŒ–ï¼šå…ˆå¢å¼ºè¾¹ç¼˜ï¼Œé˜²æ­¢åç»­å¤„ç†æ¨¡ç³ŠåŒ–
            pre_sharpened = self._extreme_pre_sharpening(image)
            logger.info("  âœ“ é¢„é”åŒ–å¤„ç†å®Œæˆ")
            
            # 2. æ™ºèƒ½é¢œè‰²é™è‰²ï¼ˆä¿æŒé”åº¦ï¼‰
            color_reduced = self._intelligent_color_reduction_preserve_edges(pre_sharpened, color_count)
            logger.info("  âœ“ æ™ºèƒ½é¢œè‰²é™è‰²å®Œæˆ")
            
            # 3. é¢œè‰²åŒºåŸŸè¿è´¯æ€§å¢å¼ºï¼ˆè½»åº¦å¤„ç†ï¼Œä¿æŒè¾¹ç¼˜ï¼‰
            coherent = self._enhance_color_coherence_preserve_edges(color_reduced)
            logger.info("  âœ“ é¢œè‰²åŒºåŸŸè¿è´¯æ€§å¢å¼ºå®Œæˆ")
            
            # 4. æœ€ç»ˆæåº¦é”åŒ–
            ultra_sharp = self._final_extreme_sharpening(coherent)
            logger.info("  âœ“ æœ€ç»ˆæåº¦é”åŒ–å®Œæˆ")
            
            # 5. ç»‡æœºè¯†åˆ«ä¼˜åŒ–ï¼ˆè½»åº¦å¤„ç†ï¼‰
            weaving_optimized = self._weaving_optimization_light(ultra_sharp)
            logger.info("  âœ“ ç»‡æœºè¯†åˆ«ä¼˜åŒ–å®Œæˆ")
            
            # 6. è´¨é‡å¢å¼ºï¼ˆä¸ä½¿ç”¨æŠ—é”¯é½¿ï¼Œä¿æŒé”åº¦ï¼‰
            enhanced = self._quality_enhancement_sharp(weaving_optimized)
            logger.info("  âœ“ è´¨é‡å¢å¼ºå®Œæˆ")
            
            # 7. ä¸“ä¸šçº§è‰ºæœ¯åŒ–å¤„ç†
            if self.config["professional_enhancement"]:
                artistic_enhanced = self._professional_artistic_enhancement(enhanced)
                logger.info("  âœ“ ä¸“ä¸šçº§è‰ºæœ¯åŒ–å¤„ç†å®Œæˆ")
                return artistic_enhanced
            
            return enhanced
            
        except Exception as e:
            raise Exception(f"ä¸“ä¸šç»‡æœºå¤„ç†å¤±è´¥: {str(e)}")
    
    def _extreme_pre_sharpening(self, image: np.ndarray) -> np.ndarray:
        """é¢„é”åŒ–å¤„ç† - åœ¨æ‰€æœ‰å¤„ç†ä¹‹å‰å…ˆæåº¦é”åŒ–"""
        try:
            # è¶…å¼ºé”åŒ–æ ¸
            kernel = np.array([
                [-4, -4, -4],
                [-4, 32, -4],
                [-4, -4, -4]
            ], dtype=np.float32)
            
            # åº”ç”¨é”åŒ–
            sharpened = cv2.filter2D(image, -1, kernel)
            
            # å¤šé‡Unsharp Mask
            for sigma in [0.3, 0.7, 1.2]:
                gaussian = cv2.GaussianBlur(image, (0, 0), sigma)
                unsharp = cv2.addWeighted(image, 4.0, gaussian, -3.0, 0)
                sharpened = cv2.addWeighted(sharpened, 0.8, unsharp, 0.2, 0)
            
            return np.clip(sharpened, 0, 255).astype(np.uint8)
            
        except Exception as e:
            logger.warning(f"é¢„é”åŒ–å¤±è´¥: {str(e)}")
            return image
    
    def _intelligent_color_reduction_preserve_edges(self, image: np.ndarray, n_colors: int) -> np.ndarray:
        """æ™ºèƒ½é¢œè‰²é™è‰² - ä¿æŒè¾¹ç¼˜é”åº¦ç‰ˆæœ¬"""
        try:
            # ä¿å­˜åŸå§‹è¾¹ç¼˜ä¿¡æ¯
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
            edges = cv2.Canny(gray, 30, 100)
            
            # æåº¦é™è‰²åˆ°æ›´å°‘é¢œè‰²
            reduced_colors = max(4, min(8, n_colors // 3))  # æ›´æ¿€è¿›çš„é™è‰²
            
            # K-meansèšç±»ï¼ˆä¸è¿›è¡Œé¢„æ¨¡ç³Šï¼Œä¿æŒé”åº¦ï¼‰
            pixels = image.reshape(-1, 3)
            kmeans = KMeans(
                n_clusters=reduced_colors,
                init='k-means++',
                n_init=50,
                max_iter=1000,
                random_state=42
            )
            
            kmeans.fit(pixels)
            colors = kmeans.cluster_centers_.astype(np.uint8)
            
            # æåº¦ä¼˜åŒ–é¢œè‰²
            colors = self._optimize_colors_extreme(colors)
            
            # æ›¿æ¢åƒç´ é¢œè‰²
            labels = kmeans.labels_
            reduced_pixels = colors[labels]
            result = reduced_pixels.reshape(image.shape)
            
            # åœ¨è¾¹ç¼˜åŒºåŸŸä¿æŒåŸå§‹é”åº¦
            edges_3d = cv2.cvtColor(edges, cv2.COLOR_GRAY2RGB) / 255.0
            result = result * (1 - edges_3d * 0.5) + image * (edges_3d * 0.5)
            
            # è‰²å½©é‡åŒ–
            result = (result // 16) * 16  # æ›´æ¿€è¿›çš„é‡åŒ–
            
            return np.clip(result, 0, 255).astype(np.uint8)
            
        except Exception as e:
            raise Exception(f"é¢œè‰²é™è‰²å¤±è´¥: {str(e)}")
    
    def _enhance_color_coherence_preserve_edges(self, image: np.ndarray) -> np.ndarray:
        """é¢œè‰²è¿è´¯æ€§å¢å¼º - ä¿æŒè¾¹ç¼˜ç‰ˆæœ¬"""
        try:
            # ä¿å­˜è¾¹ç¼˜ä¿¡æ¯
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
            edges = cv2.Canny(gray, 30, 100)
            
            # è½»åº¦è¿è´¯æ€§å¤„ç†
            unique_colors = self._get_unique_colors(image)
            result = image.copy()
            
            for color in unique_colors[:20]:  # åªå¤„ç†å‰20ç§ä¸»è¦é¢œè‰²
                color_np = np.array(color)
                diff = np.abs(result.astype(np.int16) - color_np.astype(np.int16))
                mask = np.sum(diff, axis=2) < 30
                
                if np.sum(mask) == 0:
                    continue
                
                # è½»åº¦å½¢æ€å­¦æ“ä½œ
                kernel_size = 7  # å°æ ¸å¿ƒï¼Œä¿æŒç»†èŠ‚
                kernel = np.ones((kernel_size, kernel_size), np.uint8)
                
                mask_processed = cv2.morphologyEx(mask.astype(np.uint8), cv2.MORPH_CLOSE, kernel)
                result[mask_processed > 0] = color
            
            # åœ¨éè¾¹ç¼˜åŒºåŸŸè½»åº¦å¹³æ»‘
            edges_3d = cv2.cvtColor(edges, cv2.COLOR_GRAY2RGB) / 255.0
            smoothed = cv2.bilateralFilter(result, 5, 50, 50)  # è½»åº¦å¹³æ»‘
            result = result * edges_3d + smoothed * (1 - edges_3d)
            
            return result.astype(np.uint8)
            
        except Exception as e:
            raise Exception(f"é¢œè‰²è¿è´¯æ€§å¢å¼ºå¤±è´¥: {str(e)}")
    
    def _final_extreme_sharpening(self, image: np.ndarray) -> np.ndarray:
        """æœ€ç»ˆæåº¦é”åŒ– - ä¸“ä¸šè½¯ä»¶çº§åˆ«çš„è¾¹ç¼˜æåŒ–"""
        try:
            # ç¬¬ä¸€è½®ï¼šè¾¹ç¼˜æ£€æµ‹å’ŒæåŒ–
            edges_polarized = self._polarize_edges(image)
            
            # ç¬¬äºŒè½®ï¼šè¶…å¼ºé”åŒ–æ ¸
            kernel1 = np.array([
                [-6, -6, -6],
                [-6, 48, -6],
                [-6, -6, -6]
            ], dtype=np.float32)
            
            sharpened1 = cv2.filter2D(edges_polarized, -1, kernel1)
            
            # ç¬¬ä¸‰è½®ï¼šå¤šçº§è¾¹ç¼˜å¢å¼º
            kernel2 = np.array([
                [-2, -3, -2],
                [-3, 16, -3],
                [-2, -3, -2]
            ], dtype=np.float32)
            
            sharpened2 = cv2.filter2D(sharpened1, -1, kernel2)
            
            # ç¬¬å››è½®ï¼šé«˜é€šæ»¤æ³¢å¢å¼º
            gaussian = cv2.GaussianBlur(image, (0, 0), 0.3)
            high_pass = cv2.addWeighted(image, 6.0, gaussian, -5.0, 0)
            
            # ç¬¬äº”è½®ï¼šæ‹‰æ™®æ‹‰æ–¯é”åŒ–
            laplacian_kernel = np.array([
                [0, -1, 0],
                [-1, 5, -1],
                [0, -1, 0]
            ], dtype=np.float32)
            
            laplacian_sharp = cv2.filter2D(sharpened2, -1, laplacian_kernel)
            
            # æ··åˆæ‰€æœ‰é”åŒ–ç»“æœ
            final_result = cv2.addWeighted(laplacian_sharp, 0.6, high_pass, 0.4, 0)
            
            # æœ€ç»ˆè¾¹ç¼˜å¼ºåŒ–
            final_result = self._enhance_edge_contrast(final_result)
            
            return np.clip(final_result, 0, 255).astype(np.uint8)
            
        except Exception as e:
            logger.warning(f"æœ€ç»ˆé”åŒ–å¤±è´¥: {str(e)}")
            return image
    
    def _polarize_edges(self, image: np.ndarray) -> np.ndarray:
        """è¾¹ç¼˜æåŒ–å¤„ç† - æ¨¡æ‹Ÿä¸“ä¸šè½¯ä»¶çš„æé”è¾¹ç¼˜"""
        try:
            # æ£€æµ‹è¾¹ç¼˜
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
            
            # å¤šæ–¹å‘è¾¹ç¼˜æ£€æµ‹
            sobel_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)
            sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
            
            # è®¡ç®—æ¢¯åº¦å¹…å€¼
            gradient_magnitude = np.sqrt(sobel_x**2 + sobel_y**2)
            
            # è¾¹ç¼˜æåŒ–ï¼šå¢å¼ºå¼ºè¾¹ç¼˜ï¼ŒæŠ‘åˆ¶å¼±è¾¹ç¼˜
            threshold = np.percentile(gradient_magnitude, 70)  # 70%åˆ†ä½æ•°ä½œä¸ºé˜ˆå€¼
            
            # åˆ›å»ºè¾¹ç¼˜æ©ç 
            strong_edges = gradient_magnitude > threshold
            weak_edges = (gradient_magnitude > threshold * 0.3) & (gradient_magnitude <= threshold)
            
            # å¯¹åŸå›¾åƒè¿›è¡Œè¾¹ç¼˜å¢å¼º
            result = image.copy().astype(np.float32)
            
            # åœ¨å¼ºè¾¹ç¼˜åŒºåŸŸæåº¦é”åŒ–
            for i in range(3):  # RGBä¸‰ä¸ªé€šé“
                channel = result[:, :, i]
                # å¼ºè¾¹ç¼˜åŒºåŸŸï¼šæåº¦å¢å¼ºå¯¹æ¯”åº¦
                channel[strong_edges] = channel[strong_edges] * 1.5
                # å¼±è¾¹ç¼˜åŒºåŸŸï¼šè½»åº¦å¢å¼º
                channel[weak_edges] = channel[weak_edges] * 1.2
                result[:, :, i] = channel
            
            return np.clip(result, 0, 255).astype(np.uint8)
            
        except Exception as e:
            logger.warning(f"è¾¹ç¼˜æåŒ–å¤±è´¥: {str(e)}")
            return image
    
    def _enhance_edge_contrast(self, image: np.ndarray) -> np.ndarray:
        """å¢å¼ºè¾¹ç¼˜å¯¹æ¯”åº¦ - æœ€ç»ˆè¾¹ç¼˜å¼ºåŒ–"""
        try:
            # æ£€æµ‹è¾¹ç¼˜
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
            edges = cv2.Canny(gray, 20, 80)
            
            # è†¨èƒ€è¾¹ç¼˜ï¼Œåˆ›å»ºè¾¹ç¼˜åŒºåŸŸ
            kernel = np.ones((3, 3), np.uint8)
            edge_regions = cv2.dilate(edges, kernel, iterations=1)
            
            # åœ¨è¾¹ç¼˜åŒºåŸŸå¢å¼ºå¯¹æ¯”åº¦
            result = image.copy().astype(np.float32)
            edge_mask = edge_regions > 0
            
            for i in range(3):  # RGBä¸‰ä¸ªé€šé“
                channel = result[:, :, i]
                # åœ¨è¾¹ç¼˜åŒºåŸŸåº”ç”¨Så‹å¯¹æ¯”åº¦å¢å¼º
                edge_pixels = channel[edge_mask]
                # Så‹æ›²çº¿ï¼šæš—çš„æ›´æš—ï¼Œäº®çš„æ›´äº®
                normalized = edge_pixels / 255.0
                enhanced = np.where(normalized < 0.5, 
                                  2 * normalized**2, 
                                  1 - 2 * (1 - normalized)**2)
                channel[edge_mask] = enhanced * 255
                result[:, :, i] = channel
            
            return np.clip(result, 0, 255).astype(np.uint8)
            
        except Exception as e:
            logger.warning(f"è¾¹ç¼˜å¯¹æ¯”åº¦å¢å¼ºå¤±è´¥: {str(e)}")
            return image
    
    def _weaving_optimization_light(self, image: np.ndarray) -> np.ndarray:
        """è½»åº¦ç»‡æœºè¯†åˆ«ä¼˜åŒ– - ä¿æŒé”åº¦"""
        try:
            # åªåšè½»å¾®çš„å™ªç‚¹æ¸…ç†ï¼Œä¸å½±å“è¾¹ç¼˜
            cleaned = cv2.medianBlur(image, 3)  # å°æ ¸å¿ƒ
            return cleaned
            
        except Exception as e:
            logger.warning(f"ç»‡æœºä¼˜åŒ–å¤±è´¥: {str(e)}")
            return image
    
    def _quality_enhancement_sharp(self, image: np.ndarray) -> np.ndarray:
        """è´¨é‡å¢å¼º - ä¿æŒé”åº¦ç‰ˆæœ¬"""
        try:
            # ä¸ä½¿ç”¨æŠ—é”¯é½¿ï¼Œç›´æ¥è¿›è¡Œè‰²å½©è°ƒæ•´
            pil_image = Image.fromarray(image)
            
            # æåº¦å¢å¼ºå¯¹æ¯”åº¦å’Œé¥±å’Œåº¦
            enhancer = ImageEnhance.Contrast(pil_image)
            enhanced = enhancer.enhance(self.config["contrast_boost"] * 1.5)
            
            enhancer = ImageEnhance.Color(enhanced)
            enhanced = enhancer.enhance(self.config["color_saturation_boost"] * 1.2)
            
            # å¢å¼ºé”åº¦
            enhancer = ImageEnhance.Sharpness(enhanced)
            enhanced = enhancer.enhance(2.0)  # 2å€é”åº¦
            
            return np.array(enhanced)
            
        except Exception as e:
            raise Exception(f"è´¨é‡å¢å¼ºå¤±è´¥: {str(e)}")
    
    def _professional_artistic_enhancement(self, image: np.ndarray) -> np.ndarray:
        """ä¸“ä¸šçº§è‰ºæœ¯åŒ–å¢å¼º - å¯¹æ ‡ä¸“ä¸šç»‡æœºè½¯ä»¶"""
        try:
            # 1. æè‡´è¾¹ç¼˜é”åŒ–
            ultra_sharpened = self._ultra_edge_sharpening(image)
            
            # 2. è‰ºæœ¯åŒ–èƒŒæ™¯ç”Ÿæˆ
            if self.config["artistic_background"]:
                artistic_bg = self._generate_artistic_background(ultra_sharpened)
            else:
                artistic_bg = ultra_sharpened
            
            # 3. å¤æ‚è£…é¥°å›¾æ¡ˆ
            if self.config["complex_decoration"]:
                decorated = self._add_complex_decorations(artistic_bg)
            else:
                decorated = artistic_bg
            
            return decorated
            
        except Exception as e:
            logger.warning(f"ä¸“ä¸šçº§è‰ºæœ¯åŒ–å¢å¼ºå¤±è´¥: {str(e)}")
            return image
    
    def _ultra_edge_sharpening(self, image: np.ndarray) -> np.ndarray:
        """æè‡´è¾¹ç¼˜é”åŒ–"""
        try:
            # åˆ›å»ºè¶…å¼ºé”åŒ–æ ¸
            intensity = self.config["edge_sharpening_intensity"]
            kernel = np.array([
                [-1, -1, -1, -1, -1],
                [-1, -2, -2, -2, -1],
                [-1, -2, 16+intensity*2, -2, -1],
                [-1, -2, -2, -2, -1],
                [-1, -1, -1, -1, -1]
            ]) / 9
            
            # åº”ç”¨æè‡´é”åŒ–
            ultra_sharp = cv2.filter2D(image, -1, kernel)
            
            # ä¸åŸå›¾æ··åˆï¼Œä¿æŒç»†èŠ‚
            result = cv2.addWeighted(image, 0.3, ultra_sharp, 0.7, 0)
            
            return result.astype(np.uint8)
            
        except Exception as e:
            logger.warning(f"æè‡´è¾¹ç¼˜é”åŒ–å¤±è´¥: {str(e)}")
            return image
    
    def _generate_artistic_background(self, image: np.ndarray) -> np.ndarray:
        """ç”ŸæˆAIå¢å¼ºçš„è‰ºæœ¯åŒ–èƒŒæ™¯"""
        try:
            height, width = image.shape[:2]
            
            # AIå¢å¼ºçš„ä¸»ä½“æ£€æµ‹
            main_object_mask = self._detect_main_object_enhanced(image)
            
            # ä½¿ç”¨AIç”Ÿæˆå™¨åˆ›å»ºä¸“ä¸šèƒŒæ™¯
            if self.ai_generator is not None:
                try:
                    # åˆ†æä¸»ä½“ç±»å‹
                    subject_type = "ç†ŠçŒ«"  # é»˜è®¤ï¼Œåç»­å¯ä»¥é€šè¿‡AIåˆ†æå¾—å‡º
                    if self.ai_processor is not None:
                        subject_info = self.ai_processor.analyze_image_content(image)
                        subject_type = subject_info.get('main_subject', 'ç†ŠçŒ«')
                    
                    # ç”Ÿæˆä¸“ä¸šçº§èƒŒæ™¯
                    professional_background = self.ai_generator.generate_professional_background(
                        width, height, subject_type
                    )
                    logger.info("AIä¸“ä¸šèƒŒæ™¯ç”ŸæˆæˆåŠŸ")
                    
                except Exception as e:
                    logger.warning(f"AIèƒŒæ™¯ç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•: {str(e)}")
                    professional_background = self._create_traditional_floral_pattern(height, width)
            else:
                # å›é€€åˆ°ä¼ ç»Ÿæ–¹æ³•
                professional_background = self._create_traditional_floral_pattern(height, width)
            
            # æ™ºèƒ½èåˆï¼šç»å¯¹ä¿æŠ¤ä¸»ä½“ï¼Œè£…é¥°èƒŒæ™¯
            artistic_image = image.copy()
            background_mask = ~main_object_mask
            
            if np.sum(background_mask) > 0:
                # èƒŒæ™¯åŒºåŸŸç”¨ä¸“ä¸šå›¾æ¡ˆ
                background_regions = artistic_image[background_mask]
                professional_regions = professional_background[background_mask]
                
                # 20% ä¸“ä¸šå›¾æ¡ˆ + 80% åŸå§‹è‰²è°ƒ (ä¿å®ˆèåˆ)
                blended = cv2.addWeighted(professional_regions, 0.2, background_regions, 0.8, 0)
                artistic_image[background_mask] = blended
            
            # ç»å¯¹ä¿æŠ¤ä¸»ä½“åŒºåŸŸ
            artistic_image[main_object_mask] = image[main_object_mask]
            
            return artistic_image
            
        except Exception as e:
            logger.warning(f"AIè‰ºæœ¯åŒ–èƒŒæ™¯ç”Ÿæˆå¤±è´¥: {str(e)}")
            return image
    
    def _detect_main_object_enhanced(self, image: np.ndarray) -> np.ndarray:
        """AIå¢å¼ºçš„ä¸»ä½“å¯¹è±¡æ£€æµ‹"""
        try:
            # å°è¯•ä½¿ç”¨AIå¢å¼ºæ£€æµ‹
            if self.ai_processor is not None:
                try:
                    # AIåˆ†æå›¾åƒå†…å®¹
                    subject_info = self.ai_processor.analyze_image_content(image)
                    logger.info(f"AIåˆ†æç»“æœ: {subject_info.get('main_subject', 'unknown')}")
                    
                    # åŸºäºAIç»“æœç”Ÿæˆæ™ºèƒ½æ©ç 
                    ai_mask = self.ai_processor.generate_smart_mask(image, subject_info)
                    
                    # éªŒè¯æ©ç æœ‰æ•ˆæ€§
                    if np.sum(ai_mask) > 0:
                        return ai_mask
                    else:
                        logger.warning("AIç”Ÿæˆçš„æ©ç æ— æ•ˆï¼Œå›é€€åˆ°ä¼ ç»Ÿæ–¹æ³•")
                        
                except Exception as e:
                    logger.warning(f"AIå¢å¼ºæ£€æµ‹å¤±è´¥: {str(e)}")
            
            # å›é€€åˆ°ä¼ ç»Ÿæ£€æµ‹æ–¹æ³•
            return self._detect_main_object_fallback(image)
            
        except Exception as e:
            logger.warning(f"ä¸»ä½“æ£€æµ‹å¤±è´¥: {str(e)}")
            return self._detect_main_object_fallback(image)
    
    def _detect_texture_similarity(self, image: np.ndarray, center_x: int, center_y: int) -> np.ndarray:
        """åŸºäºçº¹ç†ç›¸ä¼¼æ€§çš„åŒºåŸŸæ£€æµ‹"""
        try:
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
            height, width = gray.shape
            
            # ç®€åŒ–çš„çº¹ç†ç‰¹å¾ï¼ˆå±€éƒ¨æ ‡å‡†å·®ï¼‰
            kernel_size = 9
            kernel = np.ones((kernel_size, kernel_size), np.float32) / (kernel_size * kernel_size)
            mean_filtered = cv2.filter2D(gray.astype(np.float32), -1, kernel)
            sqr_filtered = cv2.filter2D((gray.astype(np.float32))**2, -1, kernel)
            texture = np.sqrt(np.maximum(0, sqr_filtered - mean_filtered**2))
            
            # è·å–ä¸­å¿ƒåŒºåŸŸçš„çº¹ç†ç‰¹å¾
            center_texture = texture[center_y, center_x]
            
            # ç›¸ä¼¼æ€§æ©ç 
            texture_diff = np.abs(texture - center_texture)
            similarity_mask = texture_diff < (center_texture * 0.5 + 10)
            
            return similarity_mask
            
        except Exception as e:
            logger.warning(f"çº¹ç†ç›¸ä¼¼æ€§æ£€æµ‹å¤±è´¥: {str(e)}")
            return np.ones(image.shape[:2], dtype=bool)
    
    def _detect_main_object_fallback(self, image: np.ndarray) -> np.ndarray:
        """ä¸»ä½“æ£€æµ‹å›é€€æ–¹æ³•"""
        try:
            height, width = image.shape[:2]
            
            # åŸºäºè¾¹ç¼˜æ£€æµ‹çš„ç®€å•æ–¹æ³•
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
            edges = cv2.Canny(gray, 50, 150)
            
            # å½¢æ€å­¦æ“ä½œè¿æ¥è¾¹ç¼˜
            kernel = np.ones((5, 5), np.uint8)
            edges_closed = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel)
            
            # å¡«å……å†…éƒ¨åŒºåŸŸ
            contours, _ = cv2.findContours(edges_closed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            mask = np.zeros((height, width), dtype=np.uint8)
            
            if contours:
                # é€‰æ‹©é¢ç§¯æœ€å¤§çš„è½®å»“
                largest_contour = max(contours, key=cv2.contourArea)
                cv2.fillPoly(mask, [largest_contour], 255)
            
            return mask > 0
            
        except Exception as e:
            logger.warning(f"å›é€€ä¸»ä½“æ£€æµ‹å¤±è´¥: {str(e)}")
            return np.zeros(image.shape[:2], dtype=bool)
    
    def _create_traditional_floral_pattern(self, height: int, width: int) -> np.ndarray:
        """åˆ›å»ºä¼ ç»ŸèŠ±å‰å›¾æ¡ˆ"""
        try:
            # åˆ›å»ºèŠ±å‰èƒŒæ™¯å›¾æ¡ˆ
            pattern = np.zeros((height, width, 3), dtype=np.uint8)
            
            # å®šä¹‰ä¼ ç»Ÿè‰²å½©è°ƒè‰²æ¿
            colors = [
                (139, 69, 19),    # è¤è‰²
                (160, 82, 45),    # éè¤è‰²  
                (210, 180, 140),  # æ£•è¤è‰²
                (222, 184, 135),  # æµ…è¤è‰²
                (245, 245, 220),  # ç±³è‰²
                (255, 228, 196),  # æµ…æ£•è‰²
                (205, 133, 63),   # ç§˜é²è‰²
                (188, 143, 143),  # ç«ç‘°è¤è‰²
            ]
            
            # ç”ŸæˆåŸºç¡€æ¸å˜èƒŒæ™¯
            for y in range(height):
                for x in range(width):
                    # åŸºäºä½ç½®çš„é¢œè‰²å˜åŒ–
                    color_idx = int((x / width + y / height) * len(colors) / 2) % len(colors)
                    pattern[y, x] = colors[color_idx]
            
            # æ·»åŠ èŠ±å‰å›¾æ¡ˆçº¹ç†
            pattern = self._add_floral_texture(pattern)
            
            # æ·»åŠ ç»†èŠ‚è£…é¥°
            pattern = self._add_traditional_details(pattern)
            
            return pattern
            
        except Exception as e:
            logger.warning(f"ä¼ ç»ŸèŠ±å‰å›¾æ¡ˆåˆ›å»ºå¤±è´¥: {str(e)}")
            return np.full((height, width, 3), (139, 69, 19), dtype=np.uint8)
    
    def _add_floral_texture(self, pattern: np.ndarray) -> np.ndarray:
        """æ·»åŠ èŠ±å‰çº¹ç†"""
        try:
            height, width = pattern.shape[:2]
            
            # ä½¿ç”¨æ­£å¼¦æ³¢ç”ŸæˆèŠ±å‰å›¾æ¡ˆ
            for y in range(0, height, 25):
                for x in range(0, width, 25):
                    # ç”ŸæˆèŠ±æœµä¸­å¿ƒ
                    center_x, center_y = x + 12, y + 12
                    if center_x < width and center_y < height:
                        
                        # èŠ±æœµä¸»ä½“ï¼ˆåœ†å½¢æ¸å˜ï¼‰
                        for dy in range(-8, 9):
                            for dx in range(-8, 9):
                                px, py = center_x + dx, center_y + dy
                                if 0 <= px < width and 0 <= py < height:
                                    distance = np.sqrt(dx*dx + dy*dy)
                                    if distance <= 8:
                                        # èŠ±æœµé¢œè‰²ï¼ˆæ›´äº®çš„è‰²è°ƒï¼‰
                                        intensity = max(0, 1 - distance/8)
                                        flower_color = np.array([200, 150, 100]) * intensity
                                        pattern[py, px] = np.clip(pattern[py, px] + flower_color, 0, 255)
                        
                        # èŠ±ç“£ï¼ˆæ¤­åœ†å½¢ï¼‰
                        for angle in [0, 60, 120, 180, 240, 300]:
                            rad = np.radians(angle)
                            petal_x = center_x + int(12 * np.cos(rad))
                            petal_y = center_y + int(12 * np.sin(rad))
                            
                            if 0 <= petal_x < width and 0 <= petal_y < height:
                                # èŠ±ç“£æ¤­åœ†
                                cv2.ellipse(pattern, (petal_x, petal_y), (6, 3), angle, 0, 360, 
                                          (180, 120, 80), -1)
            
            return pattern
            
        except Exception as e:
            logger.warning(f"èŠ±å‰çº¹ç†æ·»åŠ å¤±è´¥: {str(e)}")
            return pattern
    
    def _add_traditional_details(self, pattern: np.ndarray) -> np.ndarray:
        """æ·»åŠ ä¼ ç»Ÿè£…é¥°ç»†èŠ‚"""
        try:
            height, width = pattern.shape[:2]
            
            # æ·»åŠ è—¤è”“è¿æ¥çº¿
            for y in range(0, height, 50):
                for x in range(0, width-50, 50):
                    # Så½¢è—¤è”“
                    points = []
                    for t in range(0, 51, 5):
                        curve_x = x + t
                        curve_y = y + int(10 * np.sin(t * 0.2))
                        if 0 <= curve_x < width and 0 <= curve_y < height:
                            points.append([curve_x, curve_y])
                    
                    if len(points) > 1:
                        points = np.array(points, dtype=np.int32)
                        cv2.polylines(pattern, [points], False, (100, 80, 60), 2)
            
            # æ·»åŠ å°å¶å­
            for y in range(15, height, 40):
                for x in range(15, width, 40):
                    if x < width and y < height:
                        # å¶å­å½¢çŠ¶
                        leaf_points = np.array([
                            [x, y-5], [x+3, y-2], [x+5, y], 
                            [x+3, y+2], [x, y+5], [x-3, y+2],
                            [x-5, y], [x-3, y-2]
                        ], dtype=np.int32)
                        
                        cv2.fillPoly(pattern, [leaf_points], (120, 100, 70))
            
            return pattern
            
        except Exception as e:
            logger.warning(f"ä¼ ç»Ÿè£…é¥°ç»†èŠ‚æ·»åŠ å¤±è´¥: {str(e)}")
            return pattern
    
    def _add_mini_pattern(self, image: np.ndarray, x: int, y: int):
        """æ·»åŠ å°å‹è‰ºæœ¯å›¾æ¡ˆ"""
        try:
            height, width = image.shape[:2]
            pattern_size = 15
            
            if x + pattern_size >= width or y + pattern_size >= height:
                return
            
            # è·å–å½“å‰åŒºåŸŸçš„ä¸»å¯¼è‰²
            region = image[y:y+pattern_size, x:x+pattern_size]
            main_color = np.mean(region.reshape(-1, 3), axis=0).astype(np.uint8)
            
            # ç”Ÿæˆå¯¹æ¯”è‰²
            contrast_color = 255 - main_color
            
            # æ·»åŠ å°å‹å‡ ä½•å›¾æ¡ˆ
            pattern_type = (x + y) % 4
            
            if pattern_type == 0:
                # å°åœ†ç‚¹
                cv2.circle(image, (x+7, y+7), 3, contrast_color.tolist(), -1)
            elif pattern_type == 1:
                # å°è±å½¢
                pts = np.array([[x+7, y+2], [x+12, y+7], [x+7, y+12], [x+2, y+7]], np.int32)
                cv2.fillPoly(image, [pts], contrast_color.tolist())
            elif pattern_type == 2:
                # å°åå­—
                cv2.line(image, (x+3, y+7), (x+11, y+7), contrast_color.tolist(), 2)
                cv2.line(image, (x+7, y+3), (x+7, y+11), contrast_color.tolist(), 2)
            else:
                # å°æ–¹å½¢
                cv2.rectangle(image, (x+4, y+4), (x+10, y+10), contrast_color.tolist(), 1)
                
        except Exception as e:
            logger.warning(f"å°å‹å›¾æ¡ˆæ·»åŠ å¤±è´¥: {str(e)}")
    
    def _add_complex_decorations(self, image: np.ndarray) -> np.ndarray:
        """æ·»åŠ å¤æ‚è£…é¥°å›¾æ¡ˆ"""
        try:
            height, width = image.shape[:2]
            decorated = image.copy()
            
            # åœ¨è¾¹ç¼˜åŒºåŸŸæ·»åŠ æ›´å¤æ‚çš„è£…é¥°
            border_width = 30
            
            # é¡¶éƒ¨å’Œåº•éƒ¨è£…é¥°
            for y in [10, height-40]:
                for x in range(border_width, width-border_width, 25):
                    self._add_decorative_motif(decorated, x, y)
            
            # å·¦ä¾§å’Œå³ä¾§è£…é¥°
            for x in [10, width-40]:
                for y in range(border_width, height-border_width, 25):
                    self._add_decorative_motif(decorated, x, y)
            
            return decorated
            
        except Exception as e:
            logger.warning(f"å¤æ‚è£…é¥°æ·»åŠ å¤±è´¥: {str(e)}")
            return image
    
    def _add_decorative_motif(self, image: np.ndarray, x: int, y: int):
        """æ·»åŠ è£…é¥°ä¸»é¢˜å›¾æ¡ˆ"""
        try:
            height, width = image.shape[:2]
            if x + 20 >= width or y + 20 >= height or x < 0 or y < 0:
                return
            
            # èœ€é”¦é£æ ¼è£…é¥°è‰²å½©
            colors = [
                (255, 215, 0),    # é‡‘è‰²
                (220, 20, 60),    # æ·±çº¢
                (0, 100, 0),      # æ·±ç»¿
                (139, 69, 19),    # æ£•è‰²
                (75, 0, 130),     # ç´«è‰²
            ]
            
            color = colors[(x + y) % len(colors)]
            
            # ç»˜åˆ¶å¤æ‚å›¾æ¡ˆ
            # å¤–åœˆ
            cv2.circle(image, (x+10, y+10), 8, color, 2)
            # å†…éƒ¨è£…é¥°
            cv2.circle(image, (x+10, y+10), 4, color, 1)
            # åå­—è£…é¥°
            cv2.line(image, (x+6, y+10), (x+14, y+10), color, 1)
            cv2.line(image, (x+10, y+6), (x+10, y+14), color, 1)
            # è§’è½ç‚¹ç¼€
            for dx, dy in [(2, 2), (18, 2), (2, 18), (18, 18)]:
                cv2.circle(image, (x+dx, y+dy), 1, color, -1)
                
        except Exception as e:
            logger.warning(f"è£…é¥°å›¾æ¡ˆæ·»åŠ å¤±è´¥: {str(e)}")

    def _add_decorations(self, image: np.ndarray) -> np.ndarray:
        """æ·»åŠ ä¸“ä¸šè£…é¥°"""
        try:
            if not self.config["decorative_border"]:
                return image
            
            pil_image = Image.fromarray(image)
            width, height = pil_image.size
            
            # åˆ›å»ºå¸¦è¾¹æ¡†çš„å›¾åƒ
            border_width = 20
            new_width = width + 2 * border_width
            new_height = height + 2 * border_width
            
            # ç²‰è‰²è¾¹æ¡†ï¼ˆæ¨¡ä»¿ä¸“ä¸šè½¯ä»¶ï¼‰
            border_color = (255, 192, 203)
            bordered_image = Image.new('RGB', (new_width, new_height), border_color)
            
            # ç²˜è´´åŸå›¾åƒ
            bordered_image.paste(pil_image, (border_width, border_width))
            
            # æ·»åŠ è£…é¥°å›¾æ¡ˆ
            bordered_image = self._add_decorative_pattern(bordered_image)
            
            return np.array(bordered_image)
            
        except Exception as e:
            logger.warning(f"è£…é¥°æ·»åŠ å¤±è´¥: {str(e)}")
            return image
    
    def _add_decorative_pattern(self, pil_image: Image.Image) -> Image.Image:
        """æ·»åŠ è£…é¥°å›¾æ¡ˆ"""
        try:
            draw = ImageDraw.Draw(pil_image)
            width, height = pil_image.size
            pattern_color = (255, 255, 255)
            
            # åœ¨è¾¹æ¡†ä¸Šç»˜åˆ¶è£…é¥°åœ†ç‚¹
            for i in range(10, width-10, 30):
                draw.ellipse([i-3, 7, i+3, 13], fill=pattern_color)
                draw.ellipse([i-3, height-13, i+3, height-7], fill=pattern_color)
            
            for i in range(10, height-10, 30):
                draw.ellipse([7, i-3, 13, i+3], fill=pattern_color)
                draw.ellipse([width-13, i-3, width-7, i+3], fill=pattern_color)
            
            return pil_image
            
        except Exception as e:
            logger.warning(f"è£…é¥°å›¾æ¡ˆå¤±è´¥: {str(e)}")
            return pil_image
    
    def _create_comparison(self, original: np.ndarray, processed: np.ndarray) -> np.ndarray:
        """åˆ›å»ºå¯¹æ¯”å›¾åƒ"""
        try:
            # ç¡®ä¿å°ºå¯¸ä¸€è‡´
            if original.shape != processed.shape:
                original = cv2.resize(original, (processed.shape[1], processed.shape[0]))
            
            # åˆ›å»ºå¹¶æ’å¯¹æ¯”
            comparison = np.hstack([original, processed])
            
            # æ·»åŠ æ ‡æ³¨
            pil_comparison = Image.fromarray(comparison)
            draw = ImageDraw.Draw(pil_comparison)
            
            width, height = pil_comparison.size
            
            # æ ‡æ³¨æ–‡å­—
            try:
                # å°è¯•ä½¿ç”¨é»˜è®¤å­—ä½“
                font = ImageFont.load_default()
            except:
                font = None
            
            draw.text((width//4, 10), "åŸå§‹å›¾åƒ", fill=(255, 255, 255), font=font, anchor="mm")
            draw.text((3*width//4, 10), "ä¸“ä¸šç»‡æœºå¤„ç†", fill=(255, 255, 255), font=font, anchor="mm")
            
            # åˆ†éš”çº¿
            draw.line([(width//2, 0), (width//2, height)], fill=(255, 255, 255), width=2)
            
            return np.array(pil_comparison)
            
        except Exception as e:
            logger.warning(f"å¯¹æ¯”å›¾åƒåˆ›å»ºå¤±è´¥: {str(e)}")
            return processed
    
    def _save_image(self, image: np.ndarray, output_path: str):
        """ä¿å­˜å›¾åƒ"""
        try:
            pil_image = Image.fromarray(image)
            
            save_kwargs = {
                'format': 'PNG',
                'optimize': False,
                'compress_level': 0,
            }
            
            pil_image.save(output_path, **save_kwargs)
            
            file_size = Path(output_path).stat().st_size
            logger.info(f"å›¾åƒå·²ä¿å­˜: {Path(output_path).name} ({file_size/1024/1024:.2f} MB)")
            
        except Exception as e:
            raise Exception(f"å›¾åƒä¿å­˜å¤±è´¥: {str(e)}")
    
    def _get_unique_colors(self, image: np.ndarray) -> List[Tuple[int, int, int]]:
        """è·å–å”¯ä¸€é¢œè‰²"""
        try:
            pixels = image.reshape(-1, 3)
            unique_colors = np.unique(pixels, axis=0)
            return [tuple(color) for color in unique_colors]
        except Exception as e:
            logger.warning(f"è·å–é¢œè‰²å¤±è´¥: {str(e)}")
            return []

    def _intelligent_color_reduction(self, image: np.ndarray, n_colors: int) -> np.ndarray:
        """æ™ºèƒ½é¢œè‰²é™è‰² - åŸç‰ˆæœ¬ä¿ç•™ä½œä¸ºå¤‡ç”¨"""
        try:
            # é¢„å¤„ç†ï¼šè½»å¾®æ¨¡ç³Šå‡å°‘å™ªå£°
            blurred = cv2.GaussianBlur(image, (3, 3), 0.8)
            
            # K-meansèšç±»
            pixels = blurred.reshape(-1, 3)
            kmeans = KMeans(
                n_clusters=n_colors,
                init='k-means++',
                n_init=30,
                max_iter=500,
                random_state=42
            )
            
            kmeans.fit(pixels)
            colors = kmeans.cluster_centers_.astype(np.uint8)
            
            # é¢œè‰²ä¼˜åŒ–ï¼šå¢å¼ºé¥±å’Œåº¦
            colors = self._optimize_colors(colors)
            
            # æ›¿æ¢åƒç´ é¢œè‰²
            labels = kmeans.labels_
            reduced_pixels = colors[labels]
            
            return reduced_pixels.reshape(image.shape)
            
        except Exception as e:
            raise Exception(f"é¢œè‰²é™è‰²å¤±è´¥: {str(e)}")
    
    def _optimize_colors(self, colors: np.ndarray) -> np.ndarray:
        """ä¼˜åŒ–é¢œè‰²"""
        try:
            optimized = []
            
            for color in colors:
                # è½¬æ¢ä¸ºHSVè°ƒæ•´é¥±å’Œåº¦
                hsv = cv2.cvtColor(color.reshape(1, 1, 3), cv2.COLOR_RGB2HSV)[0, 0]
                
                # å¢å¼ºé¥±å’Œåº¦
                hsv[1] = min(255, int(hsv[1] * self.config["color_saturation_boost"]))
                
                # è°ƒæ•´äº®åº¦å¢å¼ºå¯¹æ¯”åº¦
                if hsv[2] > 128:
                    hsv[2] = min(255, int(hsv[2] * 1.1))
                else:
                    hsv[2] = max(0, int(hsv[2] * 0.9))
                
                # è½¬æ¢å›RGB
                rgb = cv2.cvtColor(hsv.reshape(1, 1, 3), cv2.COLOR_HSV2RGB)[0, 0]
                optimized.append(rgb)
            
            return np.array(optimized, dtype=np.uint8)
            
        except Exception as e:
            logger.warning(f"é¢œè‰²ä¼˜åŒ–å¤±è´¥: {str(e)}")
            return colors
    
    def _optimize_colors_extreme(self, colors: np.ndarray) -> np.ndarray:
        """æåº¦ä¼˜åŒ–é¢œè‰² - çœŸæ­£è¯†åˆ«å›¾é£æ ¼"""
        try:
            # æåº¦å¢å¼ºé¥±å’Œåº¦
            hsv = cv2.cvtColor(colors.reshape(1, -1, 3), cv2.COLOR_RGB2HSV)
            hsv[:, :, 1] = np.clip(hsv[:, :, 1] * 2.5, 0, 255)  # æåº¦å¢å¼ºé¥±å’Œåº¦
            enhanced_colors = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB).reshape(-1, 3)
            
            # æåº¦å¢å¼ºå¯¹æ¯”åº¦
            enhanced_colors = np.clip(enhanced_colors * 2.2, 0, 255)
            
            # æåº¦è‰²å½©é‡åŒ– - ç¡®ä¿çº¯è‰²å—æ•ˆæœ
            enhanced_colors = (enhanced_colors // 64) * 64  # æ›´æ¿€è¿›çš„é‡åŒ–
            
            # åº”ç”¨é˜ˆå€¼å¤„ç† - å¢å¼ºé»‘ç™½å¯¹æ¯”
            gray = cv2.cvtColor(enhanced_colors.reshape(1, -1, 3), cv2.COLOR_RGB2GRAY)
            _, thresh = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY)
            
            # å°†é˜ˆå€¼ç»“æœåº”ç”¨åˆ°é¢œè‰²é€šé“
            enhanced_colors = enhanced_colors.reshape(-1, 3)
            for i in range(len(enhanced_colors)):
                if thresh[0, i] > 128:
                    enhanced_colors[i] = np.clip(enhanced_colors[i] * 1.2, 0, 255)  # äº®éƒ¨æ›´äº®
                else:
                    enhanced_colors[i] = np.clip(enhanced_colors[i] * 0.8, 0, 255)  # æš—éƒ¨æ›´æš—
            
            return enhanced_colors.astype(np.uint8)
            
        except Exception as e:
            logger.warning(f"æåº¦é¢œè‰²ä¼˜åŒ–å¤±è´¥: {str(e)}")
            return colors
    
    def _apply_digital_recognition_style(self, image: np.ndarray) -> np.ndarray:
        """åº”ç”¨æ•°å­—åŒ–è¯†åˆ«å›¾é£æ ¼ - ä¸“ä¸šè¯†åˆ«å›¾ç‰ˆæœ¬"""
        try:
            # è½¬æ¢ä¸ºPILå›¾åƒè¿›è¡Œå¤„ç†
            pil_image = Image.fromarray(image)
            
            # 1. æåº¦å¢å¼ºé¥±å’Œåº¦
            enhancer = ImageEnhance.Color(pil_image)
            pil_image = enhancer.enhance(self.config["color_saturation_boost"])
            
            # 2. æåº¦å¢å¼ºå¯¹æ¯”åº¦
            enhancer = ImageEnhance.Contrast(pil_image)
            pil_image = enhancer.enhance(self.config["contrast_boost"])
            
            # è½¬æ¢å›numpyæ•°ç»„è¿›è¡Œä¸“ä¸šå¤„ç†
            result = np.array(pil_image)
            
            # 3. ä¸“ä¸šé¢œè‰²èšç±» - å‡å°‘åˆ°4-6ç§ä¸»è¦é¢œè‰²
            result = self._professional_color_clustering(result, n_colors=6)
            
            # 4. å›¾åƒåˆ†å‰²å’ŒåŒºåŸŸåˆå¹¶
            result = self._image_segmentation_and_merging(result)
            
            # 5. è¾¹ç¼˜æ£€æµ‹å’Œå¼ºåŒ–
            result = self._edge_detection_and_enhancement(result)
            
            # 6. æœ€ç»ˆé¢œè‰²ä¼˜åŒ–
            result = self._final_color_optimization(result)
            
            return result.astype(np.uint8)
            
        except Exception as e:
            logger.warning(f"æ•°å­—åŒ–è¯†åˆ«å›¾é£æ ¼åº”ç”¨å¤±è´¥: {str(e)}")
            return image
    
    def _professional_color_clustering(self, image: np.ndarray, n_colors: int = 6) -> np.ndarray:
        """ä¸“ä¸šé¢œè‰²èšç±» - ä½¿ç”¨K-meansèšç±»"""
        try:
            # é‡å¡‘å›¾åƒä¸º2Dæ•°ç»„
            pixels = image.reshape(-1, 3)
            
            # ä½¿ç”¨K-meansèšç±»
            from sklearn.cluster import KMeans
            kmeans = KMeans(n_clusters=n_colors, random_state=42, n_init=10)
            labels = kmeans.fit_predict(pixels)
            
            # è·å–èšç±»ä¸­å¿ƒä½œä¸ºä¸»è¦é¢œè‰²
            centers = kmeans.cluster_centers_.astype(np.uint8)
            
            # å°†æ¯ä¸ªåƒç´ æ›¿æ¢ä¸ºæœ€è¿‘çš„èšç±»ä¸­å¿ƒ
            clustered_pixels = centers[labels]
            
            # é‡å¡‘å›åŸå§‹å½¢çŠ¶
            result = clustered_pixels.reshape(image.shape)
            
            return result
            
        except Exception as e:
            logger.warning(f"é¢œè‰²èšç±»å¤±è´¥: {str(e)}")
            return image
    
    def _image_segmentation_and_merging(self, image: np.ndarray) -> np.ndarray:
        """å›¾åƒåˆ†å‰²å’ŒåŒºåŸŸåˆå¹¶"""
        try:
            # è½¬æ¢ä¸ºç°åº¦å›¾è¿›è¡Œåˆ†å‰²
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
            
            # ä½¿ç”¨åˆ†æ°´å²­ç®—æ³•è¿›è¡Œå›¾åƒåˆ†å‰²
            # åº”ç”¨é«˜æ–¯æ¨¡ç³Šå‡å°‘å™ªç‚¹
            blurred = cv2.GaussianBlur(gray, (5, 5), 0)
            
            # ä½¿ç”¨Otsu'sæ–¹æ³•è¿›è¡Œé˜ˆå€¼åˆ†å‰²
            _, thresh = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
            
            # å½¢æ€å­¦æ“ä½œæ¸…ç†åˆ†å‰²ç»“æœ
            kernel = np.ones((3,3), np.uint8)
            opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)
            
            # ç¡®å®šèƒŒæ™¯åŒºåŸŸ
            sure_bg = cv2.dilate(opening, kernel, iterations=3)
            
            # è·ç¦»å˜æ¢
            dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)
            
            # ç¡®å®šå‰æ™¯åŒºåŸŸ
            _, sure_fg = cv2.threshold(dist_transform, 0.7*dist_transform.max(), 255, 0)
            sure_fg = np.uint8(sure_fg)
            
            # æ‰¾åˆ°æœªçŸ¥åŒºåŸŸ
            unknown = cv2.subtract(sure_bg, sure_fg)
            
            # æ ‡è®°
            _, markers = cv2.connectedComponents(sure_fg)
            markers = markers + 1
            markers[unknown == 255] = 0
            
            # åº”ç”¨åˆ†æ°´å²­ç®—æ³•
            markers = cv2.watershed(image, markers)
            
            # æ ¹æ®åˆ†å‰²ç»“æœé‡æ–°ç€è‰²
            result = image.copy()
            for i in range(2, markers.max() + 1):
                mask = (markers == i)
                if mask.sum() > 100:  # åªå¤„ç†è¶³å¤Ÿå¤§çš„åŒºåŸŸ
                    # è®¡ç®—è¯¥åŒºåŸŸçš„å¹³å‡é¢œè‰²
                    region_colors = image[mask]
                    avg_color = np.mean(region_colors, axis=0).astype(np.uint8)
                    result[mask] = avg_color
            
            return result
            
        except Exception as e:
            logger.warning(f"å›¾åƒåˆ†å‰²å¤±è´¥: {str(e)}")
            return image
    
    def _edge_detection_and_enhancement(self, image: np.ndarray) -> np.ndarray:
        """è¾¹ç¼˜æ£€æµ‹å’Œå¼ºåŒ–"""
        try:
            # è½¬æ¢ä¸ºç°åº¦å›¾
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
            
            # ä½¿ç”¨Cannyè¾¹ç¼˜æ£€æµ‹
            edges = cv2.Canny(gray, 50, 150)
            
            # è†¨èƒ€è¾¹ç¼˜
            kernel = np.ones((2,2), np.uint8)
            edges = cv2.dilate(edges, kernel, iterations=1)
            
            # å°†è¾¹ç¼˜åº”ç”¨åˆ°åŸå›¾
            result = image.copy()
            result[edges > 0] = [0, 0, 0]  # è¾¹ç¼˜è®¾ä¸ºé»‘è‰²
            
            # åº”ç”¨å½¢æ€å­¦é—­è¿ç®—å¡«å……å°å­”
            kernel = np.ones((3,3), np.uint8)
            for i in range(3):
                channel = result[:,:,i]
                channel = cv2.morphologyEx(channel, cv2.MORPH_CLOSE, kernel)
                result[:,:,i] = channel
            
            return result
            
        except Exception as e:
            logger.warning(f"è¾¹ç¼˜æ£€æµ‹å¤±è´¥: {str(e)}")
            return image
    
    def _final_color_optimization(self, image: np.ndarray) -> np.ndarray:
        """æœ€ç»ˆé¢œè‰²ä¼˜åŒ–"""
        try:
            # è½¬æ¢ä¸ºHSVè¿›è¡Œæœ€ç»ˆè°ƒæ•´
            hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)
            
            # æåº¦å¢å¼ºé¥±å’Œåº¦
            hsv[:, :, 1] = np.clip(hsv[:, :, 1] * 3.0, 0, 255)
            
            # å¢å¼ºå¯¹æ¯”åº¦
            hsv[:, :, 2] = np.clip(hsv[:, :, 2] * 1.5, 0, 255)
            
            # è½¬æ¢å›RGB
            result = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)
            
            # æœ€ç»ˆè‰²å½©é‡åŒ– - ç¡®ä¿çº¯è‰²æ•ˆæœ
            result = (result // 85) * 85  # é‡åŒ–åˆ°85çš„å€æ•°ï¼Œç¡®ä¿çº¯è‰²
            
            return result.astype(np.uint8)
            
        except Exception as e:
            logger.warning(f"æœ€ç»ˆé¢œè‰²ä¼˜åŒ–å¤±è´¥: {str(e)}")
            return image