"""
ä¸“ä¸šç»‡æœºè¯†åˆ«å›¾åƒç”Ÿæˆå™¨
åŸºäºå¯¹ä¸“ä¸šç»‡æœºè½¯ä»¶çš„åˆ†æï¼Œä¼˜åŒ–å›¾åƒå¤„ç†ç®—æ³•ä»¥è¾¾åˆ°ä¸“ä¸šçº§åˆ«çš„æ•ˆæœ
"""

import cv2
import numpy as np
from PIL import Image, ImageFilter, ImageEnhance, ImageOps, ImageDraw
from sklearn.cluster import KMeans
import os
import logging
import time
from pathlib import Path
from typing import Tuple, List, Optional, Dict, Any
from scipy import ndimage
from scipy.spatial.distance import cdist
import warnings

# æŠ‘åˆ¶ä¸å¿…è¦çš„è­¦å‘Š
warnings.filterwarnings('ignore', category=UserWarning)

logger = logging.getLogger(__name__)


class ProfessionalWeavingImageGenerator:
    """
    ä¸“ä¸šç»‡æœºè¯†åˆ«å›¾åƒç”Ÿæˆå™¨
    
    åŸºäºä¸“ä¸šç»‡æœºè½¯ä»¶çš„æ•ˆæœåˆ†æï¼Œå®ç°ï¼š
    1. é«˜è´¨é‡é¢œè‰²åŒºåŸŸè¿è´¯æ€§
    2. ä¸“ä¸šçº§è¾¹ç¼˜é”åŒ–
    3. è‰ºæœ¯åŒ–èƒŒæ™¯è£…é¥°
    4. ç»‡æœºè¯†åˆ«ä¼˜åŒ–
    """
    
    def __init__(self, outputs_dir: str = "outputs"):
        """åˆå§‹åŒ–ä¸“ä¸šå›¾åƒç”Ÿæˆå™¨"""
        self.outputs_dir = Path(outputs_dir)
        self.outputs_dir.mkdir(exist_ok=True, parents=True)
        
        # ä¸“ä¸šç»‡æœºé…ç½®
        self.weaving_config = {
            # é¢œè‰²å¤„ç†
            "color_connectivity_strength": 15,  # é¢œè‰²è¿é€šæ€§å¼ºåº¦
            "color_smoothing_radius": 8,        # é¢œè‰²å¹³æ»‘åŠå¾„
            "dominant_color_threshold": 0.02,   # ä¸»å¯¼è‰²é˜ˆå€¼
            
            # è¾¹ç¼˜å¤„ç†
            "edge_sharpening_intensity": 2.5,   # è¾¹ç¼˜é”åŒ–å¼ºåº¦
            "contour_enhancement": True,        # è½®å»“å¢å¼º
            "edge_smoothing": True,            # è¾¹ç¼˜å¹³æ»‘
            
            # åŒºåŸŸå¤„ç†
            "region_consolidation": True,       # åŒºåŸŸåˆå¹¶
            "small_region_threshold": 100,      # å°åŒºåŸŸé˜ˆå€¼
            "region_filling": True,            # åŒºåŸŸå¡«å……
            
            # è‰ºæœ¯åŒ–å¤„ç†
            "decorative_border": True,         # è£…é¥°æ€§è¾¹æ¡†
            "background_enhancement": True,     # èƒŒæ™¯å¢å¼º
            "artistic_pattern": True,          # è‰ºæœ¯å›¾æ¡ˆ
            
            # è´¨é‡ä¼˜åŒ–
            "anti_aliasing": True,            # æŠ—é”¯é½¿
            "texture_preservation": True,      # çº¹ç†ä¿æŒ
            "color_saturation_boost": 1.3,    # è‰²å½©é¥±å’Œåº¦æå‡
        }
        
        logger.info("ä¸“ä¸šç»‡æœºè¯†åˆ«å›¾åƒç”Ÿæˆå™¨å·²åˆå§‹åŒ–")
    
    def generate_professional_weaving_image(self, 
                                          input_path: str, 
                                          job_id: str,
                                          color_count: int = 16,
                                          style: str = "professional") -> Tuple[str, str, float]:
        """
        ç”Ÿæˆä¸“ä¸šç»‡æœºè¯†åˆ«å›¾åƒ
        
        Args:
            input_path: è¾“å…¥å›¾åƒè·¯å¾„
            job_id: ä»»åŠ¡ID
            color_count: é¢œè‰²æ•°é‡
            style: å¤„ç†é£æ ¼ ("professional", "artistic", "technical")
            
        Returns:
            Tuple[professional_png_path, comparison_png_path, processing_time]
        """
        start_time = time.time()
        
        try:
            logger.info(f"ğŸ¨ å¼€å§‹ç”Ÿæˆä¸“ä¸šç»‡æœºè¯†åˆ«å›¾åƒ: {job_id}")
            
            # åˆ›å»ºè¾“å‡ºç›®å½•
            job_dir = self.outputs_dir / job_id
            job_dir.mkdir(exist_ok=True, parents=True)
            
            # åŠ è½½å’Œé¢„å¤„ç†åŸå§‹å›¾åƒ
            original_image = self._load_image_professionally(input_path)
            logger.info("âœ“ åŸå§‹å›¾åƒåŠ è½½å®Œæˆ")
            
            # ä¸“ä¸šç»‡æœºå¤„ç†æµæ°´çº¿
            processed_image = self._professional_weaving_pipeline(
                original_image, color_count, style
            )
            logger.info("âœ“ ä¸“ä¸šç»‡æœºå¤„ç†å®Œæˆ")
            
            # åˆ›å»ºå¯¹æ¯”å›¾åƒ
            comparison_image = self._create_comparison_visualization(
                original_image, processed_image
            )
            logger.info("âœ“ å¯¹æ¯”å¯è§†åŒ–åˆ›å»ºå®Œæˆ")
            
            # æ·»åŠ ä¸“ä¸šè£…é¥°å’Œè¾¹æ¡†
            final_professional_image = self._add_professional_decorations(
                processed_image, style
            )
            logger.info("âœ“ ä¸“ä¸šè£…é¥°æ·»åŠ å®Œæˆ")
            
            # ä¿å­˜ç»“æœ
            professional_path = job_dir / f"{job_id}_professional_weaving.png"
            comparison_path = job_dir / f"{job_id}_comparison.png"
            
            self._save_professional_image(final_professional_image, str(professional_path))
            self._save_professional_image(comparison_image, str(comparison_path))
            
            processing_time = time.time() - start_time
            logger.info(f"ğŸ¯ ä¸“ä¸šç»‡æœºå›¾åƒç”Ÿæˆå®Œæˆï¼Œè€—æ—¶: {processing_time:.2f}ç§’")
            
            return str(professional_path), str(comparison_path), processing_time
            
        except Exception as e:
            error_msg = f"ä¸“ä¸šç»‡æœºå›¾åƒç”Ÿæˆå¤±è´¥: {str(e)}"
            logger.error(error_msg, exc_info=True)
            raise Exception(error_msg)
    
    def _load_image_professionally(self, input_path: str) -> np.ndarray:
        """ä¸“ä¸šçº§å›¾åƒåŠ è½½"""
        try:
            with Image.open(input_path) as pil_image:
                if pil_image.mode != 'RGB':
                    pil_image = pil_image.convert('RGB')
                
                # é«˜è´¨é‡é‡é‡‡æ ·
                image = np.array(pil_image.resize(
                    pil_image.size, Image.Resampling.LANCZOS
                ))
                
                return image
                
        except Exception as e:
            raise Exception(f"å›¾åƒåŠ è½½å¤±è´¥: {str(e)}")
    
    def _professional_weaving_pipeline(self, 
                                     image: np.ndarray, 
                                     color_count: int, 
                                     style: str) -> np.ndarray:
        """ä¸“ä¸šç»‡æœºå¤„ç†æµæ°´çº¿"""
        try:
            # 1. æ™ºèƒ½é¢œè‰²é™è‰²ï¼ˆåŸºäºç»‡æœºéœ€æ±‚ï¼‰
            color_reduced = self._intelligent_color_reduction(image, color_count)
            logger.info("  âœ“ æ™ºèƒ½é¢œè‰²é™è‰²å®Œæˆ")
            
            # 2. é¢œè‰²åŒºåŸŸè¿è´¯æ€§å¢å¼º
            coherent_regions = self._enhance_color_coherence(color_reduced)
            logger.info("  âœ“ é¢œè‰²åŒºåŸŸè¿è´¯æ€§å¢å¼ºå®Œæˆ")
            
            # 3. ä¸“ä¸šçº§è¾¹ç¼˜å¤„ç†
            sharp_edges = self._professional_edge_enhancement(coherent_regions)
            logger.info("  âœ“ ä¸“ä¸šçº§è¾¹ç¼˜å¤„ç†å®Œæˆ")
            
            # 4. ç»‡æœºè¯†åˆ«ä¼˜åŒ–
            weaving_optimized = self._weaving_machine_optimization(sharp_edges)
            logger.info("  âœ“ ç»‡æœºè¯†åˆ«ä¼˜åŒ–å®Œæˆ")
            
            # 5. åŒºåŸŸåˆå¹¶å’Œæ¸…ç†
            clean_regions = self._region_consolidation(weaving_optimized)
            logger.info("  âœ“ åŒºåŸŸåˆå¹¶å’Œæ¸…ç†å®Œæˆ")
            
            # 6. è´¨é‡å¢å¼º
            enhanced_quality = self._quality_enhancement(clean_regions, style)
            logger.info("  âœ“ è´¨é‡å¢å¼ºå®Œæˆ")
            
            return enhanced_quality
            
        except Exception as e:
            raise Exception(f"ä¸“ä¸šç»‡æœºå¤„ç†æµæ°´çº¿å¤±è´¥: {str(e)}")
    
    def _intelligent_color_reduction(self, image: np.ndarray, n_colors: int) -> np.ndarray:
        """æ™ºèƒ½é¢œè‰²é™è‰² - åŸºäºç»‡æœºéœ€æ±‚ä¼˜åŒ–"""
        try:
            # é¢„å¤„ç†ï¼šè½»å¾®é«˜æ–¯æ¨¡ç³Šä»¥å‡å°‘å™ªå£°
            blurred = cv2.GaussianBlur(image, (3, 3), 0.8)
            
            # é‡å¡‘ä¸ºåƒç´ å‘é‡
            pixels = blurred.reshape(-1, 3)
            
            # ä½¿ç”¨æ”¹è¿›çš„K-meansèšç±»
            kmeans = KMeans(
                n_clusters=n_colors,
                init='k-means++',
                n_init=30,  # å¢åŠ åˆå§‹åŒ–æ¬¡æ•°
                max_iter=500,  # å¢åŠ è¿­ä»£æ¬¡æ•°
                random_state=42,
                algorithm='lloyd'
            )
            
            # æ‰§è¡Œèšç±»
            kmeans.fit(pixels)
            
            # è·å–èšç±»ä¸­å¿ƒå¹¶ä¼˜åŒ–é¢œè‰²
            colors = kmeans.cluster_centers_.astype(np.uint8)
            
            # é¢œè‰²ä¼˜åŒ–ï¼šå¢å¼ºå¯¹æ¯”åº¦å’Œé¥±å’Œåº¦
            colors = self._optimize_weaving_colors(colors)
            
            # æ›¿æ¢åƒç´ é¢œè‰²
            labels = kmeans.labels_
            reduced_pixels = colors[labels]
            
            # é‡å¡‘å›åŸå§‹å›¾åƒå½¢çŠ¶
            reduced_image = reduced_pixels.reshape(image.shape)
            
            return reduced_image
            
        except Exception as e:
            raise Exception(f"æ™ºèƒ½é¢œè‰²é™è‰²å¤±è´¥: {str(e)}")
    
    def _optimize_weaving_colors(self, colors: np.ndarray) -> np.ndarray:
        """ä¼˜åŒ–ç»‡æœºé¢œè‰² - å¢å¼ºå¯¹æ¯”åº¦å’Œé¥±å’Œåº¦"""
        try:
            optimized_colors = []
            
            for color in colors:
                # è½¬æ¢ä¸ºHSVä»¥ä¾¿äºè°ƒæ•´é¥±å’Œåº¦
                hsv = cv2.cvtColor(color.reshape(1, 1, 3), cv2.COLOR_RGB2HSV)[0, 0]
                
                # å¢å¼ºé¥±å’Œåº¦ï¼ˆç»‡æœºéœ€è¦é«˜é¥±å’Œåº¦ï¼‰
                hsv[1] = min(255, int(hsv[1] * self.weaving_config["color_saturation_boost"]))
                
                # è½»å¾®è°ƒæ•´äº®åº¦ä»¥å¢å¼ºå¯¹æ¯”åº¦
                if hsv[2] > 128:
                    hsv[2] = min(255, int(hsv[2] * 1.1))
                else:
                    hsv[2] = max(0, int(hsv[2] * 0.9))
                
                # è½¬æ¢å›RGB
                rgb = cv2.cvtColor(hsv.reshape(1, 1, 3), cv2.COLOR_HSV2RGB)[0, 0]
                optimized_colors.append(rgb)
            
            return np.array(optimized_colors, dtype=np.uint8)
            
        except Exception as e:
            logger.warning(f"é¢œè‰²ä¼˜åŒ–å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹é¢œè‰²: {str(e)}")
            return colors
    
    def _enhance_color_coherence(self, image: np.ndarray) -> np.ndarray:
        """å¢å¼ºé¢œè‰²åŒºåŸŸè¿è´¯æ€§ - å…³é”®æ”¹è¿›"""
        try:
            # 1. è·å–æ‰€æœ‰å”¯ä¸€é¢œè‰²
            unique_colors = self._get_unique_colors(image)
            
            # 2. ä¸ºæ¯ä¸ªé¢œè‰²åˆ›å»ºæ©ç å¹¶å¢å¼ºè¿è´¯æ€§
            result = image.copy()
            
            for color in unique_colors:
                # åˆ›å»ºå½“å‰é¢œè‰²çš„æ©ç 
                mask = np.all(image == color, axis=2)
                
                if np.sum(mask) == 0:
                    continue
                
                # å½¢æ€å­¦æ“ä½œå¢å¼ºè¿è´¯æ€§
                kernel_size = self.weaving_config["color_connectivity_strength"]
                kernel = np.ones((kernel_size, kernel_size), np.uint8)
                
                # é—­è¿ç®—ï¼šè¿æ¥ç›¸è¿‘åŒºåŸŸ
                mask_closed = cv2.morphologyEx(mask.astype(np.uint8), cv2.MORPH_CLOSE, kernel)
                
                # å¼€è¿ç®—ï¼šå»é™¤å°å™ªç‚¹
                mask_cleaned = cv2.morphologyEx(mask_closed, cv2.MORPH_OPEN, kernel//2)
                
                # åº”ç”¨æ¸…ç†åçš„æ©ç 
                result[mask_cleaned > 0] = color
            
            # 3. æ•´ä½“å¹³æ»‘å¤„ç†
            smoothed = cv2.bilateralFilter(
                result, 
                self.weaving_config["color_smoothing_radius"], 
                80, 80
            )
            
            return smoothed
            
        except Exception as e:
            raise Exception(f"é¢œè‰²è¿è´¯æ€§å¢å¼ºå¤±è´¥: {str(e)}")
    
    def _professional_edge_enhancement(self, image: np.ndarray) -> np.ndarray:
        """ä¸“ä¸šçº§è¾¹ç¼˜å¢å¼º - å¯¹æ ‡ä¸“ä¸šè½¯ä»¶"""
        try:
            # 1. å¤šå°ºåº¦è¾¹ç¼˜æ£€æµ‹
            edges = self._multi_scale_edge_detection(image)
            
            # 2. è¾¹ç¼˜é”åŒ–
            sharpened = self._selective_sharpening(image, edges)
            
            # 3. è½®å»“å¢å¼º
            if self.weaving_config["contour_enhancement"]:
                contour_enhanced = self._enhance_contours(sharpened)
            else:
                contour_enhanced = sharpened
            
            # 4. è¾¹ç¼˜å¹³æ»‘
            if self.weaving_config["edge_smoothing"]:
                final_edges = self._smooth_edges(contour_enhanced)
            else:
                final_edges = contour_enhanced
            
            return final_edges
            
        except Exception as e:
            raise Exception(f"ä¸“ä¸šçº§è¾¹ç¼˜å¢å¼ºå¤±è´¥: {str(e)}")
    
    def _multi_scale_edge_detection(self, image: np.ndarray) -> np.ndarray:
        """å¤šå°ºåº¦è¾¹ç¼˜æ£€æµ‹"""
        try:
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
            
            # å¤šä¸ªå°ºåº¦çš„è¾¹ç¼˜æ£€æµ‹
            edges_combined = np.zeros_like(gray)
            
            scales = [1, 2, 3]
            for scale in scales:
                # é«˜æ–¯æ¨¡ç³Š
                blurred = cv2.GaussianBlur(gray, (scale*2+1, scale*2+1), scale)
                
                # Cannyè¾¹ç¼˜æ£€æµ‹
                edges = cv2.Canny(blurred, 50, 150)
                
                # åˆå¹¶è¾¹ç¼˜
                edges_combined = cv2.bitwise_or(edges_combined, edges)
            
            return edges_combined
            
        except Exception as e:
            logger.warning(f"å¤šå°ºåº¦è¾¹ç¼˜æ£€æµ‹å¤±è´¥: {str(e)}")
            return cv2.Canny(cv2.cvtColor(image, cv2.COLOR_RGB2GRAY), 50, 150)
    
    def _selective_sharpening(self, image: np.ndarray, edges: np.ndarray) -> np.ndarray:
        """é€‰æ‹©æ€§é”åŒ– - åªåœ¨è¾¹ç¼˜åŒºåŸŸé”åŒ–"""
        try:
            # åˆ›å»ºé”åŒ–æ ¸
            intensity = self.weaving_config["edge_sharpening_intensity"]
            kernel = np.array([
                [-1, -1, -1],
                [-1, 8+intensity, -1],
                [-1, -1, -1]
            ])
            
            # åº”ç”¨é”åŒ–
            sharpened = cv2.filter2D(image, -1, kernel)
            
            # åªåœ¨è¾¹ç¼˜åŒºåŸŸåº”ç”¨é”åŒ–
            edges_3d = cv2.cvtColor(edges, cv2.COLOR_GRAY2RGB) / 255.0
            
            # è¾¹ç¼˜åŒºåŸŸä½¿ç”¨é”åŒ–ç‰ˆæœ¬ï¼Œå…¶ä»–åŒºåŸŸä¿æŒåŸæ ·
            result = (image * (1 - edges_3d) + sharpened * edges_3d).astype(np.uint8)
            
            return result
            
        except Exception as e:
            logger.warning(f"é€‰æ‹©æ€§é”åŒ–å¤±è´¥: {str(e)}")
            return image
    
    def _enhance_contours(self, image: np.ndarray) -> np.ndarray:
        """å¢å¼ºè½®å»“æ¸…æ™°åº¦"""
        try:
            # æ‰¾åˆ°è½®å»“
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
            contours, _ = cv2.findContours(gray, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            # åœ¨åŸå›¾ä¸Šç»˜åˆ¶å¢å¼ºçš„è½®å»“
            result = image.copy()
            
            # ç»˜åˆ¶è½®å»“ï¼ˆç¨å¾®åŠ ç²—ï¼‰
            cv2.drawContours(result, contours, -1, (0, 0, 0), 1)
            
            return result
            
        except Exception as e:
            logger.warning(f"è½®å»“å¢å¼ºå¤±è´¥: {str(e)}")
            return image
    
    def _smooth_edges(self, image: np.ndarray) -> np.ndarray:
        """è¾¹ç¼˜å¹³æ»‘å¤„ç†"""
        try:
            # ä½¿ç”¨åŒè¾¹æ»¤æ³¢ä¿æŒè¾¹ç¼˜çš„åŒæ—¶å¹³æ»‘
            smoothed = cv2.bilateralFilter(image, 5, 50, 50)
            return smoothed
            
        except Exception as e:
            logger.warning(f"è¾¹ç¼˜å¹³æ»‘å¤±è´¥: {str(e)}")
            return image
    
    def _weaving_machine_optimization(self, image: np.ndarray) -> np.ndarray:
        """ç»‡æœºè¯†åˆ«ä¸“é¡¹ä¼˜åŒ–"""
        try:
            # 1. é¢œè‰²åŒºåŸŸåˆå¹¶
            merged_regions = self._merge_similar_regions(image)
            
            # 2. å°åŒºåŸŸæ¸…ç†
            cleaned = self._clean_small_regions(merged_regions)
            
            # 3. è¾¹ç•Œæ¸…ç†
            boundary_cleaned = self._clean_boundaries(cleaned)
            
            return boundary_cleaned
            
        except Exception as e:
            raise Exception(f"ç»‡æœºè¯†åˆ«ä¼˜åŒ–å¤±è´¥: {str(e)}")
    
    def _merge_similar_regions(self, image: np.ndarray) -> np.ndarray:
        """åˆå¹¶ç›¸ä¼¼é¢œè‰²åŒºåŸŸ"""
        try:
            # ä½¿ç”¨å½¢æ€å­¦æ“ä½œåˆå¹¶ç›¸ä¼¼åŒºåŸŸ
            kernel = np.ones((5, 5), np.uint8)
            
            # é—­è¿ç®—
            closed = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)
            
            # å¼€è¿ç®—
            opened = cv2.morphologyEx(closed, cv2.MORPH_OPEN, kernel)
            
            return opened
            
        except Exception as e:
            logger.warning(f"åŒºåŸŸåˆå¹¶å¤±è´¥: {str(e)}")
            return image
    
    def _clean_small_regions(self, image: np.ndarray) -> np.ndarray:
        """æ¸…ç†å°åŒºåŸŸ"""
        try:
            # è·å–æ‰€æœ‰å”¯ä¸€é¢œè‰²
            unique_colors = self._get_unique_colors(image)
            result = image.copy()
            
            for color in unique_colors:
                # ä¸ºæ¯ä¸ªé¢œè‰²åˆ›å»ºæ©ç 
                mask = np.all(image == color, axis=2).astype(np.uint8)
                
                # æ‰¾åˆ°è¿é€šç»„ä»¶
                num_labels, labels = cv2.connectedComponents(mask)
                
                # è®¡ç®—æ¯ä¸ªç»„ä»¶çš„å¤§å°
                for label in range(1, num_labels):
                    component_mask = (labels == label)
                    component_size = np.sum(component_mask)
                    
                    # å¦‚æœç»„ä»¶å¤ªå°ï¼Œç”¨å‘¨å›´çš„ä¸»è¦é¢œè‰²æ›¿æ¢
                    if component_size < self.weaving_config["small_region_threshold"]:
                        # ç®€å•å¤„ç†ï¼šç”¨æœ€è¿‘é‚»é¢œè‰²æ›¿æ¢
                        result[component_mask] = self._get_dominant_neighbor_color(
                            image, component_mask
                        )
            
            return result
            
        except Exception as e:
            logger.warning(f"å°åŒºåŸŸæ¸…ç†å¤±è´¥: {str(e)}")
            return image
    
    def _clean_boundaries(self, image: np.ndarray) -> np.ndarray:
        """æ¸…ç†è¾¹ç•Œ"""
        try:
            # ä½¿ç”¨ä¸­å€¼æ»¤æ³¢æ¸…ç†è¾¹ç•Œå™ªå£°
            cleaned = cv2.medianBlur(image, 3)
            
            return cleaned
            
        except Exception as e:
            logger.warning(f"è¾¹ç•Œæ¸…ç†å¤±è´¥: {str(e)}")
            return image
    
    def _region_consolidation(self, image: np.ndarray) -> np.ndarray:
        """åŒºåŸŸåˆå¹¶"""
        try:
            if not self.weaving_config["region_consolidation"]:
                return image
            
            # 1. å½¢æ€å­¦æ“ä½œ
            kernel = np.ones((7, 7), np.uint8)
            
            # é—­è¿ç®— - è¿æ¥ç›¸è¿‘åŒºåŸŸ
            closed = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)
            
            # 2. åŒºåŸŸå¡«å……
            if self.weaving_config["region_filling"]:
                filled = self._fill_regions(closed)
            else:
                filled = closed
            
            return filled
            
        except Exception as e:
            raise Exception(f"åŒºåŸŸåˆå¹¶å¤±è´¥: {str(e)}")
    
    def _fill_regions(self, image: np.ndarray) -> np.ndarray:
        """å¡«å……åŒºåŸŸå†…çš„ç©ºæ´"""
        try:
            # å¯¹æ¯ä¸ªé¢œè‰²é€šé“åˆ†åˆ«å¤„ç†
            result = image.copy()
            
            for channel in range(3):
                # ä½¿ç”¨å½¢æ€å­¦é—­è¿ç®—å¡«å……ç©ºæ´
                kernel = np.ones((5, 5), np.uint8)
                filled = cv2.morphologyEx(result[:, :, channel], cv2.MORPH_CLOSE, kernel)
                result[:, :, channel] = filled
            
            return result
            
        except Exception as e:
            logger.warning(f"åŒºåŸŸå¡«å……å¤±è´¥: {str(e)}")
            return image
    
    def _quality_enhancement(self, image: np.ndarray, style: str) -> np.ndarray:
        """è´¨é‡å¢å¼º"""
        try:
            # 1. æŠ—é”¯é½¿å¤„ç†
            if self.weaving_config["anti_aliasing"]:
                anti_aliased = self._apply_anti_aliasing(image)
            else:
                anti_aliased = image
            
            # 2. çº¹ç†ä¿æŒ
            if self.weaving_config["texture_preservation"]:
                texture_preserved = self._preserve_texture(anti_aliased)
            else:
                texture_preserved = anti_aliased
            
            # 3. æœ€ç»ˆè‰²å½©è°ƒæ•´
            final_enhanced = self._final_color_adjustment(texture_preserved, style)
            
            return final_enhanced
            
        except Exception as e:
            raise Exception(f"è´¨é‡å¢å¼ºå¤±è´¥: {str(e)}")
    
    def _apply_anti_aliasing(self, image: np.ndarray) -> np.ndarray:
        """åº”ç”¨æŠ—é”¯é½¿"""
        try:
            # ä½¿ç”¨é«˜è´¨é‡é‡é‡‡æ ·å®ç°æŠ—é”¯é½¿
            pil_image = Image.fromarray(image)
            
            # å…ˆæ”¾å¤§å†ç¼©å°ï¼Œå®ç°æŠ—é”¯é½¿æ•ˆæœ
            width, height = pil_image.size
            enlarged = pil_image.resize((width*2, height*2), Image.Resampling.LANCZOS)
            anti_aliased = enlarged.resize((width, height), Image.Resampling.LANCZOS)
            
            return np.array(anti_aliased)
            
        except Exception as e:
            logger.warning(f"æŠ—é”¯é½¿å¤„ç†å¤±è´¥: {str(e)}")
            return image
    
    def _preserve_texture(self, image: np.ndarray) -> np.ndarray:
        """ä¿æŒçº¹ç†"""
        try:
            # ä½¿ç”¨ä¿è¾¹æ»¤æ³¢å™¨ä¿æŒçº¹ç†
            preserved = cv2.edgePreservingFilter(image, flags=1, sigma_s=50, sigma_r=0.4)
            
            return preserved
            
        except Exception as e:
            logger.warning(f"çº¹ç†ä¿æŒå¤±è´¥: {str(e)}")
            return image
    
    def _final_color_adjustment(self, image: np.ndarray, style: str) -> np.ndarray:
        """æœ€ç»ˆè‰²å½©è°ƒæ•´"""
        try:
            pil_image = Image.fromarray(image)
            
            # æ ¹æ®é£æ ¼è°ƒæ•´
            if style == "professional":
                # ä¸“ä¸šé£æ ¼ï¼šå¢å¼ºå¯¹æ¯”åº¦å’Œé¥±å’Œåº¦
                enhancer = ImageEnhance.Contrast(pil_image)
                enhanced = enhancer.enhance(1.2)
                
                enhancer = ImageEnhance.Color(enhanced)
                enhanced = enhancer.enhance(1.3)
                
            elif style == "artistic":
                # è‰ºæœ¯é£æ ¼ï¼šå¢å¼ºè‰²å½©é²œè‰³åº¦
                enhancer = ImageEnhance.Color(pil_image)
                enhanced = enhancer.enhance(1.4)
                
                enhancer = ImageEnhance.Brightness(enhanced)
                enhanced = enhancer.enhance(1.1)
                
            else:  # technical
                # æŠ€æœ¯é£æ ¼ï¼šä¿æŒå‡†ç¡®æ€§
                enhancer = ImageEnhance.Sharpness(pil_image)
                enhanced = enhancer.enhance(1.1)
            
            return np.array(enhanced)
            
        except Exception as e:
            logger.warning(f"æœ€ç»ˆè‰²å½©è°ƒæ•´å¤±è´¥: {str(e)}")
            return image
    
    def _add_professional_decorations(self, image: np.ndarray, style: str) -> np.ndarray:
        """æ·»åŠ ä¸“ä¸šè£…é¥°ï¼ˆæ¨¡ä»¿ä¸“ä¸šç»‡æœºè½¯ä»¶ï¼‰"""
        try:
            if not self.weaving_config["decorative_border"]:
                return image
            
            # è½¬æ¢ä¸ºPILå›¾åƒä»¥ä¾¿äºç»˜åˆ¶
            pil_image = Image.fromarray(image)
            width, height = pil_image.size
            
            # åˆ›å»ºå¸¦è¾¹æ¡†çš„æ–°å›¾åƒ
            border_width = 20
            new_width = width + 2 * border_width
            new_height = height + 2 * border_width
            
            # åˆ›å»ºèƒŒæ™¯
            if style == "professional":
                border_color = (255, 192, 203)  # ç²‰è‰²è¾¹æ¡†ï¼ˆæ¨¡ä»¿ä¸“ä¸šè½¯ä»¶ï¼‰
            elif style == "artistic":
                border_color = (255, 215, 0)    # é‡‘è‰²è¾¹æ¡†
            else:
                border_color = (128, 128, 128)  # ç°è‰²è¾¹æ¡†
            
            bordered_image = Image.new('RGB', (new_width, new_height), border_color)
            
            # ç²˜è´´åŸå›¾åƒåˆ°ä¸­å¿ƒ
            bordered_image.paste(pil_image, (border_width, border_width))
            
            # æ·»åŠ è£…é¥°å›¾æ¡ˆï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if self.weaving_config["artistic_pattern"]:
                bordered_image = self._add_decorative_pattern(bordered_image, style)
            
            return np.array(bordered_image)
            
        except Exception as e:
            logger.warning(f"ä¸“ä¸šè£…é¥°æ·»åŠ å¤±è´¥: {str(e)}")
            return image
    
    def _add_decorative_pattern(self, pil_image: Image.Image, style: str) -> Image.Image:
        """æ·»åŠ è£…é¥°å›¾æ¡ˆ"""
        try:
            draw = ImageDraw.Draw(pil_image)
            width, height = pil_image.size
            
            if style == "professional":
                # ä¸“ä¸šé£æ ¼ï¼šç®€å•å‡ ä½•å›¾æ¡ˆ
                pattern_color = (255, 255, 255)  # ç™½è‰²å›¾æ¡ˆ
                
                # åœ¨è¾¹æ¡†ä¸Šç»˜åˆ¶å°åœ†ç‚¹
                for i in range(10, width-10, 30):
                    draw.ellipse([i-3, 7, i+3, 13], fill=pattern_color)
                    draw.ellipse([i-3, height-13, i+3, height-7], fill=pattern_color)
                
                for i in range(10, height-10, 30):
                    draw.ellipse([7, i-3, 13, i+3], fill=pattern_color)
                    draw.ellipse([width-13, i-3, width-7, i+3], fill=pattern_color)
            
            elif style == "artistic":
                # è‰ºæœ¯é£æ ¼ï¼šæ›´å¤æ‚çš„å›¾æ¡ˆ
                pattern_color = (255, 255, 255)
                
                # ç»˜åˆ¶è§’è½è£…é¥°
                for corner in [(10, 10), (width-30, 10), (10, height-30), (width-30, height-30)]:
                    x, y = corner
                    draw.rectangle([x, y, x+20, y+20], outline=pattern_color, width=2)
                    draw.line([x, y, x+20, y+20], fill=pattern_color, width=1)
                    draw.line([x+20, y, x, y+20], fill=pattern_color, width=1)
            
            return pil_image
            
        except Exception as e:
            logger.warning(f"è£…é¥°å›¾æ¡ˆæ·»åŠ å¤±è´¥: {str(e)}")
            return pil_image
    
    def _create_comparison_visualization(self, 
                                       original: np.ndarray, 
                                       processed: np.ndarray) -> np.ndarray:
        """åˆ›å»ºå¯¹æ¯”å¯è§†åŒ–"""
        try:
            # ç¡®ä¿ä¸¤ä¸ªå›¾åƒå°ºå¯¸ä¸€è‡´
            if original.shape != processed.shape:
                original = cv2.resize(original, (processed.shape[1], processed.shape[0]))
            
            # åˆ›å»ºå¹¶æ’å¯¹æ¯”
            comparison = np.hstack([original, processed])
            
            # è½¬æ¢ä¸ºPILè¿›è¡Œæ–‡å­—æ ‡æ³¨
            pil_comparison = Image.fromarray(comparison)
            draw = ImageDraw.Draw(pil_comparison)
            
            # æ·»åŠ æ ‡é¢˜
            width, height = pil_comparison.size
            
            # æ ‡æ³¨åŸå›¾
            draw.text((width//4, 10), "åŸå§‹å›¾åƒ", fill=(255, 255, 255), anchor="mm")
            
            # æ ‡æ³¨å¤„ç†åå›¾åƒ
            draw.text((3*width//4, 10), "ä¸“ä¸šç»‡æœºå¤„ç†", fill=(255, 255, 255), anchor="mm")
            
            # æ·»åŠ åˆ†éš”çº¿
            draw.line([(width//2, 0), (width//2, height)], fill=(255, 255, 255), width=2)
            
            return np.array(pil_comparison)
            
        except Exception as e:
            logger.warning(f"å¯¹æ¯”å¯è§†åŒ–åˆ›å»ºå¤±è´¥: {str(e)}")
            # è¿”å›å¤„ç†åçš„å›¾åƒ
            return processed
    
    def _save_professional_image(self, image: np.ndarray, output_path: str):
        """ä¿å­˜ä¸“ä¸šçº§å›¾åƒ"""
        try:
            pil_image = Image.fromarray(image)
            
            # è¶…é«˜è´¨é‡ä¿å­˜è®¾ç½®
            save_kwargs = {
                'format': 'PNG',
                'optimize': False,
                'compress_level': 0,
                'pnginfo': self._create_professional_metadata()
            }
            
            pil_image.save(output_path, **save_kwargs)
            
            file_size = Path(output_path).stat().st_size
            logger.info(f"ä¸“ä¸šå›¾åƒå·²ä¿å­˜: {Path(output_path).name} ({file_size/1024/1024:.2f} MB)")
            
        except Exception as e:
            raise Exception(f"ä¸“ä¸šå›¾åƒä¿å­˜å¤±è´¥: {str(e)}")
    
    def _create_professional_metadata(self) -> Optional[object]:
        """åˆ›å»ºä¸“ä¸šå…ƒæ•°æ®"""
        try:
            from PIL.PngImagePlugin import PngInfo
            metadata = PngInfo()
            metadata.add_text("Software", "ä¸“ä¸šç»‡æœºè¯†åˆ«å›¾åƒç”Ÿæˆå™¨")
            metadata.add_text("Description", "Professional Weaving Machine Recognition Image")
            metadata.add_text("Generator", "ProfessionalWeavingImageGenerator v1.0")
            metadata.add_text("Creation Time", time.strftime("%Y-%m-%d %H:%M:%S"))
            return metadata
        except ImportError:
            return None
    
    def _get_unique_colors(self, image: np.ndarray) -> List[Tuple[int, int, int]]:
        """è·å–å›¾åƒä¸­çš„å”¯ä¸€é¢œè‰²"""
        try:
            pixels = image.reshape(-1, 3)
            unique_colors = np.unique(pixels, axis=0)
            return [tuple(color) for color in unique_colors]
        except Exception as e:
            logger.warning(f"è·å–å”¯ä¸€é¢œè‰²å¤±è´¥: {str(e)}")
            return []
    
    def _get_dominant_neighbor_color(self, 
                                   image: np.ndarray, 
                                   mask: np.ndarray) -> Tuple[int, int, int]:
        """è·å–å‘¨å›´åŒºåŸŸçš„ä¸»å¯¼é¢œè‰²"""
        try:
            # è†¨èƒ€æ©ç ä»¥è·å–å‘¨å›´åŒºåŸŸ
            kernel = np.ones((5, 5), np.uint8)
            dilated_mask = cv2.dilate(mask.astype(np.uint8), kernel, iterations=1)
            
            # è·å–è¾¹ç•ŒåŒºåŸŸ
            boundary = dilated_mask - mask.astype(np.uint8)
            
            if np.sum(boundary) == 0:
                return (128, 128, 128)  # é»˜è®¤ç°è‰²
            
            # è·å–è¾¹ç•ŒåŒºåŸŸçš„é¢œè‰²
            boundary_colors = image[boundary > 0]
            
            if len(boundary_colors) == 0:
                return (128, 128, 128)
            
            # è¿”å›æœ€å¸¸è§çš„é¢œè‰²
            unique_colors, counts = np.unique(boundary_colors, axis=0, return_counts=True)
            dominant_color = unique_colors[np.argmax(counts)]
            
            return tuple(dominant_color)
            
        except Exception as e:
            logger.warning(f"è·å–ä¸»å¯¼é‚»å±…é¢œè‰²å¤±è´¥: {str(e)}")
            return (128, 128, 128)
    
    def get_generator_info(self) -> Dict[str, Any]:
        """è·å–ç”Ÿæˆå™¨ä¿¡æ¯"""
        return {
            "generator_version": "1.0.0",
            "output_directory": str(self.outputs_dir),
            "weaving_config": self.weaving_config.copy(),
            "supported_styles": ["professional", "artistic", "technical"],
            "features": [
                "ä¸“ä¸šç»‡æœºè¯†åˆ«ä¼˜åŒ–",
                "æ™ºèƒ½é¢œè‰²é™è‰²",
                "é¢œè‰²åŒºåŸŸè¿è´¯æ€§å¢å¼º",
                "ä¸“ä¸šçº§è¾¹ç¼˜å¤„ç†",
                "å¤šå°ºåº¦è¾¹ç¼˜æ£€æµ‹",
                "é€‰æ‹©æ€§é”åŒ–",
                "è½®å»“å¢å¼º",
                "åŒºåŸŸåˆå¹¶æ¸…ç†",
                "è£…é¥°æ€§è¾¹æ¡†",
                "å¯¹æ¯”å¯è§†åŒ–",
                "è¶…é«˜è´¨é‡è¾“å‡º"
            ]
        } 