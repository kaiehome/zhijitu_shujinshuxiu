"""
å¢å¼ºç‰ˆå›¾åƒå¤„ç†å™¨
é›†æˆå¹¶è¡Œå¤„ç†ã€GPUåŠ é€Ÿå’Œæ™ºèƒ½å†…å­˜ç®¡ç†
"""

import cv2
import numpy as np
import logging
import time
from typing import Dict, Any, Optional, Tuple, List
from pathlib import Path
import os

# å¯¼å…¥æ–°å¼€å‘çš„ç»„ä»¶
from parallel_processor import ParallelProcessor, ProcessingTask, ImageProcessingPipeline
from gpu_accelerator import GPUAccelerator, GPUProcessingPipeline
from memory_manager import MemoryManager

logger = logging.getLogger(__name__)


class EnhancedImageProcessor:
    """
    å¢å¼ºç‰ˆå›¾åƒå¤„ç†å™¨
    
    é›†æˆå¹¶è¡Œå¤„ç†ã€GPUåŠ é€Ÿå’Œæ™ºèƒ½å†…å­˜ç®¡ç†ï¼Œæä¾›é«˜æ€§èƒ½å›¾åƒå¤„ç†
    """
    
    def __init__(self, 
                 outputs_dir: str = "outputs",
                 use_gpu: bool = True,
                 use_parallel: bool = True,
                 max_workers: int = None,
                 cache_size: int = 100):
        """
        åˆå§‹åŒ–å¢å¼ºç‰ˆå›¾åƒå¤„ç†å™¨
        
        Args:
            outputs_dir: è¾“å‡ºç›®å½•
            use_gpu: æ˜¯å¦ä½¿ç”¨GPUåŠ é€Ÿ
            use_parallel: æ˜¯å¦ä½¿ç”¨å¹¶è¡Œå¤„ç†
            max_workers: æœ€å¤§å·¥ä½œè¿›ç¨‹æ•°
            cache_size: ç¼“å­˜å¤§å°
        """
        self.outputs_dir = Path(outputs_dir)
        self.outputs_dir.mkdir(exist_ok=True, parents=True)
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.use_gpu = use_gpu
        self.use_parallel = use_parallel
        
        # GPUåŠ é€Ÿå™¨
        if use_gpu:
            self.gpu_accelerator = GPUAccelerator()
            self.gpu_pipeline = GPUProcessingPipeline()
            logger.info("GPUåŠ é€Ÿå™¨å·²å¯ç”¨")
        else:
            self.gpu_accelerator = None
            self.gpu_pipeline = None
        
        # å¹¶è¡Œå¤„ç†å™¨
        if use_parallel:
            self.parallel_processor = ParallelProcessor(max_workers=max_workers)
            self.parallel_pipeline = ImageProcessingPipeline(max_workers=max_workers)
            logger.info("å¹¶è¡Œå¤„ç†å™¨å·²å¯ç”¨")
        else:
            self.parallel_processor = None
            self.parallel_pipeline = None
        
        # å†…å­˜ç®¡ç†å™¨
        self.memory_manager = MemoryManager(cache_size=cache_size)
        
        # æ€§èƒ½ç»Ÿè®¡
        self.performance_stats = {
            "total_processed": 0,
            "gpu_processed": 0,
            "parallel_processed": 0,
            "total_time": 0,
            "average_time": 0
        }
        
        logger.info("å¢å¼ºç‰ˆå›¾åƒå¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def process_image_enhanced(self, 
                              input_path: str, 
                              job_id: str,
                              color_count: int = 16,
                              edge_enhancement: bool = True,
                              noise_reduction: bool = True,
                              use_ai_segmentation: bool = True) -> Tuple[str, str, float]:
        """
        å¢å¼ºç‰ˆå›¾åƒå¤„ç†
        
        Args:
            input_path: è¾“å…¥å›¾åƒè·¯å¾„
            job_id: ä»»åŠ¡ID
            color_count: é¢œè‰²æ•°é‡
            edge_enhancement: æ˜¯å¦å¯ç”¨è¾¹ç¼˜å¢å¼º
            noise_reduction: æ˜¯å¦å¯ç”¨å™ªå£°æ¸…ç†
            use_ai_segmentation: æ˜¯å¦ä½¿ç”¨AIåˆ†å‰²
            
        Returns:
            Tuple[str, str, float]: å¤„ç†ç»“æœè·¯å¾„å’Œè€—æ—¶
        """
        start_time = time.time()
        
        try:
            logger.info(f"ğŸš€ å¼€å§‹å¢å¼ºç‰ˆå›¾åƒå¤„ç†: {job_id}")
            
            # æ£€æŸ¥ç¼“å­˜
            cache_key = f"{job_id}_enhanced"
            cached_result = self.memory_manager.get_cached_image(cache_key)
            if cached_result is not None:
                logger.info(f"ä½¿ç”¨ç¼“å­˜ç»“æœ: {job_id}")
                return self._save_cached_result(cached_result, job_id, start_time)
            
            # åŠ è½½å›¾åƒ
            image = self._load_image(input_path)
            if image is None:
                raise ValueError(f"æ— æ³•åŠ è½½å›¾åƒ: {input_path}")
            
            # é€‰æ‹©å¤„ç†ç­–ç•¥
            if self.use_gpu and self.gpu_accelerator.is_available():
                processed_image = self._gpu_process(image, color_count, edge_enhancement, 
                                                  noise_reduction, use_ai_segmentation)
                self.performance_stats["gpu_processed"] += 1
            elif self.use_parallel:
                processed_image = self._parallel_process(image, color_count, edge_enhancement,
                                                       noise_reduction, use_ai_segmentation)
                self.performance_stats["parallel_processed"] += 1
            else:
                processed_image = self._cpu_process(image, color_count, edge_enhancement,
                                                  noise_reduction, use_ai_segmentation)
            
            # ä¿å­˜ç»“æœ
            output_path = self._save_result(processed_image, job_id)
            
            # ç¼“å­˜ç»“æœ
            self.memory_manager.cache_image(cache_key, processed_image)
            
            # æ›´æ–°ç»Ÿè®¡
            processing_time = time.time() - start_time
            self._update_stats(processing_time)
            
            logger.info(f"âœ… å¢å¼ºç‰ˆå›¾åƒå¤„ç†å®Œæˆ: {job_id}, è€—æ—¶: {processing_time:.2f}s")
            
            return output_path, "", processing_time
            
        except Exception as e:
            logger.error(f"å¢å¼ºç‰ˆå›¾åƒå¤„ç†å¤±è´¥: {job_id}, é”™è¯¯: {e}")
            raise
    
    def _gpu_process(self, image: np.ndarray, color_count: int, edge_enhancement: bool,
                    noise_reduction: bool, use_ai_segmentation: bool) -> np.ndarray:
        """GPUå¤„ç†"""
        # æ„å»ºGPUå¤„ç†æµæ°´çº¿
        self.gpu_pipeline.pipeline_steps.clear()
        
        if noise_reduction:
            self.gpu_pipeline.add_step("bilateral_filter", {
                "d": 9, "sigma_color": 75, "sigma_space": 75
            })
        
        if edge_enhancement:
            self.gpu_pipeline.add_step("laplacian", {
                "ddepth": cv2.CV_16S, "ksize": 3
            })
        
        # é¢œè‰²é™è‰²ï¼ˆä½¿ç”¨GPUåŠ é€Ÿçš„K-meansï¼‰
        processed_image = self.gpu_pipeline.process_image(image)
        
        # é¢œè‰²é™è‰²ï¼ˆCPUå¤„ç†ï¼Œå› ä¸ºGPU K-meanså®ç°å¤æ‚ï¼‰
        processed_image = self._color_reduction_gpu_fallback(processed_image, color_count)
        
        return processed_image
    
    def _parallel_process(self, image: np.ndarray, color_count: int, edge_enhancement: bool,
                         noise_reduction: bool, use_ai_segmentation: bool) -> np.ndarray:
        """å¹¶è¡Œå¤„ç†"""
        # æ„å»ºå¹¶è¡Œå¤„ç†æµæ°´çº¿
        self.parallel_pipeline.pipeline_steps.clear()
        
        if noise_reduction:
            self.parallel_pipeline.add_step("noise_reduction", {
                "kernel_size": 5
            })
        
        if edge_enhancement:
            self.parallel_pipeline.add_step("edge_enhancement", {
                "kernel_size": 3
            })
        
        if use_ai_segmentation:
            self.parallel_pipeline.add_step("segmentation", {
                "method": "grabcut"
            })
        
        # é¢œè‰²é™è‰²
        self.parallel_pipeline.add_step("color_reduction", {
            "n_colors": color_count
        })
        
        # æ‰§è¡Œå¹¶è¡Œå¤„ç†
        results = self.parallel_pipeline.process_image(image, f"parallel_{int(time.time())}")
        
        # è·å–æœ€ç»ˆç»“æœ
        if results:
            return list(results.values())[-1]  # è¿”å›æœ€åä¸€ä¸ªæ­¥éª¤çš„ç»“æœ
        else:
            return image
    
    def _cpu_process(self, image: np.ndarray, color_count: int, edge_enhancement: bool,
                    noise_reduction: bool, use_ai_segmentation: bool) -> np.ndarray:
        """CPUå¤„ç†ï¼ˆä¼ ç»Ÿæ–¹æ³•ï¼‰"""
        processed_image = image.copy()
        
        # å™ªå£°æ¸…ç†
        if noise_reduction:
            processed_image = cv2.bilateralFilter(processed_image, 9, 75, 75)
        
        # è¾¹ç¼˜å¢å¼º
        if edge_enhancement:
            gray = cv2.cvtColor(processed_image, cv2.COLOR_BGR2GRAY)
            edges = cv2.Laplacian(gray, cv2.CV_64F, ksize=3)
            edges = np.uint8(np.absolute(edges))
            enhanced = cv2.addWeighted(gray, 1.5, edges, 0.5, 0)
            processed_image = cv2.cvtColor(enhanced, cv2.COLOR_GRAY2BGR)
        
        # AIåˆ†å‰²
        if use_ai_segmentation:
            mask = self._ai_segmentation(processed_image)
            # åº”ç”¨åˆ†å‰²æ©ç 
            processed_image = cv2.bitwise_and(processed_image, processed_image, mask=mask)
        
        # é¢œè‰²é™è‰²
        processed_image = self._color_reduction(processed_image, color_count)
        
        return processed_image
    
    def _color_reduction_gpu_fallback(self, image: np.ndarray, n_colors: int) -> np.ndarray:
        """GPUå›é€€çš„é¢œè‰²é™è‰²"""
        return self._color_reduction(image, n_colors)
    
    def _color_reduction(self, image: np.ndarray, n_colors: int) -> np.ndarray:
        """é¢œè‰²é™è‰²"""
        # é‡å¡‘å›¾åƒä¸ºäºŒç»´æ•°ç»„
        pixels = image.reshape(-1, 3)
        
        # K-meansèšç±»
        from sklearn.cluster import KMeans
        kmeans = KMeans(n_clusters=n_colors, random_state=42, n_init=10)
        labels = kmeans.fit_predict(pixels)
        
        # é‡å»ºå›¾åƒ
        quantized = kmeans.cluster_centers_[labels]
        result = quantized.reshape(image.shape).astype(np.uint8)
        
        return result
    
    def _ai_segmentation(self, image: np.ndarray) -> np.ndarray:
        """AIåˆ†å‰²"""
        # ä½¿ç”¨GrabCutè¿›è¡Œåˆ†å‰²
        mask = np.zeros(image.shape[:2], np.uint8)
        bgd_model = np.zeros((1, 65), np.float64)
        fgd_model = np.zeros((1, 65), np.float64)
        
        rect = (10, 10, image.shape[1]-20, image.shape[0]-20)
        cv2.grabCut(image, mask, rect, bgd_model, fgd_model, 5, cv2.GC_INIT_WITH_RECT)
        
        mask2 = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')
        return mask2 * 255
    
    def _load_image(self, input_path: str) -> Optional[np.ndarray]:
        """åŠ è½½å›¾åƒ"""
        try:
            image = cv2.imread(input_path)
            if image is None:
                logger.error(f"æ— æ³•åŠ è½½å›¾åƒ: {input_path}")
                return None
            return image
        except Exception as e:
            logger.error(f"åŠ è½½å›¾åƒå¤±è´¥: {input_path}, é”™è¯¯: {e}")
            return None
    
    def _save_result(self, image: np.ndarray, job_id: str) -> str:
        """ä¿å­˜å¤„ç†ç»“æœ"""
        timestamp = time.strftime("%y%m%d_%H%M%S")
        filename = f"{timestamp}_enhanced_{job_id}.png"
        output_path = self.outputs_dir / filename
        
        # é«˜è´¨é‡ä¿å­˜
        cv2.imwrite(str(output_path), image, [cv2.IMWRITE_PNG_COMPRESSION, 0])
        
        return str(output_path)
    
    def _save_cached_result(self, cached_image: np.ndarray, job_id: str, start_time: float) -> Tuple[str, str, float]:
        """ä¿å­˜ç¼“å­˜ç»“æœ"""
        output_path = self._save_result(cached_image, job_id)
        processing_time = time.time() - start_time
        return output_path, "", processing_time
    
    def _update_stats(self, processing_time: float):
        """æ›´æ–°æ€§èƒ½ç»Ÿè®¡"""
        self.performance_stats["total_processed"] += 1
        self.performance_stats["total_time"] += processing_time
        self.performance_stats["average_time"] = (
            self.performance_stats["total_time"] / self.performance_stats["total_processed"]
        )
    
    def get_performance_stats(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½ç»Ÿè®¡"""
        stats = self.performance_stats.copy()
        
        # æ·»åŠ ç»„ä»¶ç»Ÿè®¡
        if self.gpu_accelerator:
            stats["gpu_stats"] = self.gpu_accelerator.get_performance_stats()
        
        if self.parallel_processor:
            stats["parallel_stats"] = self.parallel_processor.get_stats()
        
        stats["memory_stats"] = self.memory_manager.get_comprehensive_stats()
        
        return stats
    
    def optimize_system(self) -> Dict[str, Any]:
        """ç³»ç»Ÿä¼˜åŒ–"""
        optimization_results = {}
        
        # å†…å­˜ä¼˜åŒ–
        optimization_results["memory"] = self.memory_manager.optimize_memory()
        
        # GPUä¼˜åŒ–ï¼ˆå¦‚æœæœ‰ï¼‰
        if self.gpu_accelerator and self.gpu_accelerator.is_available():
            # è¿™é‡Œå¯ä»¥æ·»åŠ GPUç‰¹å®šçš„ä¼˜åŒ–
            optimization_results["gpu"] = {"status": "optimized"}
        
        logger.info("ç³»ç»Ÿä¼˜åŒ–å®Œæˆ")
        return optimization_results
    
    def shutdown(self):
        """å…³é—­å¤„ç†å™¨"""
        if self.parallel_processor:
            self.parallel_processor.shutdown()
        
        if self.memory_manager:
            self.memory_manager.shutdown()
        
        logger.info("å¢å¼ºç‰ˆå›¾åƒå¤„ç†å™¨å·²å…³é—­")
    
    def __enter__(self):
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        self.shutdown()


class EnhancedProcessingManager:
    """
    å¢å¼ºç‰ˆå¤„ç†ç®¡ç†å™¨
    
    ç»Ÿä¸€ç®¡ç†å¤šä¸ªå¢å¼ºç‰ˆå›¾åƒå¤„ç†å™¨
    """
    
    def __init__(self, num_processors: int = 2):
        """
        åˆå§‹åŒ–å¤„ç†ç®¡ç†å™¨
        
        Args:
            num_processors: å¤„ç†å™¨æ•°é‡
        """
        self.processors = []
        self.current_processor = 0
        
        # åˆ›å»ºå¤šä¸ªå¤„ç†å™¨å®ä¾‹
        for i in range(num_processors):
            processor = EnhancedImageProcessor(
                outputs_dir=f"outputs/processor_{i}",
                use_gpu=True,
                use_parallel=True
            )
            self.processors.append(processor)
        
        logger.info(f"å¢å¼ºç‰ˆå¤„ç†ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ: {num_processors} ä¸ªå¤„ç†å™¨")
    
    def process_image(self, input_path: str, job_id: str, **kwargs) -> Tuple[str, str, float]:
        """
        å¤„ç†å›¾åƒï¼ˆè´Ÿè½½å‡è¡¡ï¼‰
        
        Args:
            input_path: è¾“å…¥å›¾åƒè·¯å¾„
            job_id: ä»»åŠ¡ID
            **kwargs: å…¶ä»–å‚æ•°
            
        Returns:
            Tuple[str, str, float]: å¤„ç†ç»“æœ
        """
        # ç®€å•çš„è½®è¯¢è´Ÿè½½å‡è¡¡
        processor = self.processors[self.current_processor]
        self.current_processor = (self.current_processor + 1) % len(self.processors)
        
        return processor.process_image_enhanced(input_path, job_id, **kwargs)
    
    def get_all_stats(self) -> Dict[str, Any]:
        """è·å–æ‰€æœ‰å¤„ç†å™¨çš„ç»Ÿè®¡ä¿¡æ¯"""
        all_stats = {}
        for i, processor in enumerate(self.processors):
            all_stats[f"processor_{i}"] = processor.get_performance_stats()
        return all_stats
    
    def shutdown(self):
        """å…³é—­æ‰€æœ‰å¤„ç†å™¨"""
        for processor in self.processors:
            processor.shutdown()
        logger.info("å¢å¼ºç‰ˆå¤„ç†ç®¡ç†å™¨å·²å…³é—­") 