"""
ç»¼åˆæµ‹è¯•å¥—ä»¶
æµ‹è¯•æ‰€æœ‰æ–°å¼€å‘çš„AIç»„ä»¶å’Œæ€§èƒ½åŸºå‡†æµ‹è¯•
"""

import cv2
import numpy as np
import logging
import time
import json
import argparse
from typing import Dict, Any, List, Tuple, Optional
from pathlib import Path
import os
import sys

# å¯¼å…¥æ–°å¼€å‘çš„ç»„ä»¶
from parallel_processor import ParallelProcessor, ImageProcessingPipeline
from gpu_accelerator import GPUAccelerator, GPUProcessingPipeline
from memory_manager import MemoryManager
from enhanced_image_processor import EnhancedImageProcessor, EnhancedProcessingManager
from deep_learning_models import DeepLearningModelManager, ModelConfig
from quality_assessment import QualityAssessmentSystem

logger = logging.getLogger(__name__)


class ComprehensiveTestSuite:
    """ç»¼åˆæµ‹è¯•å¥—ä»¶"""
    
    def __init__(self, test_data_dir: str = "test_data", results_dir: str = "test_results"):
        self.test_data_dir = Path(test_data_dir)
        self.results_dir = Path(results_dir)
        self.results_dir.mkdir(exist_ok=True, parents=True)
        
        # æµ‹è¯•ç»“æœ
        self.test_results = {
            "timestamp": time.time(),
            "system_info": self._get_system_info(),
            "tests": {}
        }
        
        logger.info("ç»¼åˆæµ‹è¯•å¥—ä»¶åˆå§‹åŒ–å®Œæˆ")
    
    def run_all_tests(self) -> Dict[str, Any]:
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        logger.info("ğŸš€ å¼€å§‹è¿è¡Œç»¼åˆæµ‹è¯•å¥—ä»¶")
        
        try:
            # 1. åŸºç¡€åŠŸèƒ½æµ‹è¯•
            self.test_results["tests"]["basic_functionality"] = self._test_basic_functionality()
            
            # 2. å¹¶è¡Œå¤„ç†æµ‹è¯•
            self.test_results["tests"]["parallel_processing"] = self._test_parallel_processing()
            
            # 3. GPUåŠ é€Ÿæµ‹è¯•
            self.test_results["tests"]["gpu_acceleration"] = self._test_gpu_acceleration()
            
            # 4. å†…å­˜ç®¡ç†æµ‹è¯•
            self.test_results["tests"]["memory_management"] = self._test_memory_management()
            
            # 5. å¢å¼ºå›¾åƒå¤„ç†æµ‹è¯•
            self.test_results["tests"]["enhanced_processing"] = self._test_enhanced_processing()
            
            # 6. æ·±åº¦å­¦ä¹ æ¨¡å‹æµ‹è¯•
            self.test_results["tests"]["deep_learning"] = self._test_deep_learning()
            
            # 7. è´¨é‡è¯„ä¼°æµ‹è¯•
            self.test_results["tests"]["quality_assessment"] = self._test_quality_assessment()
            
            # 8. æ€§èƒ½åŸºå‡†æµ‹è¯•
            self.test_results["tests"]["performance_benchmark"] = self._test_performance_benchmark()
            
            # 9. é›†æˆæµ‹è¯•
            self.test_results["tests"]["integration"] = self._test_integration()
            
            # ä¿å­˜æµ‹è¯•ç»“æœ
            self._save_test_results()
            
            # ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
            report = self._generate_test_report()
            
            logger.info("âœ… ç»¼åˆæµ‹è¯•å¥—ä»¶è¿è¡Œå®Œæˆ")
            return report
            
        except Exception as e:
            logger.error(f"ç»¼åˆæµ‹è¯•å¥—ä»¶è¿è¡Œå¤±è´¥: {e}")
            raise
    
    def _test_basic_functionality(self) -> Dict[str, Any]:
        """åŸºç¡€åŠŸèƒ½æµ‹è¯•"""
        logger.info("ğŸ“‹ è¿è¡ŒåŸºç¡€åŠŸèƒ½æµ‹è¯•")
        
        results = {
            "status": "passed",
            "tests": {},
            "errors": []
        }
        
        try:
            # æµ‹è¯•OpenCVåŸºç¡€åŠŸèƒ½
            test_image = np.random.randint(0, 255, (100, 100, 3), dtype=np.uint8)
            
            # æµ‹è¯•å›¾åƒè¯»å–å’Œä¿å­˜
            test_path = self.results_dir / "test_basic.png"
            cv2.imwrite(str(test_path), test_image)
            loaded_image = cv2.imread(str(test_path))
            
            if loaded_image is not None and np.array_equal(test_image, loaded_image):
                results["tests"]["opencv_io"] = {"status": "passed", "message": "OpenCV I/OåŠŸèƒ½æ­£å¸¸"}
            else:
                results["tests"]["opencv_io"] = {"status": "failed", "message": "OpenCV I/OåŠŸèƒ½å¼‚å¸¸"}
                results["status"] = "failed"
            
            # æµ‹è¯•NumPyåŠŸèƒ½
            array1 = np.array([1, 2, 3])
            array2 = np.array([4, 5, 6])
            result = np.dot(array1, array2)
            
            if result == 32:  # 1*4 + 2*5 + 3*6 = 32
                results["tests"]["numpy_operations"] = {"status": "passed", "message": "NumPyè¿ç®—åŠŸèƒ½æ­£å¸¸"}
            else:
                results["tests"]["numpy_operations"] = {"status": "failed", "message": "NumPyè¿ç®—åŠŸèƒ½å¼‚å¸¸"}
                results["status"] = "failed"
            
        except Exception as e:
            results["status"] = "failed"
            results["errors"].append(f"åŸºç¡€åŠŸèƒ½æµ‹è¯•å¼‚å¸¸: {e}")
            logger.error(f"åŸºç¡€åŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
        
        return results
    
    def _test_parallel_processing(self) -> Dict[str, Any]:
        """å¹¶è¡Œå¤„ç†æµ‹è¯•"""
        logger.info("ğŸ”„ è¿è¡Œå¹¶è¡Œå¤„ç†æµ‹è¯•")
        
        results = {
            "status": "passed",
            "tests": {},
            "performance": {},
            "errors": []
        }
        
        try:
            # åˆ›å»ºæµ‹è¯•å›¾åƒ
            test_images = []
            for i in range(5):
                img = np.random.randint(0, 255, (200, 200, 3), dtype=np.uint8)
                test_images.append(img)
            
            # æµ‹è¯•å¹¶è¡Œå¤„ç†å™¨
            processor = ParallelProcessor(max_workers=2)
            
            # æµ‹è¯•ä»»åŠ¡æäº¤
            start_time = time.time()
            tasks = []
            for i, img in enumerate(test_images):
                task = processor.submit_task(f"test_{i}", img, "blur", {"kernel_size": 5})
                tasks.append(task)
            
            # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
            results_list = []
            for task in tasks:
                result = processor.get_result(task.task_id)
                if result:
                    results_list.append(result)
            
            processing_time = time.time() - start_time
            
            # éªŒè¯ç»“æœ
            if len(results_list) == len(test_images):
                results["tests"]["task_execution"] = {"status": "passed", "message": "å¹¶è¡Œä»»åŠ¡æ‰§è¡ŒæˆåŠŸ"}
                results["performance"]["processing_time"] = processing_time
                results["performance"]["images_per_second"] = len(test_images) / processing_time
            else:
                results["tests"]["task_execution"] = {"status": "failed", "message": "å¹¶è¡Œä»»åŠ¡æ‰§è¡Œå¤±è´¥"}
                results["status"] = "failed"
            
            # æµ‹è¯•æµæ°´çº¿å¤„ç†
            pipeline = ImageProcessingPipeline(max_workers=2)
            pipeline.add_step("blur", {"kernel_size": 3})
            pipeline.add_step("sharpen", {"kernel_size": 3})
            
            start_time = time.time()
            pipeline_result = pipeline.process_image(test_images[0], "pipeline_test")
            pipeline_time = time.time() - start_time
            
            if pipeline_result:
                results["tests"]["pipeline_processing"] = {"status": "passed", "message": "æµæ°´çº¿å¤„ç†æˆåŠŸ"}
                results["performance"]["pipeline_time"] = pipeline_time
            else:
                results["tests"]["pipeline_processing"] = {"status": "failed", "message": "æµæ°´çº¿å¤„ç†å¤±è´¥"}
                results["status"] = "failed"
            
            processor.shutdown()
            
        except Exception as e:
            results["status"] = "failed"
            results["errors"].append(f"å¹¶è¡Œå¤„ç†æµ‹è¯•å¼‚å¸¸: {e}")
            logger.error(f"å¹¶è¡Œå¤„ç†æµ‹è¯•å¤±è´¥: {e}")
        
        return results
    
    def _test_gpu_acceleration(self) -> Dict[str, Any]:
        """GPUåŠ é€Ÿæµ‹è¯•"""
        logger.info("ğŸš€ è¿è¡ŒGPUåŠ é€Ÿæµ‹è¯•")
        
        results = {
            "status": "passed",
            "tests": {},
            "performance": {},
            "errors": []
        }
        
        try:
            # æµ‹è¯•GPUæ£€æµ‹
            gpu_accelerator = GPUAccelerator()
            gpu_info = gpu_accelerator.get_gpu_info()
            
            if gpu_info:
                results["tests"]["gpu_detection"] = {"status": "passed", "message": f"æ£€æµ‹åˆ°GPU: {gpu_info[0].name}"}
                results["performance"]["gpu_info"] = [gpu.to_dict() for gpu in gpu_info]
            else:
                results["tests"]["gpu_detection"] = {"status": "skipped", "message": "æœªæ£€æµ‹åˆ°GPU"}
                results["status"] = "skipped"
                return results
            
            # æµ‹è¯•GPUå¤„ç†æµæ°´çº¿
            test_image = np.random.randint(0, 255, (300, 300, 3), dtype=np.uint8)
            
            gpu_pipeline = GPUProcessingPipeline()
            gpu_pipeline.add_step("bilateral_filter", {"d": 9, "sigma_color": 75, "sigma_space": 75})
            
            start_time = time.time()
            gpu_result = gpu_pipeline.process_image(test_image)
            gpu_time = time.time() - start_time
            
            if gpu_result is not None:
                results["tests"]["gpu_processing"] = {"status": "passed", "message": "GPUå¤„ç†æˆåŠŸ"}
                results["performance"]["gpu_processing_time"] = gpu_time
            else:
                results["tests"]["gpu_processing"] = {"status": "failed", "message": "GPUå¤„ç†å¤±è´¥"}
                results["status"] = "failed"
            
            # å¯¹æ¯”CPUå¤„ç†æ—¶é—´
            start_time = time.time()
            cpu_result = cv2.bilateralFilter(test_image, 9, 75, 75)
            cpu_time = time.time() - start_time
            
            results["performance"]["cpu_processing_time"] = cpu_time
            if gpu_time < cpu_time:
                results["performance"]["speedup"] = cpu_time / gpu_time
            else:
                results["performance"]["speedup"] = 1.0
            
        except Exception as e:
            results["status"] = "failed"
            results["errors"].append(f"GPUåŠ é€Ÿæµ‹è¯•å¼‚å¸¸: {e}")
            logger.error(f"GPUåŠ é€Ÿæµ‹è¯•å¤±è´¥: {e}")
        
        return results
    
    def _test_memory_management(self) -> Dict[str, Any]:
        """å†…å­˜ç®¡ç†æµ‹è¯•"""
        logger.info("ğŸ’¾ è¿è¡Œå†…å­˜ç®¡ç†æµ‹è¯•")
        
        results = {
            "status": "passed",
            "tests": {},
            "performance": {},
            "errors": []
        }
        
        try:
            # æµ‹è¯•å†…å­˜ç®¡ç†å™¨
            memory_manager = MemoryManager(pool_size=5, cache_size=10)
            
            # æµ‹è¯•å†…å­˜åˆ†é…
            start_time = time.time()
            allocated_memory = []
            for i in range(10):
                mem = memory_manager.allocate_memory(1024 * 1024)  # 1MB
                if mem is not None:
                    allocated_memory.append(mem)
            
            allocation_time = time.time() - start_time
            
            if len(allocated_memory) == 10:
                results["tests"]["memory_allocation"] = {"status": "passed", "message": "å†…å­˜åˆ†é…æˆåŠŸ"}
                results["performance"]["allocation_time"] = allocation_time
            else:
                results["tests"]["memory_allocation"] = {"status": "failed", "message": "å†…å­˜åˆ†é…å¤±è´¥"}
                results["status"] = "failed"
            
            # æµ‹è¯•å›¾åƒç¼“å­˜
            test_image = np.random.randint(0, 255, (100, 100, 3), dtype=np.uint8)
            
            cache_success = memory_manager.cache_image("test_image", test_image)
            if cache_success:
                results["tests"]["image_caching"] = {"status": "passed", "message": "å›¾åƒç¼“å­˜æˆåŠŸ"}
            else:
                results["tests"]["image_caching"] = {"status": "failed", "message": "å›¾åƒç¼“å­˜å¤±è´¥"}
                results["status"] = "failed"
            
            # æµ‹è¯•ç¼“å­˜æ£€ç´¢
            cached_image = memory_manager.get_cached_image("test_image")
            if cached_image is not None and np.array_equal(test_image, cached_image):
                results["tests"]["cache_retrieval"] = {"status": "passed", "message": "ç¼“å­˜æ£€ç´¢æˆåŠŸ"}
            else:
                results["tests"]["cache_retrieval"] = {"status": "failed", "message": "ç¼“å­˜æ£€ç´¢å¤±è´¥"}
                results["status"] = "failed"
            
            # æµ‹è¯•å†…å­˜ä¼˜åŒ–
            optimization_result = memory_manager.optimize_memory()
            results["performance"]["optimization_result"] = optimization_result
            
            # è·å–ç»Ÿè®¡ä¿¡æ¯
            stats = memory_manager.get_comprehensive_stats()
            results["performance"]["memory_stats"] = stats
            
            memory_manager.shutdown()
            
        except Exception as e:
            results["status"] = "failed"
            results["errors"].append(f"å†…å­˜ç®¡ç†æµ‹è¯•å¼‚å¸¸: {e}")
            logger.error(f"å†…å­˜ç®¡ç†æµ‹è¯•å¤±è´¥: {e}")
        
        return results
    
    def _test_enhanced_processing(self) -> Dict[str, Any]:
        """å¢å¼ºå›¾åƒå¤„ç†æµ‹è¯•"""
        logger.info("ğŸ¨ è¿è¡Œå¢å¼ºå›¾åƒå¤„ç†æµ‹è¯•")
        
        results = {
            "status": "passed",
            "tests": {},
            "performance": {},
            "errors": []
        }
        
        try:
            # åˆ›å»ºæµ‹è¯•å›¾åƒ
            test_image = np.random.randint(0, 255, (400, 400, 3), dtype=np.uint8)
            test_path = self.results_dir / "test_enhanced_input.png"
            cv2.imwrite(str(test_path), test_image)
            
            # æµ‹è¯•å¢å¼ºå›¾åƒå¤„ç†å™¨
            processor = EnhancedImageProcessor(
                outputs_dir=str(self.results_dir / "enhanced_outputs"),
                use_gpu=False,  # å…ˆæµ‹è¯•CPUç‰ˆæœ¬
                use_parallel=True
            )
            
            # æµ‹è¯•å¢å¼ºå¤„ç†
            start_time = time.time()
            output_path, error, processing_time = processor.process_image_enhanced(
                str(test_path), "test_enhanced",
                color_count=16,
                edge_enhancement=True,
                noise_reduction=True,
                use_ai_segmentation=True
            )
            
            total_time = time.time() - start_time
            
            if error == "" and os.path.exists(output_path):
                results["tests"]["enhanced_processing"] = {"status": "passed", "message": "å¢å¼ºå¤„ç†æˆåŠŸ"}
                results["performance"]["processing_time"] = processing_time
                results["performance"]["total_time"] = total_time
            else:
                results["tests"]["enhanced_processing"] = {"status": "failed", "message": f"å¢å¼ºå¤„ç†å¤±è´¥: {error}"}
                results["status"] = "failed"
            
            # æµ‹è¯•å¤„ç†ç®¡ç†å™¨
            manager = EnhancedProcessingManager(num_processors=2)
            
            start_time = time.time()
            output_path2, error2, processing_time2 = manager.process_image(
                str(test_path), "test_manager",
                color_count=8,
                edge_enhancement=False,
                noise_reduction=True
            )
            
            manager_time = time.time() - start_time
            
            if error2 == "" and os.path.exists(output_path2):
                results["tests"]["processing_manager"] = {"status": "passed", "message": "å¤„ç†ç®¡ç†å™¨æˆåŠŸ"}
                results["performance"]["manager_time"] = manager_time
            else:
                results["tests"]["processing_manager"] = {"status": "failed", "message": f"å¤„ç†ç®¡ç†å™¨å¤±è´¥: {error2}"}
                results["status"] = "failed"
            
            # è·å–æ€§èƒ½ç»Ÿè®¡
            stats = processor.get_performance_stats()
            results["performance"]["processor_stats"] = stats
            
            manager.shutdown()
            
        except Exception as e:
            results["status"] = "failed"
            results["errors"].append(f"å¢å¼ºå›¾åƒå¤„ç†æµ‹è¯•å¼‚å¸¸: {e}")
            logger.error(f"å¢å¼ºå›¾åƒå¤„ç†æµ‹è¯•å¤±è´¥: {e}")
        
        return results
    
    def _test_deep_learning(self) -> Dict[str, Any]:
        """æ·±åº¦å­¦ä¹ æ¨¡å‹æµ‹è¯•"""
        logger.info("ğŸ§  è¿è¡Œæ·±åº¦å­¦ä¹ æ¨¡å‹æµ‹è¯•")
        
        results = {
            "status": "passed",
            "tests": {},
            "performance": {},
            "errors": []
        }
        
        try:
            # æµ‹è¯•æ·±åº¦å­¦ä¹ æ¨¡å‹ç®¡ç†å™¨
            model_manager = DeepLearningModelManager(models_dir=str(self.results_dir / "models"))
            
            # æµ‹è¯•æ¨¡å‹é…ç½®
            config = ModelConfig(
                model_type="unet",
                input_size=(256, 256),
                num_classes=2,
                device="cpu"  # ä½¿ç”¨CPUè¿›è¡Œæµ‹è¯•
            )
            
            # æµ‹è¯•æ¨¡å‹åŠ è½½ï¼ˆå¦‚æœPyTorchå¯ç”¨ï¼‰
            try:
                if model_manager.load_segmentation_model("unet", config):
                    results["tests"]["model_loading"] = {"status": "passed", "message": "æ¨¡å‹åŠ è½½æˆåŠŸ"}
                else:
                    results["tests"]["model_loading"] = {"status": "skipped", "message": "æ¨¡å‹åŠ è½½è·³è¿‡ï¼ˆä¾èµ–åº“æœªå®‰è£…ï¼‰"}
                    results["status"] = "skipped"
                    return results
            except ImportError:
                results["tests"]["model_loading"] = {"status": "skipped", "message": "PyTorchæœªå®‰è£…"}
                results["status"] = "skipped"
                return results
            
            # æµ‹è¯•å›¾åƒåˆ†å‰²
            test_image = np.random.randint(0, 255, (200, 200, 3), dtype=np.uint8)
            
            start_time = time.time()
            segmentation_result = model_manager.segment_image(test_image, "unet")
            segmentation_time = time.time() - start_time
            
            if segmentation_result is not None and segmentation_result.shape[:2] == test_image.shape[:2]:
                results["tests"]["image_segmentation"] = {"status": "passed", "message": "å›¾åƒåˆ†å‰²æˆåŠŸ"}
                results["performance"]["segmentation_time"] = segmentation_time
            else:
                results["tests"]["image_segmentation"] = {"status": "failed", "message": "å›¾åƒåˆ†å‰²å¤±è´¥"}
                results["status"] = "failed"
            
            # æµ‹è¯•ç‰¹å¾æå–å™¨
            if model_manager.load_feature_extractor("resnet50"):
                start_time = time.time()
                features = model_manager.extract_features(test_image, "resnet50")
                feature_time = time.time() - start_time
                
                if features is not None and len(features) > 0:
                    results["tests"]["feature_extraction"] = {"status": "passed", "message": "ç‰¹å¾æå–æˆåŠŸ"}
                    results["performance"]["feature_time"] = feature_time
                    results["performance"]["feature_dimension"] = len(features)
                else:
                    results["tests"]["feature_extraction"] = {"status": "failed", "message": "ç‰¹å¾æå–å¤±è´¥"}
                    results["status"] = "failed"
            
            # è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨
            available_models = model_manager.get_available_models()
            results["performance"]["available_models"] = available_models
            
        except Exception as e:
            results["status"] = "failed"
            results["errors"].append(f"æ·±åº¦å­¦ä¹ æ¨¡å‹æµ‹è¯•å¼‚å¸¸: {e}")
            logger.error(f"æ·±åº¦å­¦ä¹ æ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
        
        return results
    
    def _test_quality_assessment(self) -> Dict[str, Any]:
        """è´¨é‡è¯„ä¼°æµ‹è¯•"""
        logger.info("ğŸ“Š è¿è¡Œè´¨é‡è¯„ä¼°æµ‹è¯•")
        
        results = {
            "status": "passed",
            "tests": {},
            "performance": {},
            "errors": []
        }
        
        try:
            # åˆ›å»ºæµ‹è¯•å›¾åƒ
            original_image = np.random.randint(0, 255, (300, 300, 3), dtype=np.uint8)
            processed_image = cv2.GaussianBlur(original_image, (5, 5), 0)  # æ·»åŠ ä¸€äº›æ¨¡ç³Š
            
            original_path = self.results_dir / "test_original.png"
            processed_path = self.results_dir / "test_processed.png"
            
            cv2.imwrite(str(original_path), original_image)
            cv2.imwrite(str(processed_path), processed_image)
            
            # æµ‹è¯•è´¨é‡è¯„ä¼°ç³»ç»Ÿ
            quality_system = QualityAssessmentSystem(output_dir=str(self.results_dir / "quality"))
            
            # ä¸»è§‚è¯„åˆ†
            subjective_scores = {
                "color_accuracy": 8.0,
                "edge_preservation": 7.5,
                "detail_preservation": 7.0,
                "overall_quality": 7.5
            }
            
            # ç»¼åˆè¯„ä¼°
            start_time = time.time()
            assessment_result = quality_system.comprehensive_assessment(
                str(original_path), str(processed_path), "test_quality", subjective_scores
            )
            assessment_time = time.time() - start_time
            
            if assessment_result:
                results["tests"]["quality_assessment"] = {"status": "passed", "message": "è´¨é‡è¯„ä¼°æˆåŠŸ"}
                results["performance"]["assessment_time"] = assessment_time
                results["performance"]["assessment_result"] = assessment_result
            else:
                results["tests"]["quality_assessment"] = {"status": "failed", "message": "è´¨é‡è¯„ä¼°å¤±è´¥"}
                results["status"] = "failed"
            
            # æµ‹è¯•ç»Ÿè®¡ä¿¡æ¯
            stats = quality_system.get_statistics()
            results["performance"]["quality_stats"] = stats
            
        except Exception as e:
            results["status"] = "failed"
            results["errors"].append(f"è´¨é‡è¯„ä¼°æµ‹è¯•å¼‚å¸¸: {e}")
            logger.error(f"è´¨é‡è¯„ä¼°æµ‹è¯•å¤±è´¥: {e}")
        
        return results
    
    def _test_performance_benchmark(self) -> Dict[str, Any]:
        """æ€§èƒ½åŸºå‡†æµ‹è¯•"""
        logger.info("âš¡ è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•")
        
        results = {
            "status": "passed",
            "tests": {},
            "benchmarks": {},
            "errors": []
        }
        
        try:
            # åˆ›å»ºä¸åŒå°ºå¯¸çš„æµ‹è¯•å›¾åƒ
            test_sizes = [(100, 100), (300, 300), (500, 500), (800, 800)]
            
            for size in test_sizes:
                test_image = np.random.randint(0, 255, (*size, 3), dtype=np.uint8)
                size_key = f"{size[0]}x{size[1]}"
                
                # åŸºå‡†æµ‹è¯•ï¼šä¼ ç»ŸOpenCVå¤„ç†
                start_time = time.time()
                cv2_result = cv2.bilateralFilter(test_image, 9, 75, 75)
                cv2_time = time.time() - start_time
                
                # åŸºå‡†æµ‹è¯•ï¼šå¢å¼ºå¤„ç†å™¨
                processor = EnhancedImageProcessor(use_gpu=False, use_parallel=True)
                start_time = time.time()
                output_path, error, processing_time = processor.process_image_enhanced(
                    "test_image", f"benchmark_{size_key}",
                    color_count=16,
                    edge_enhancement=True,
                    noise_reduction=True
                )
                enhanced_time = time.time() - start_time
                
                results["benchmarks"][size_key] = {
                    "opencv_time": cv2_time,
                    "enhanced_time": enhanced_time,
                    "speedup": cv2_time / enhanced_time if enhanced_time > 0 else 0
                }
            
            # å†…å­˜ä½¿ç”¨åŸºå‡†æµ‹è¯•
            memory_manager = MemoryManager()
            start_memory = memory_manager.get_comprehensive_stats()["system_memory"]["used_mb"]
            
            # å¤„ç†å¤§é‡å›¾åƒ
            for i in range(10):
                test_image = np.random.randint(0, 255, (200, 200, 3), dtype=np.uint8)
                memory_manager.cache_image(f"benchmark_{i}", test_image)
            
            end_memory = memory_manager.get_comprehensive_stats()["system_memory"]["used_mb"]
            memory_increase = end_memory - start_memory
            
            results["benchmarks"]["memory_usage"] = {
                "start_memory_mb": start_memory,
                "end_memory_mb": end_memory,
                "memory_increase_mb": memory_increase
            }
            
            memory_manager.shutdown()
            
        except Exception as e:
            results["status"] = "failed"
            results["errors"].append(f"æ€§èƒ½åŸºå‡†æµ‹è¯•å¼‚å¸¸: {e}")
            logger.error(f"æ€§èƒ½åŸºå‡†æµ‹è¯•å¤±è´¥: {e}")
        
        return results
    
    def _test_integration(self) -> Dict[str, Any]:
        """é›†æˆæµ‹è¯•"""
        logger.info("ğŸ”— è¿è¡Œé›†æˆæµ‹è¯•")
        
        results = {
            "status": "passed",
            "tests": {},
            "performance": {},
            "errors": []
        }
        
        try:
            # åˆ›å»ºå®Œæ•´çš„å¤„ç†æµæ°´çº¿
            test_image = np.random.randint(0, 255, (400, 400, 3), dtype=np.uint8)
            test_path = self.results_dir / "test_integration.png"
            cv2.imwrite(str(test_path), test_image)
            
            # 1. å¢å¼ºå›¾åƒå¤„ç†
            processor = EnhancedImageProcessor(use_gpu=False, use_parallel=True)
            output_path, error, processing_time = processor.process_image_enhanced(
                str(test_path), "integration_test",
                color_count=16,
                edge_enhancement=True,
                noise_reduction=True,
                use_ai_segmentation=True
            )
            
            if error != "" or not os.path.exists(output_path):
                results["tests"]["enhanced_processing"] = {"status": "failed", "message": "å¢å¼ºå¤„ç†å¤±è´¥"}
                results["status"] = "failed"
                return results
            
            # 2. è´¨é‡è¯„ä¼°
            quality_system = QualityAssessmentSystem()
            subjective_scores = {
                "color_accuracy": 8.0,
                "edge_preservation": 7.5,
                "detail_preservation": 7.0,
                "overall_quality": 7.5
            }
            
            assessment_result = quality_system.comprehensive_assessment(
                str(test_path), output_path, "integration_test", subjective_scores
            )
            
            if assessment_result:
                results["tests"]["quality_assessment"] = {"status": "passed", "message": "è´¨é‡è¯„ä¼°æˆåŠŸ"}
                results["performance"]["assessment_result"] = assessment_result
            else:
                results["tests"]["quality_assessment"] = {"status": "failed", "message": "è´¨é‡è¯„ä¼°å¤±è´¥"}
                results["status"] = "failed"
            
            # 3. æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            try:
                model_manager = DeepLearningModelManager()
                config = ModelConfig(model_type="unet", input_size=(256, 256), device="cpu")
                
                if model_manager.load_segmentation_model("unet", config):
                    segmentation_result = model_manager.segment_image(test_image, "unet")
                    if segmentation_result is not None:
                        results["tests"]["deep_learning"] = {"status": "passed", "message": "æ·±åº¦å­¦ä¹ é›†æˆæˆåŠŸ"}
                    else:
                        results["tests"]["deep_learning"] = {"status": "failed", "message": "æ·±åº¦å­¦ä¹ é›†æˆå¤±è´¥"}
                        results["status"] = "failed"
                else:
                    results["tests"]["deep_learning"] = {"status": "skipped", "message": "æ·±åº¦å­¦ä¹ æ¨¡å‹ä¸å¯ç”¨"}
            except Exception as e:
                results["tests"]["deep_learning"] = {"status": "skipped", "message": f"æ·±åº¦å­¦ä¹ è·³è¿‡: {e}"}
            
            results["tests"]["integration"] = {"status": "passed", "message": "é›†æˆæµ‹è¯•å®Œæˆ"}
            
        except Exception as e:
            results["status"] = "failed"
            results["errors"].append(f"é›†æˆæµ‹è¯•å¼‚å¸¸: {e}")
            logger.error(f"é›†æˆæµ‹è¯•å¤±è´¥: {e}")
        
        return results
    
    def _get_system_info(self) -> Dict[str, Any]:
        """è·å–ç³»ç»Ÿä¿¡æ¯"""
        import platform
        import psutil
        
        return {
            "platform": platform.platform(),
            "python_version": platform.python_version(),
            "cpu_count": psutil.cpu_count(),
            "memory_total_gb": psutil.virtual_memory().total / (1024**3),
            "opencv_version": cv2.__version__,
            "numpy_version": np.__version__
        }
    
    def _save_test_results(self):
        """ä¿å­˜æµ‹è¯•ç»“æœ"""
        timestamp = time.strftime("%y%m%d_%H%M%S")
        filename = f"comprehensive_test_results_{timestamp}.json"
        filepath = self.results_dir / filename
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(self.test_results, f, indent=2, ensure_ascii=False)
        
        logger.info(f"æµ‹è¯•ç»“æœå·²ä¿å­˜: {filepath}")
    
    def _generate_test_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        total_tests = 0
        passed_tests = 0
        failed_tests = 0
        skipped_tests = 0
        
        for test_category, test_result in self.test_results["tests"].items():
            if test_result["status"] == "passed":
                passed_tests += 1
            elif test_result["status"] == "failed":
                failed_tests += 1
            elif test_result["status"] == "skipped":
                skipped_tests += 1
            
            total_tests += 1
        
        report = {
            "summary": {
                "total_tests": total_tests,
                "passed_tests": passed_tests,
                "failed_tests": failed_tests,
                "skipped_tests": skipped_tests,
                "success_rate": (passed_tests / total_tests * 100) if total_tests > 0 else 0
            },
            "system_info": self.test_results["system_info"],
            "detailed_results": self.test_results["tests"],
            "timestamp": self.test_results["timestamp"]
        }
        
        # æ‰“å°æŠ¥å‘Šæ‘˜è¦
        logger.info("ğŸ“Š æµ‹è¯•æŠ¥å‘Šæ‘˜è¦:")
        logger.info(f"  æ€»æµ‹è¯•æ•°: {total_tests}")
        logger.info(f"  é€šè¿‡: {passed_tests}")
        logger.info(f"  å¤±è´¥: {failed_tests}")
        logger.info(f"  è·³è¿‡: {skipped_tests}")
        logger.info(f"  æˆåŠŸç‡: {report['summary']['success_rate']:.1f}%")
        
        return report


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="ç»¼åˆæµ‹è¯•å¥—ä»¶")
    parser.add_argument("--test-data-dir", default="test_data", help="æµ‹è¯•æ•°æ®ç›®å½•")
    parser.add_argument("--results-dir", default="test_results", help="ç»“æœè¾“å‡ºç›®å½•")
    parser.add_argument("--verbose", "-v", action="store_true", help="è¯¦ç»†è¾“å‡º")
    
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—çº§åˆ«
    if args.verbose:
        logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    else:
        logging.basicConfig(level=logging.WARNING, format='%(asctime)s - %(levelname)s - %(message)s')
    
    # è¿è¡Œæµ‹è¯•å¥—ä»¶
    test_suite = ComprehensiveTestSuite(args.test_data_dir, args.results_dir)
    report = test_suite.run_all_tests()
    
    # è¿”å›é€€å‡ºç 
    if report["summary"]["failed_tests"] > 0:
        sys.exit(1)
    else:
        sys.exit(0)


if __name__ == "__main__":
    main() 